{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T00:58:22.961851Z",
     "end_time": "2024-04-18T00:58:24.147443Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T00:58:24.152443Z",
     "end_time": "2024-04-18T00:58:34.632202Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../tools')\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import random\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import pytorch_lightning.callbacks as pl_callbacks\n",
    "from models.rns_dataloader import get_data, get_data_by_episode\n",
    "\n",
    "import data_utility\n",
    "import annotation_utility\n",
    "import interactive_plot\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argument*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Set a lower value for log_every_n_steps if you want to see logs for the training epoch*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*exists and is not empty*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Checkpoint directory {dirpath} exists and is not empty*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T00:58:34.636201Z",
     "end_time": "2024-04-18T00:58:35.464412Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"../../../user_data/\"\n",
    "log_folder_root = '../../../user_data/logs/'\n",
    "ckpt_folder_root = '../../../user_data/checkpoints/'\n",
    "\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    # True ensures the algorithm selected by CUFA is deterministic\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # torch.set_deterministic(True)\n",
    "    # False ensures CUDA select the same algorithm each time the application is run\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import pytorch_lightning\n",
    "\n",
    "pytorch_lightning.utilities.seed.seed_everything(seed=random_seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T00:58:35.466412Z",
     "end_time": "2024-04-18T00:58:36.229387Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.rns_dataloader import RNS_Downstream\n",
    "# from models.SwaV import SwaV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T00:58:36.231392Z",
     "end_time": "2024-04-18T00:58:37.357344Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "from lightly.data import LightlyDataset, SwaVCollateFunction\n",
    "from lightly.loss import SwaVLoss\n",
    "from lightly.loss.memory_bank import MemoryBankModule\n",
    "from lightly.models.modules import SwaVProjectionHead, SwaVPrototypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T00:58:37.358345Z",
     "end_time": "2024-04-18T00:58:38.179438Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    info = list(zip(*batch))\n",
    "    data = info[0]\n",
    "    label = info[1]\n",
    "    return torch.stack(data), torch.stack(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T00:58:38.168438Z",
     "end_time": "2024-04-18T00:59:06.080152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:26<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87319, 249, 36)\n",
      "(87319,)\n",
      "(87319,)\n",
      "(21837, 249, 36)\n",
      "(21837,)\n",
      "(21837,)\n"
     ]
    }
   ],
   "source": [
    "data_list = os.listdir(data_dir+'rns_test_cache')[1:]\n",
    "\n",
    "# data_list = ['HUP182.npy',   'HUP129.npy',   'HUP109.npy', 'HUP156.npy', 'HUP096.npy', 'RNS026.npy',  'HUP159.npy']\n",
    "# data_list = ['RNS026.npy', 'HUP159.npy', 'HUP129.npy', 'HUP096.npy', 'HUP182.npy']\n",
    "train_data, train_label, test_data, test_label, train_index, test_index = get_data(data_list, split=0.8)\n",
    "# data, label,_,_ = get_data(data_list, split=1)\n",
    "# train_data, test_data, train_label, test_label = sklearn.model_selection.train_test_split(data, label, test_size=0.8, random_state=42)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(train_index.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)\n",
    "print(test_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import sklearn\n",
    "from sigmoid_loss import sigmoid_focal_loss\n",
    "\n",
    "class LinearHead(pl.LightningModule):\n",
    "    def __init__(self, backbone,):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.fc1 = nn.Linear(2048, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.alpha = 0\n",
    "        self.gamma = 5\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        self.set_requires_grad(self.backbone, False)\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(-1, 2048)\n",
    "        pred = self.fc1(x)\n",
    "        pred = self.softmax(pred)\n",
    "        label = F.one_hot(y, num_classes=2).squeeze()\n",
    "        loss = sigmoid_focal_loss(pred.float(), label.float(), alpha=self.alpha, gamma=self.gamma, reduction='mean')\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(-1, 2048)\n",
    "        pred = self.fc1(x)\n",
    "        pred = self.softmax(pred)\n",
    "        label = F.one_hot(y, num_classes=2).squeeze()\n",
    "        loss = sigmoid_focal_loss(pred.float(), label.float(), alpha=self.alpha, gamma=self.gamma, reduction='mean')\n",
    "        out = torch.argmax(pred, dim=1)\n",
    "        # print(out.size)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        target = y.squeeze().detach().cpu().numpy()\n",
    "        fscore = sklearn.metrics.f1_score(out, target,labels = [0,1],zero_division=0)\n",
    "        acc = sklearn.metrics.accuracy_score(out, target)\n",
    "        # print(acc)\n",
    "        # print(precision)\n",
    "        # print(recall)\n",
    "        # print(fscore)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"val_loss\", loss,prog_bar=False)\n",
    "        self.log(\"val_acc\", acc,prog_bar=False)\n",
    "        self.log(\"val_fscore\", fscore,prog_bar=False)\n",
    "        return pred, label\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # print(batch)\n",
    "        x, y = batch\n",
    "        emb = self.backbone(x)\n",
    "        emb = emb.view(-1, 2048)\n",
    "        pred = self.fc1(emb)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        return pred, y, emb\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def set_requires_grad(self, model, requires_grad=True, exclude = None):\n",
    "        \"\"\"\n",
    "        Used in training adversarial approach\n",
    "        :param model:\n",
    "        :param requires_grad:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "        if exclude is not None:\n",
    "            for name, child in model.named_children():\n",
    "                if name in exclude:\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad =not requires_grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T00:59:06.088151Z",
     "end_time": "2024-04-18T00:59:06.899152Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class SwaV(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = SwaVProjectionHead(2048, 2048, 128)\n",
    "        self.prototypes = SwaVPrototypes(128, 2048, 1)\n",
    "\n",
    "        self.start_queue_at_epoch = 35\n",
    "        self.queues = nn.ModuleList([MemoryBankModule(size=256) for _ in range(2)])\n",
    "\n",
    "    def forward(self, high_resolution, low_resolution, epoch):\n",
    "        self.prototypes.normalize()\n",
    "\n",
    "        high_resolution_features = [self._subforward(x) for x in high_resolution]\n",
    "        low_resolution_features = [self._subforward(x) for x in low_resolution]\n",
    "\n",
    "        high_resolution_prototypes = [\n",
    "            self.prototypes(x, epoch) for x in high_resolution_features\n",
    "        ]\n",
    "        low_resolution_prototypes = [\n",
    "            self.prototypes(x, epoch) for x in low_resolution_features\n",
    "        ]\n",
    "        queue_prototypes = self._get_queue_prototypes(high_resolution_features, epoch)\n",
    "\n",
    "        return high_resolution_prototypes, low_resolution_prototypes, queue_prototypes\n",
    "\n",
    "    def _subforward(self, input):\n",
    "        features = self.backbone(input).flatten(start_dim=1)\n",
    "        features = self.projection_head(features)\n",
    "        features = nn.functional.normalize(features, dim=1, p=2)\n",
    "        return features\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_queue_prototypes(self, high_resolution_features, epoch):\n",
    "        if len(high_resolution_features) != len(self.queues):\n",
    "            raise ValueError(\n",
    "                f\"The number of queues ({len(self.queues)}) should be equal to the number of high \"\n",
    "                f\"resolution inputs ({len(high_resolution_features)}). Set `n_queues` accordingly.\"\n",
    "            )\n",
    "\n",
    "        # Get the queue features\n",
    "        queue_features = []\n",
    "        for i in range(len(self.queues)):\n",
    "            _, features = self.queues[i](high_resolution_features[i], update=True)\n",
    "            # Queue features are in (num_ftrs X queue_length) shape, while the high res\n",
    "            # features are in (batch_size X num_ftrs). Swap the axes for interoperability.\n",
    "            features = torch.permute(features, (1, 0))\n",
    "            queue_features.append(features)\n",
    "\n",
    "        # If loss calculation with queue prototypes starts at a later epoch,\n",
    "        # just queue the features and return None instead of queue prototypes.\n",
    "        if self.start_queue_at_epoch > 0 and epoch < self.start_queue_at_epoch:\n",
    "            return None\n",
    "\n",
    "        # Assign prototypes\n",
    "        queue_prototypes = [self.prototypes(x, epoch) for x in queue_features]\n",
    "        return queue_prototypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T00:59:06.899152Z",
     "end_time": "2024-04-18T00:59:07.708370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T00:59:07.714369Z",
     "end_time": "2024-04-18T00:59:09.565368Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "linear_eval = 'p=0'\n",
    "\n",
    "ckpt = torch.load(ckpt_folder_root+\"checkpoint99.pth\")\n",
    "resnet = torchvision.models.resnet50()\n",
    "\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "swav = SwaV(backbone)\n",
    "swav.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "model = LinearHead(swav.backbone)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "ckpt_save_n_step = 150\n",
    "\n",
    "checkpoint_callback = pl_callbacks.ModelCheckpoint(monitor='train_loss',\n",
    "                                                   filename= linear_eval + '-{step}-{train_loss:.5f}',\n",
    "                                                   dirpath=ckpt_folder_root + 'rns_linear_eval/' + linear_eval + '/',\n",
    "                                                   save_top_k=-1,\n",
    "                                                   every_n_train_steps=ckpt_save_n_step,\n",
    "                                                   save_on_train_epoch_end=False)\n",
    "\n",
    "early_stop_callback = pl_callbacks.EarlyStopping(monitor=\"val_fscore\",\n",
    "                                                 patience=10,\n",
    "                                                 verbose=False,\n",
    "                                                 mode=\"max\")\n",
    "\n",
    "csv_logger = pl_loggers.CSVLogger(ckpt_folder_root + 'rns_linear_eval/' + linear_eval + '/',\n",
    "                                  name='logger')\n",
    "\n",
    "trainer = pl.Trainer(logger=csv_logger,\n",
    "                     max_epochs=100,\n",
    "                     callbacks=[checkpoint_callback, early_stop_callback],\n",
    "                     # callbacks=[checkpoint_callback],\n",
    "                     accelerator='gpu',\n",
    "                     devices=1,\n",
    "                     log_every_n_steps=50,\n",
    "                     precision=16,\n",
    "                     check_val_every_n_epoch=None,\n",
    "                     val_check_interval=ckpt_save_n_step,\n",
    "                     enable_model_summary=False,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T00:59:09.543369Z",
     "end_time": "2024-04-18T01:21:15.972405Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "(87319, 249, 36)\n",
      "(87319,)\n",
      "data loaded\n",
      "(21837, 249, 36)\n",
      "(21837,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12c419e22cea40df8abe723dc3d27793"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72e182e3b7bf488db457a4ba5d9df189"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21be720461c847b28102854f31e101dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57b54ea10c5543d09bd3df2ff830c745"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "647748888e0042f598fe152c025b0981"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1676b96d4bc41f9b106f0d29b76764b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbf9bc3f95fd4b27acf8a6a7d3db8aed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21c2c80f52324638822e68e4419b8666"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aed3f23d78e94ddb9bffe00b7c8aa443"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c3eb85d68d24896a04a1c738a19baad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3463a8a84f4544738c58d748767f7b06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a0e0c21d71a49d897d27894e4cf3247"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15bd3081468e4242b5d9cfdcf7c18335"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.rns_dataloader import RNS_Downstream\n",
    "train_dataset = RNS_Downstream(train_data, train_label, transform=True, astensor=True)\n",
    "test_dataset = RNS_Downstream(test_data, test_label, transform=False, astensor=True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T23:38:35.542956Z",
     "end_time": "2024-04-17T23:38:36.248954Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = RNS_Downstream(test_data, test_label, transform=False, astensor=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:34:41.413286Z",
     "end_time": "2024-04-18T01:35:56.662922Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at ../../../user_data/checkpoints/rns_linear_eval/p=0/p=0-step=150-train_loss=0.02511.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at ../../../user_data/checkpoints/rns_linear_eval/p=0/p=0-step=150-train_loss=0.02511.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 286it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2005d15c2b974e71a5a8c50b70afec2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(model,val_dataloader,ckpt_path=ckpt_folder_root+ 'rns_linear_eval/p=0/p=0-step=150-train_loss=0.02511.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:35:56.665922Z",
     "end_time": "2024-04-18T01:35:57.477992Z"
    }
   },
   "outputs": [],
   "source": [
    "output_list = []\n",
    "target_list = []\n",
    "emb_list = []\n",
    "m = nn.Softmax(dim=1)\n",
    "for pred, y, emb in predictions:\n",
    "    output_list.append(pred)\n",
    "    target_list.append(y)\n",
    "    emb_list.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:35:57.478993Z",
     "end_time": "2024-04-18T01:35:58.300329Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_raw = torch.vstack(output_list)\n",
    "target = torch.vstack(target_list)\n",
    "emb = torch.vstack(emb_list)\n",
    "out = torch.argmax(pred_raw, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:35:58.302330Z",
     "end_time": "2024-04-18T01:35:59.101471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.8566652928515822"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(torch.argmax(pred_raw, dim=1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:35:59.103472Z",
     "end_time": "2024-04-18T01:35:59.951211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.924500  0.872484  0.897739     15747\n",
      "           1   0.712156  0.815764  0.760447      6090\n",
      "\n",
      "    accuracy                       0.856665     21837\n",
      "   macro avg   0.818328  0.844124  0.829093     21837\n",
      "weighted avg   0.865281  0.856665  0.859450     21837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report = sklearn.metrics.classification_report(torch.argmax(pred_raw, dim=1), target, digits=6)\n",
    "\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8812383708296269"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(target, m(pred_raw.float())[:,1], pos_label=1)\n",
    "sklearn.metrics.auc(fpr, tpr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:35:59.951211Z",
     "end_time": "2024-04-18T01:36:00.778209Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "split_ind = np.insert(np.where(np.diff(test_index['episode_index'])!=0)[0],0,-1)\n",
    "split_ind = np.insert(split_ind, split_ind.size, len(test_index))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:36:00.781210Z",
     "end_time": "2024-04-18T01:36:01.591309Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "21837"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:36:01.592311Z",
     "end_time": "2024-04-18T01:36:02.391308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "21837"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ind[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:36:02.392309Z",
     "end_time": "2024-04-18T01:36:03.189363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "test_label_split = []\n",
    "pred_label_split = []\n",
    "for i in range(len(split_ind)-1):\n",
    "    start_ind = split_ind[i]\n",
    "    end_ind = split_ind[i+1]\n",
    "    test_label_split.append(test_label[start_ind+1:end_ind+1])\n",
    "    pred_label_split.append(out[start_ind+1:end_ind+1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:36:03.193366Z",
     "end_time": "2024-04-18T01:36:04.009363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label_split[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:36:04.010364Z",
     "end_time": "2024-04-18T01:36:04.779364Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_split[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:36:04.780364Z",
     "end_time": "2024-04-18T01:36:05.582082Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7709923664122137"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score([np.sign(tl.sum()) for tl in test_label_split], [np.sign(tl.sum()) for tl in pred_label_split])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:36:05.585082Z",
     "end_time": "2024-04-18T01:36:06.388262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.4915    0.6591       118\n",
      "         1.0     0.7059    1.0000    0.8276       144\n",
      "\n",
      "    accuracy                         0.7710       262\n",
      "   macro avg     0.8529    0.7458    0.7433       262\n",
      "weighted avg     0.8383    0.7710    0.7517       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report = sklearn.metrics.classification_report([np.sign(tl.sum()) for tl in test_label_split], [np.sign(tl.sum()) for tl in pred_label_split], digits=4)\n",
    "\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:36:06.386262Z",
     "end_time": "2024-04-18T01:36:07.269337Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-17T23:57:54.295411Z",
     "end_time": "2024-04-17T23:57:54.820546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-17T23:39:15.792544Z",
     "end_time": "2024-04-17T23:39:15.806546Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
