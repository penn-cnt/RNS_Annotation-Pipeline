{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T16:52:28.495137Z",
     "end_time": "2023-10-24T16:52:29.375939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T16:52:29.377941Z",
     "end_time": "2023-10-24T16:52:30.013520Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../tools')\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import pytorch_lightning.callbacks as pl_callbacks\n",
    "\n",
    "import data_utility\n",
    "import annotation_utility\n",
    "import interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data_dir = \"../../../user_data/\"\n",
    "log_folder_root = '../../../user_data/logs/'\n",
    "ckpt_folder_root = '../../../user_data/checkpoints/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-24T16:52:30.012520Z",
     "end_time": "2023-10-24T16:52:30.851282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T16:52:30.851282Z",
     "end_time": "2023-10-24T16:52:31.531903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['HUP047',\n 'HUP084',\n 'HUP096',\n 'HUP109',\n 'HUP121',\n 'HUP129',\n 'HUP131',\n 'HUP137',\n 'HUP147',\n 'HUP153',\n 'HUP156',\n 'HUP159',\n 'HUP182',\n 'HUP197',\n 'HUP199',\n 'HUP205',\n 'RNS026',\n 'RNS029']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_annotations = pd.read_csv(data_dir + 'full_updated_anns_annotTbl_cleaned.csv')\n",
    "ids = list(np.unique(raw_annotations[raw_annotations['descriptions'].notnull()]['HUP_ID']))\n",
    "# ids = list(np.unique(raw_annotations['HUP_ID']))\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T16:52:31.532904Z",
     "end_time": "2023-10-24T16:52:51.284886Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:19<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "data_import = data_utility.read_files(path=data_dir + 'rns_data', path_data=data_dir + 'rns_raw_cache', patientIDs=ids,\n",
    "                                      verbose=True)  # Import data with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-24T16:52:51.283885Z",
     "end_time": "2023-10-24T16:52:55.355592Z"
    }
   },
   "outputs": [],
   "source": [
    "annotations = annotation_utility.read_annotation(annotation_path=data_dir + 'full_updated_anns_annotTbl_cleaned.csv',\n",
    "                                                 data=data_import, n_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Dataset  Annotation_Catalog_Index Patient_ID    Alias_ID  Episode_Start_Timestamp  Episode_End_Timestamp  Episode_Start_UTC_Time    Episode_End_UTC_Time  Episode_Index  Episode_Start_Index  Episode_End_Index Annotation_Start_Timestamp Annotation_End_Timestamp     Annotation_Start_UTC_Time       Annotation_End_UTC_Time Annotation_Start_Index Annotation_End_Index Type_Description  Class_Code Annotation_Channel Channel_Code Binary_Channel_Code\n0      RNS_Annotations_JimGugger                         0     HUP096  RNS_1_JiGu         1427397884964000       1427397975128000 2015-03-26 19:24:44.964 2015-03-26 19:26:15.128              5               138107             160647                         []                       []                            []                            []                     []                   []               no           0                 []           []                  []\n1      RNS_Annotations_JimGugger                         1     HUP096  RNS_1_JiGu         1427742903476000       1427742993628000 2015-03-30 19:15:03.476 2015-03-30 19:16:33.628             10               250781             273318                         []                       []                            []                            []                     []                   []               no           0                 []           []                  []\n2      RNS_Annotations_JimGugger                         2     HUP096  RNS_1_JiGu         1427919210984000       1427919301120000 2015-04-01 20:13:30.984 2015-04-01 20:15:01.120             21               498694             521227                         []                       []                            []                            []                     []                   []               no           0                 []           []                  []\n3      RNS_Annotations_JimGugger                         3     HUP096  RNS_1_JiGu         1427963083488000       1427963173624000 2015-04-02 08:24:43.488 2015-04-02 08:26:13.624             22               521228             543761                         []                       []                            []                            []                     []                   []               no           0                 []           []                  []\n4      RNS_Annotations_JimGugger                         4     HUP096  RNS_1_JiGu         1428304634480000       1428304724616000 2015-04-06 07:17:14.480 2015-04-06 07:18:44.616             34               791679             814212                         []                       []                            []                            []                     []                   []               no           0                 []           []                  []\n...                          ...                       ...        ...         ...                      ...                    ...                     ...                     ...            ...                  ...                ...                        ...                      ...                           ...                           ...                    ...                  ...              ...         ...                ...          ...                 ...\n3924  RNS_Annotations_ErinConrad                      3924     HUP199  RNS_3_ErCo         1651096512496000       1651096602516000 2022-04-27 21:55:12.496 2022-04-27 21:56:42.516           2984             66967478           66989982         [1651096537416000]       [1651096592443000]  [2022-04-27 21:55:37.416000]  [2022-04-27 21:56:32.443000]             [66973708]           [66987463]              yes           1              [1,2]       [1110]                  []\n3925  RNS_Annotations_ErinConrad                      3925     HUP199  RNS_3_ErCo         1652403775468000       1652403865392000 2022-05-13 01:02:55.468 2022-05-13 01:04:25.392           3043             68292954           68315434         [1652403775575000]       [1652403851536000]  [2022-05-13 01:02:55.575000]  [2022-05-13 01:04:11.536000]             [68292981]           [68311969]              yes           1              [1,2]       [1110]                  []\n3926  RNS_Annotations_ErinConrad                      3926     HUP199  RNS_3_ErCo         1652901348068000       1652901438044000 2022-05-18 19:15:48.068 2022-05-18 19:17:18.044           3065             68775838           68798331         [1652901376959000]       [1652901437752000]  [2022-05-18 19:16:16.959000]  [2022-05-18 19:17:17.752000]             [68783060]           [68798257]              yes           1              [1,2]       [1110]                  []\n3927  RNS_Annotations_ErinConrad                      3927     HUP199  RNS_3_ErCo         1656740710564000       1656740800640000 2022-07-02 05:45:10.564 2022-07-02 05:46:40.640           3213             72094667           72117185                         []                       []                            []                            []                     []                   []               no           0                 []           []                  []\n3928  RNS_Annotations_ErinConrad                      3928     HUP199  RNS_3_ErCo         1657734176965000       1657734267117000 2022-07-13 17:42:56.965 2022-07-13 17:44:27.117           3251             72950467           72973004                         []                       []                            []                            []                     []                   []               no           0                 []           []                  []\n\n[1401 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Annotation_Catalog_Index</th>\n      <th>Patient_ID</th>\n      <th>Alias_ID</th>\n      <th>Episode_Start_Timestamp</th>\n      <th>Episode_End_Timestamp</th>\n      <th>Episode_Start_UTC_Time</th>\n      <th>Episode_End_UTC_Time</th>\n      <th>Episode_Index</th>\n      <th>Episode_Start_Index</th>\n      <th>Episode_End_Index</th>\n      <th>Annotation_Start_Timestamp</th>\n      <th>Annotation_End_Timestamp</th>\n      <th>Annotation_Start_UTC_Time</th>\n      <th>Annotation_End_UTC_Time</th>\n      <th>Annotation_Start_Index</th>\n      <th>Annotation_End_Index</th>\n      <th>Type_Description</th>\n      <th>Class_Code</th>\n      <th>Annotation_Channel</th>\n      <th>Channel_Code</th>\n      <th>Binary_Channel_Code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RNS_Annotations_JimGugger</td>\n      <td>0</td>\n      <td>HUP096</td>\n      <td>RNS_1_JiGu</td>\n      <td>1427397884964000</td>\n      <td>1427397975128000</td>\n      <td>2015-03-26 19:24:44.964</td>\n      <td>2015-03-26 19:26:15.128</td>\n      <td>5</td>\n      <td>138107</td>\n      <td>160647</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>no</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RNS_Annotations_JimGugger</td>\n      <td>1</td>\n      <td>HUP096</td>\n      <td>RNS_1_JiGu</td>\n      <td>1427742903476000</td>\n      <td>1427742993628000</td>\n      <td>2015-03-30 19:15:03.476</td>\n      <td>2015-03-30 19:16:33.628</td>\n      <td>10</td>\n      <td>250781</td>\n      <td>273318</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>no</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RNS_Annotations_JimGugger</td>\n      <td>2</td>\n      <td>HUP096</td>\n      <td>RNS_1_JiGu</td>\n      <td>1427919210984000</td>\n      <td>1427919301120000</td>\n      <td>2015-04-01 20:13:30.984</td>\n      <td>2015-04-01 20:15:01.120</td>\n      <td>21</td>\n      <td>498694</td>\n      <td>521227</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>no</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RNS_Annotations_JimGugger</td>\n      <td>3</td>\n      <td>HUP096</td>\n      <td>RNS_1_JiGu</td>\n      <td>1427963083488000</td>\n      <td>1427963173624000</td>\n      <td>2015-04-02 08:24:43.488</td>\n      <td>2015-04-02 08:26:13.624</td>\n      <td>22</td>\n      <td>521228</td>\n      <td>543761</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>no</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RNS_Annotations_JimGugger</td>\n      <td>4</td>\n      <td>HUP096</td>\n      <td>RNS_1_JiGu</td>\n      <td>1428304634480000</td>\n      <td>1428304724616000</td>\n      <td>2015-04-06 07:17:14.480</td>\n      <td>2015-04-06 07:18:44.616</td>\n      <td>34</td>\n      <td>791679</td>\n      <td>814212</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>no</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3924</th>\n      <td>RNS_Annotations_ErinConrad</td>\n      <td>3924</td>\n      <td>HUP199</td>\n      <td>RNS_3_ErCo</td>\n      <td>1651096512496000</td>\n      <td>1651096602516000</td>\n      <td>2022-04-27 21:55:12.496</td>\n      <td>2022-04-27 21:56:42.516</td>\n      <td>2984</td>\n      <td>66967478</td>\n      <td>66989982</td>\n      <td>[1651096537416000]</td>\n      <td>[1651096592443000]</td>\n      <td>[2022-04-27 21:55:37.416000]</td>\n      <td>[2022-04-27 21:56:32.443000]</td>\n      <td>[66973708]</td>\n      <td>[66987463]</td>\n      <td>yes</td>\n      <td>1</td>\n      <td>[1,2]</td>\n      <td>[1110]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3925</th>\n      <td>RNS_Annotations_ErinConrad</td>\n      <td>3925</td>\n      <td>HUP199</td>\n      <td>RNS_3_ErCo</td>\n      <td>1652403775468000</td>\n      <td>1652403865392000</td>\n      <td>2022-05-13 01:02:55.468</td>\n      <td>2022-05-13 01:04:25.392</td>\n      <td>3043</td>\n      <td>68292954</td>\n      <td>68315434</td>\n      <td>[1652403775575000]</td>\n      <td>[1652403851536000]</td>\n      <td>[2022-05-13 01:02:55.575000]</td>\n      <td>[2022-05-13 01:04:11.536000]</td>\n      <td>[68292981]</td>\n      <td>[68311969]</td>\n      <td>yes</td>\n      <td>1</td>\n      <td>[1,2]</td>\n      <td>[1110]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3926</th>\n      <td>RNS_Annotations_ErinConrad</td>\n      <td>3926</td>\n      <td>HUP199</td>\n      <td>RNS_3_ErCo</td>\n      <td>1652901348068000</td>\n      <td>1652901438044000</td>\n      <td>2022-05-18 19:15:48.068</td>\n      <td>2022-05-18 19:17:18.044</td>\n      <td>3065</td>\n      <td>68775838</td>\n      <td>68798331</td>\n      <td>[1652901376959000]</td>\n      <td>[1652901437752000]</td>\n      <td>[2022-05-18 19:16:16.959000]</td>\n      <td>[2022-05-18 19:17:17.752000]</td>\n      <td>[68783060]</td>\n      <td>[68798257]</td>\n      <td>yes</td>\n      <td>1</td>\n      <td>[1,2]</td>\n      <td>[1110]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3927</th>\n      <td>RNS_Annotations_ErinConrad</td>\n      <td>3927</td>\n      <td>HUP199</td>\n      <td>RNS_3_ErCo</td>\n      <td>1656740710564000</td>\n      <td>1656740800640000</td>\n      <td>2022-07-02 05:45:10.564</td>\n      <td>2022-07-02 05:46:40.640</td>\n      <td>3213</td>\n      <td>72094667</td>\n      <td>72117185</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>no</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3928</th>\n      <td>RNS_Annotations_ErinConrad</td>\n      <td>3928</td>\n      <td>HUP199</td>\n      <td>RNS_3_ErCo</td>\n      <td>1657734176965000</td>\n      <td>1657734267117000</td>\n      <td>2022-07-13 17:42:56.965</td>\n      <td>2022-07-13 17:44:27.117</td>\n      <td>3251</td>\n      <td>72950467</td>\n      <td>72973004</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>no</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>1401 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.annotations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-24T16:53:04.596008Z",
     "end_time": "2023-10-24T16:53:05.458793Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-25T11:12:56.624086Z",
     "end_time": "2023-10-25T11:12:57.335941Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "annot = annotations.annotations\n",
    "annot_nonseizure = annot[annot['Class_Code'] == 0]\n",
    "annot_seizure = annot[annot['Class_Code'] == 1]\n",
    "patient_list = list(np.unique(annot['Patient_ID']))\n",
    "# patient_list = ['RNS026', 'HUP159', 'HUP129', 'HUP096', 'HUP182']\n",
    "clip_dict = {}\n",
    "for p in patient_list:\n",
    "    seizure_start_index = np.array([])\n",
    "    seizure_end_index = np.array([])\n",
    "    nonseizure_start_index = np.array([])\n",
    "    nonseizure_end_index = np.array([])\n",
    "    global_episode_index_seizure = np.array([])\n",
    "    global_episode_index_nonseizure = np.array([])\n",
    "    start_index = annot_seizure[annot_seizure['Patient_ID'] == p]['Episode_Start_Index']\n",
    "    end_index = annot_seizure[annot_seizure['Patient_ID'] == p]['Episode_End_Index']\n",
    "    annot_start_list = annot_seizure[annot_seizure['Patient_ID'] == p]['Annotation_Start_Index']\n",
    "    annot_end_list = annot_seizure[annot_seizure['Patient_ID'] == p]['Annotation_End_Index']\n",
    "    episode_index = annot_seizure[annot_seizure['Patient_ID'] == p]['Episode_Index']\n",
    "\n",
    "    # print(start_index)\n",
    "    # print(episode_index.index)\n",
    "    # break\n",
    "    # print(np.vstack((annot_start_list, annot_end_list)))\n",
    "    for i, slel in enumerate(zip(annot_start_list, annot_end_list, episode_index.index)):\n",
    "        sl = slel[0]\n",
    "        el = slel[1]\n",
    "        ei = slel[2]\n",
    "\n",
    "        annot_array = np.vstack((sl, el))\n",
    "        seizure_start_index = np.hstack((seizure_start_index, annot_array[0, :]))\n",
    "        seizure_end_index = np.hstack((seizure_end_index, annot_array[1, :]))\n",
    "\n",
    "        nonseizure_start_index = np.hstack((nonseizure_start_index, start_index.iloc[i]))\n",
    "        nonseizure_end_index = np.hstack((nonseizure_end_index, annot_array[0, 0]))\n",
    "\n",
    "        nonseizure_start_index = np.hstack((nonseizure_start_index, annot_array[1, -1]))\n",
    "        nonseizure_end_index = np.hstack((nonseizure_end_index, end_index.iloc[i]))\n",
    "\n",
    "        if annot_array.shape[1] > 1:\n",
    "            nonseizure_start_index = np.hstack((nonseizure_start_index, annot_array[0, 1:]))\n",
    "            nonseizure_end_index = np.hstack((nonseizure_end_index, annot_array[1, :-1]))\n",
    "\n",
    "        global_episode_index_seizure = np.hstack((global_episode_index_seizure,\n",
    "                                                  np.repeat(ei, len(seizure_start_index) -\n",
    "                                                            len(global_episode_index_seizure))))\n",
    "        global_episode_index_nonseizure = np.hstack((global_episode_index_nonseizure,\n",
    "                                                     np.repeat(ei, len(nonseizure_start_index) -\n",
    "                                                               len(global_episode_index_nonseizure))))\n",
    "\n",
    "    assert len(global_episode_index_nonseizure) == len(nonseizure_start_index)\n",
    "    assert len(global_episode_index_seizure) == len(seizure_start_index)\n",
    "\n",
    "    nonseizure_valid = np.where(nonseizure_end_index - nonseizure_start_index > 500)\n",
    "    seizure_valid = np.where(seizure_end_index - seizure_start_index > 500)\n",
    "\n",
    "    nonseizure_ind_arr = np.vstack(\n",
    "        [nonseizure_start_index[nonseizure_valid],\n",
    "         nonseizure_end_index[nonseizure_valid],\n",
    "         global_episode_index_nonseizure[nonseizure_valid]]).astype(int)\n",
    "\n",
    "    seizure_ind_arr = np.vstack(\n",
    "        [seizure_start_index[seizure_valid],\n",
    "         seizure_end_index[seizure_valid],\n",
    "         global_episode_index_seizure[seizure_valid]]).astype(int)\n",
    "\n",
    "    # print(nonseizure_ind_arr)\n",
    "    # print(seizure_ind_arr)\n",
    "\n",
    "    start_index = annot_nonseizure[annot_nonseizure['Patient_ID'] == p]['Episode_Start_Index']\n",
    "    end_index = annot_nonseizure[annot_nonseizure['Patient_ID'] == p]['Episode_End_Index']\n",
    "    episode_index = start_index.index\n",
    "\n",
    "    # print(np.vstack((seizure_start_index[seizure_valid], seizure_end_index[seizure_valid])).astype(int).shape)\n",
    "\n",
    "    valid = np.where(end_index - start_index > 500)\n",
    "    nonseizure_ind_arr_eps = np.vstack(\n",
    "        [start_index.iloc[valid],\n",
    "         end_index.iloc[valid],\n",
    "         episode_index[valid]]).astype(int)\n",
    "\n",
    "    if len(valid[0]) or len(nonseizure_valid) > 0:  #len(seizure_valid[0]) > 0:\n",
    "\n",
    "        nonseizure_clip_temp = np.hstack((nonseizure_ind_arr, nonseizure_ind_arr_eps))\n",
    "        nonseizure_clip_label = np.zeros(nonseizure_clip_temp.shape[1]).astype(int)\n",
    "        non_seizure_clip = np.vstack((nonseizure_clip_temp, nonseizure_clip_label))\n",
    "\n",
    "    if len(seizure_valid) > 0:\n",
    "        seizure_clip_temp = np.vstack(\n",
    "            [seizure_start_index[seizure_valid],\n",
    "             seizure_end_index[seizure_valid],\n",
    "             global_episode_index_seizure[seizure_valid]]).astype(int)\n",
    "        seizure_clip_label = np.ones(seizure_clip_temp.shape[1]).astype(int)\n",
    "        seizure_clip = np.vstack((seizure_clip_temp, seizure_clip_label))\n",
    "\n",
    "    combined_clip = np.hstack((seizure_clip, non_seizure_clip))\n",
    "    shuffled_index = np.arange(combined_clip.shape[1])\n",
    "    np.random.shuffle(shuffled_index)\n",
    "\n",
    "    clip_dict[p] = combined_clip[:, shuffled_index]\n",
    "\n",
    "np.save(data_dir + 'rns_test_cache/clip_dict.npy', clip_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "{'HUP047': array([[57433375, 53043952,  7025634, 18723886, 42056632, 37438894,\n         20652231, 57044111, 57058500, 48939023, 39233740,  4047327,\n         15302455, 37496236, 56706802, 53048272, 13513695, 58221940,\n         53754667, 60775207, 36111633, 41455361, 29497099, 33948966,\n         42041175, 33858851, 31655980, 20548452,   193764, 46736197,\n         18066511, 20562135, 21382271, 42253773, 33868563, 62285700,\n         33791289, 30600731, 39713106,  9844232, 16080448, 45196517,\n           189179,  7508985, 13528534, 29993058,  8443128, 60784951,\n           180296, 60717298,  4413657, 57523527, 31663360, 42051016,\n         15437610, 29977900, 58232089, 57537023, 61428515, 25434402,\n         36102833, 17434858, 54656175,  3159938, 21729186, 20539603,\n          6710271, 29399908, 48947309, 61022918, 57838800, 41185051,\n         21378458,  7556712, 33813805, 37428648, 21368763, 20553802,\n         58469682, 29987658, 31648252, 58236150, 12513983,  7541468,\n         45857382, 55489915, 30595747, 39243225, 36775283, 34196792,\n         18075435, 45192229, 27743860, 60723124, 42379221, 27737883,\n         21639115, 17429345, 57906418, 41200297, 37443716, 56143497,\n         33874961, 25241075, 48932455, 62127798,  5217501, 42567031,\n         14823892, 30586253, 42257592, 14595188, 36118775, 11815231,\n         54273039, 57530857, 42243997,  2674246, 18082506, 59874176,\n         45181271, 53033722, 54701251, 27728466, 17420575, 29174702,\n         57748660, 13520388, 39247691, 24533531, 21481422, 37777414,\n         10981286, 60789871, 44257302, 64766937, 57054146, 60707667,\n         28779010, 41194309, 14936486, 21931998],\n        [57455914, 53048272,  7048157, 18746413, 42063704, 37443716,\n         20674754, 57054146, 57066627, 48947309, 39243225,  4069852,\n         15324981, 37518774, 56729341, 53056240, 13520388, 58232089,\n         53777206, 60784951, 36118775, 41477899, 29519626, 33971507,\n         42051016, 33868563, 31663360, 20553802,   202831, 46758722,\n         18075435, 20584662, 21391291, 42257592, 33874961, 62308257,\n         33813804, 30608782, 39735635,  9866773, 16102960, 45203792,\n           193764,  7527975, 13536223, 30000426,  8465652, 60789871,\n           189179, 60723124,  4436182, 57530857, 31670782, 42056632,\n         15460132, 29987658, 58236150, 57546033, 61451071, 25456918,\n         36111633, 17443105, 54678714,  3182458, 21751703, 20548452,\n          6732812, 29414274, 48954974, 61045451, 57861337, 41194309,\n         21382271,  7579233, 33836321, 37438894, 21378458, 20562134,\n         58477336, 29993058, 31655980, 58244458, 12536524,  7556711,\n         45879920, 55512454, 30600731, 39247691, 36797811, 34219316,\n         18082506, 45196517, 27750992, 60730180, 42401740, 27743860,\n         21661633, 17434858, 57928959, 41207580, 37451179, 56166028,\n         33881381, 25263600, 48939023, 62150354,  5236111, 42589557,\n         14846405, 30595747, 42266527, 14617716, 36125363, 11837772,\n         54295578, 57537023, 42253773,  2683861, 18089041, 59896707,\n         45192229, 53043952, 54723786, 27737883, 17429345, 29197226,\n         57771199, 13528534, 39256271, 24556053, 21503940, 37799934,\n         11003827, 60797726, 44279834, 64789493, 57058500, 60717298,\n         28801526, 41200297, 14959013, 21954536],\n        [    1187,     1178,     1111,     1130,     1168,     1161,\n             1133,     1186,     1186,     1177,     1164,     1106,\n             1124,     1162,     1185,     1178,     1120,     1192,\n             1179,     1196,     1159,     1167,     1149,     1157,\n             1168,     1156,     1153,     1131,     1102,     1176,\n             1128,     1132,     1134,     1169,     1156,     1200,\n             1154,     1152,     1165,     1116,     1126,     1174,\n             1102,     1112,     1120,     1150,     1115,     1196,\n             1102,     1195,     1107,     1188,     1153,     1168,\n             1125,     1150,     1192,     1188,     1198,     1144,\n             1159,     1127,     1181,     1105,     1137,     1131,\n             1110,     1148,     1177,     1197,     1190,     1166,\n             1134,     1114,     1155,     1161,     1134,     1131,\n             1193,     1150,     1153,     1192,     1119,     1113,\n             1175,     1183,     1152,     1164,     1160,     1158,\n             1128,     1174,     1145,     1195,     1170,     1145,\n             1136,     1127,     1191,     1166,     1161,     1184,\n             1156,     1143,     1177,     1199,     1108,     1171,\n             1122,     1152,     1169,     1121,     1159,     1118,\n             1180,     1188,     1169,     1104,     1128,     1194,\n             1174,     1178,     1182,     1145,     1127,     1147,\n             1189,     1120,     1164,     1142,     1135,     1163,\n             1117,     1196,     1173,     1201,     1186,     1195,\n             1146,     1166,     1123,     1138],\n        [       0,        1,        0,        0,        0,        1,\n                0,        0,        0,        1,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                0,        0,        1,        1,        0,        0,\n                0,        0,        0,        1,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        0,        0,        0,        0,        1,\n                0,        1,        0,        0,        0,        1,\n                0,        0,        1,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        0,        0,        0,        0,        0,\n                0,        1,        0,        0,        0,        0,\n                0,        0,        1,        1,        0,        0,\n                1,        1,        0,        0,        0,        1,\n                0,        1,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        1,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        1,        0,        0,        0,        0,\n                0,        0,        0,        0,        1,        0,\n                0,        1,        0,        0]]),\n 'HUP084': array([[12510541,  6379914, 90592854, 25182544,  4102460, 20327009,\n         63012791,  2340801, 40262773, 72118005, 47095918, 40267729,\n          7127405, 59361792, 72121902, 23785908, 87289418, 87379911,\n          2328305,  9665517, 39360873, 92801678,  7354774, 12517826,\n         47098297, 87376250,  8755312, 20877529, 81794281, 87393073,\n         22755604, 20372052, 17786753, 12082549, 23402984,  7367427,\n         72135089, 40262120, 73019502, 63029063, 17780466,  3584137,\n         81787042,  7360415, 47112302, 17604018, 77797587,  2335547,\n         17773125, 40307172,  8734496,   995590, 40310001,  9830303,\n         92803159, 31101419, 55531462, 11474261,  9478014,  9823226,\n         87301618, 92819513,  4177243, 55546502, 40374725,  8238876,\n          9672993,  1329499, 12526602, 54633602, 20340697,  9816002,\n         54639358, 49371398,  7352695,  8746040, 87286122,  4850221,\n         81799975, 30470712, 54631255, 63015719, 38707538, 20328635,\n          9658246, 55532587],\n        [12517826,  6402432, 90615395, 25205066,  4120950, 20328635,\n         63015719,  2350838, 40267729, 72121902, 47098297, 40284629,\n          7149927, 59384333, 72135089, 23808438, 87301618, 87393073,\n          2335547,  9672993, 39383397, 92803159,  7359648, 12526602,\n         47112302, 87379911,  8757023, 20900049, 81799975, 87398763,\n         22778124, 20394566, 17795653, 12105067, 23425506,  7375219,\n         72140518, 40262773, 73042043, 63035308, 17786753,  3606654,\n         81794281,  7367427, 47118431, 17626525, 77820128,  2340801,\n         17780466, 40310001,  8746040,  1018115, 40329663,  9838525,\n         92819513, 31123953, 55532587, 11496790,  9500533,  9830303,\n         87308632, 92824185,  4199768, 55553974, 40397254,  8261404,\n          9680771,  1352025, 12533065, 54639358, 20349528,  9823226,\n         54653767, 49393927,  7354774,  8755312, 87289418,  4872752,\n         81809551, 30493229, 54633602, 63029063, 38730076, 20340697,\n          9665517, 55546502],\n        [    1928,     1917,     1958,     1938,     1914,     1932,\n             1951,     1912,     1943,     1952,     1946,     1943,\n             1918,     1950,     1952,     1937,     1956,     1957,\n             1912,     1923,     1942,     1959,     1919,     1928,\n             1946,     1957,     1921,     1934,     1955,     1957,\n             1935,     1933,     1930,     1927,     1936,     1919,\n             1952,     1943,     1953,     1951,     1930,     1913,\n             1955,     1919,     1946,     1929,     1954,     1912,\n             1930,     1944,     1921,     1910,     1944,     1925,\n             1959,     1940,     1949,     1926,     1922,     1925,\n             1956,     1959,     1915,     1949,     1945,     1920,\n             1923,     1911,     1928,     1948,     1932,     1925,\n             1948,     1947,     1919,     1921,     1956,     1916,\n             1955,     1939,     1948,     1951,     1941,     1932,\n             1923,     1949],\n        [       0,        0,        0,        0,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                0,        0,        1,        0,        1,        1,\n                0,        1,        0,        0,        1,        1,\n                1,        0,        0,        0,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        1,        0,\n                0,        1,        0,        0,        0,        1,\n                0,        0,        0,        0,        1,        0,\n                1,        0,        0,        0,        0,        1,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        1,        0,        0,\n                0,        0,        0,        1,        0,        0,\n                0,        0,        0,        1,        0,        1,\n                0,        1]]),\n 'HUP096': array([[45488202, 27562055, 62594004, 20338919, 25781253, 13870413,\n         38545250, 40218557, 29616073, 12501801, 11555424, 22783626,\n         41025527, 20689275,  8312266, 25037782, 14060828, 62589134,\n          7598797, 24450741,  6538022,  6109850, 56819032, 15909503,\n         60510526, 25482886, 61484514, 11192081, 60521477, 15503884,\n         52007603, 29100197, 53558172,  6718300, 53107884,  3954155,\n         34372979, 40211266, 60505974,  5455312, 13960548, 13976421,\n         12486402, 34363540, 27544769, 20236600, 48104601, 15919893,\n         18154251, 20349373, 14067174, 33240640,  2827089, 23154455,\n         47168808, 35456129, 61474838, 16401002, 14050623, 16390505,\n         52017965, 25465814, 26255315, 59282587, 62038111,   521228,\n         25798055, 41409851, 62052423, 18161123, 34354325, 58889189,\n         35464392,  8387442, 25048216, 49196571, 20226279, 22105720,\n         23452869, 20242553, 62048274, 33260774, 25789558, 22096165,\n          8403893, 36679322, 33251139, 18145323,  6125016, 59272171,\n         58088385, 50422916, 29115829, 44439830, 59920193, 11550041,\n         48114873, 41399354, 48120194, 20706004, 45481963, 20699400,\n         50725192, 52390625, 34432310,  8393856, 22794034, 39308211,\n          2832322, 33655837, 50718204,  8297349, 27101033, 27539342,\n         31428937, 34421909, 39325376, 32249256, 62578772, 27111541,\n         13879477, 29921013, 52761628, 26244825, 24467317, 47789147,\n         29110045, 41376834, 24461220, 29605601, 27551547, 40206528,\n         38560116, 41397920, 50733111, 23447112, 33621243, 60145536,\n         50402830,   498694, 26260921,   791679,  6605625, 52023142,\n          3087549, 16405458,   250781, 58905197, 13885617, 55563388,\n         29622561, 58899641, 49203083,  4388705, 36662219, 58077915,\n          5943218, 61490756, 13971011, 61993040, 36672664, 41032604,\n         50413372,   138107,  6119270, 27529030,  2817274, 27116425,\n          5083254, 28581909, 12490945, 23436882, 41386386, 52751194,\n         49186065, 15514328, 35445675, 25054259, 15925454, 39318389,\n         34438682, 59292112, 56802501, 56809272, 22800593,  5988275,\n          5320132, 20353615, 47158266, 58093219,  6740822, 47174491,\n          8305386, 22085686, 11539990,  4835329, 33626234, 23144047,\n         41418675, 41016296, 62488627, 23160212, 27567750, 11196786,\n         25476176, 38555553, 45471609, 33610798,  3864075, 32654800,\n          3245143, 11181530, 52771514,  8702900],\n        [45494127, 27567750, 62601294, 20349373, 25789558, 13879477,\n         38555553, 40224642, 29622561, 12508907, 11562516, 22794034,\n         41032604, 20699400,  8319868, 25048216, 14067174, 62594004,\n          7621338, 24461220,  6560557,  6119270, 56825017, 15919893,\n         60521477, 25488334, 61490756, 11196786, 60528499, 15514328,\n         52017965, 29110045, 53580713,  6740821, 53130425,  3976686,\n         34376839, 40218557, 60510526,  5470057, 13971011, 13983063,\n         12490945, 34372979, 27551546, 20242553, 48114873, 15925454,\n         18161123, 20353615, 14073142, 33251139,  2832322, 23160212,\n         47174491, 35464392, 61484514, 16405458, 14060828, 16401002,\n         52023142, 25476176, 26260921, 59292112, 62048274,   543761,\n         25803762, 41418675, 62060630, 18167839, 34363540, 58899641,\n         35468193,  8393856, 25054259, 49203083, 20236600, 22108201,\n         23459400, 20248801, 62052423, 33263158, 25798055, 22105720,\n          8409961, 36684732, 33260774, 18154251,  6132377, 59282587,\n         58093219, 50425350, 29122717, 44462363, 59942731, 11555424,\n         48120194, 41409851, 48127125, 20711791, 45488202, 20706004,\n         50733111, 52413155, 34438682,  8403893, 22800593, 39318389,\n          2839793, 33678357, 50725192,  8305386, 27111541, 27544769,\n         31451461, 34432310, 39330732, 32271788, 62589134, 27116425,\n         13885617, 29943554, 52771514, 26255315, 24473261, 47811688,\n         29115829, 41386386, 24467317, 29616073, 27562055, 40211266,\n         38567769, 41399353, 50740720, 23452869, 33626234, 60168077,\n         50413372,   521227, 26267340,   814212,  6628159, 52030120,\n          3110053, 16413027,   273318, 58911696, 13892934, 55585920,\n         29628117, 58905197, 49208582,  4411211, 36672664, 58088385,\n          5965743, 61497345, 13976421, 62015571, 36679322, 41038806,\n         50422916,   160647,  6125016, 27539342,  2827089, 27123557,\n          5105790, 28604432, 12501801, 23447112, 41397920, 52761628,\n         49196571, 15526396, 35456129, 25060303, 15932023, 39325376,\n         34444426, 59294692, 56809272, 56819032, 22806147,  6010812,\n          5342660, 20361443, 47168808, 58100433,  6763356, 47180788,\n          8312266, 22096165, 11550041,  4857869, 33633316, 23154455,\n         41421878, 41025527, 62511159, 23166568, 27574063, 11204050,\n         25482886, 38560116, 45481963, 33621243,  3886572, 32677341,\n          3267661, 11192081, 52773712,  8725441],\n        [      75,       53,       99,       39,       49,       31,\n               68,       70,       56,       30,       29,       43,\n               71,       41,       24,       47,       33,       99,\n               23,       46,       19,       18,       88,       35,\n               94,       48,       95,       28,       94,       34,\n               82,       55,       86,       21,       85,       10,\n               64,       70,       94,       15,       32,       32,\n               30,       64,       52,       38,       78,       35,\n               37,       39,       33,       61,        6,       44,\n               76,       66,       95,       36,       33,       36,\n               82,       48,       50,       91,       97,        3,\n               49,       73,       97,       37,       64,       90,\n               66,       26,       47,       79,       38,       42,\n               45,       38,       97,       61,       49,       42,\n               26,       67,       61,       37,       18,       91,\n               89,       80,       55,       74,       92,       29,\n               78,       73,       78,       41,       75,       41,\n               81,       83,       65,       26,       43,       69,\n                6,       63,       81,       24,       51,       52,\n               58,       65,       69,       59,       99,       51,\n               31,       57,       84,       50,       46,       77,\n               55,       72,       46,       56,       53,       70,\n               68,       72,       81,       45,       62,       93,\n               80,        2,       50,        4,       20,       82,\n                7,       36,        1,       90,       31,       87,\n               56,       90,       79,       11,       67,       89,\n               16,       95,       32,       96,       67,       71,\n               80,        0,       18,       52,        6,       51,\n               13,       54,       30,       45,       72,       84,\n               79,       34,       66,       47,       35,       69,\n               65,       91,       88,       88,       43,       17,\n               14,       39,       76,       89,       22,       76,\n               24,       42,       29,       12,       62,       44,\n               73,       71,       98,       44,       53,       28,\n               48,       68,       75,       62,        9,       60,\n                8,       28,       84,       27],\n        [       0,        1,        0,        0,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                1,        0,        0,        0,        1,        1,\n                0,        0,        0,        0,        0,        0,\n                1,        0,        1,        1,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        1,        0,        0,        0,        0,\n                0,        1,        0,        1,        0,        1,\n                1,        1,        0,        0,        1,        1,\n                1,        1,        0,        1,        0,        0,\n                1,        0,        1,        1,        0,        0,\n                0,        1,        0,        0,        0,        0,\n                0,        0,        1,        1,        0,        0,\n                0,        0,        1,        0,        1,        1,\n                0,        0,        1,        0,        0,        0,\n                1,        0,        0,        0,        0,        1,\n                1,        0,        0,        0,        1,        1,\n                1,        0,        1,        1,        1,        0,\n                0,        0,        0,        0,        0,        1,\n                0,        0,        0,        0,        0,        1,\n                1,        0,        1,        0,        0,        0,\n                1,        0,        1,        0,        0,        0,\n                0,        0,        0,        1,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        1,        0,        0,        0,        0,\n                0,        0,        1,        0,        1,        0,\n                1,        0,        1,        0,        0,        0,\n                0,        0,        1,        0,        1,        0,\n                0,        1,        0,        0,        0,        1,\n                0,        0,        0,        1,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        1,        0,        0,        0,        0,\n                0,        0,        0,        0]]),\n 'HUP109': array([[14805525,  1740801,  8956136, 16643319, 16639902,    45025,\n           563123, 14783124,  4294325,  4319561,  7955220,  3906764,\n          4514632,  1959965, 18757821,        0,  8142774,  4141806,\n           698197,  7443662,  8277125,  1896202,  2011046, 15980710,\n          7939204,  3921358,  8570044, 10637009, 18762444,  1968383,\n          5032772,  4520412,  8160871, 18776676, 14806520,  8970120,\n          4222004, 10665117,  7466124,  1599600,  4507965,   566930,\n         13571490, 17112951,   579143,  9035616,  8517788, 16324953,\n          4206105,  4237382,  7945166, 10622653, 14894994, 10668302,\n          1912136,    50955,  4131978,  4289537,  8598555,  8592547,\n           703822,   715367,  1605278,  4151052,  4627208, 17202980,\n          7467467,  8141958,  2005001, 12557692,  8950573,  3907905,\n          8574057, 15433869, 19073244,  6835236, 14891206, 15964088,\n         10620111,  4312049,  1734769, 16661592,  8608559, 13573126,\n          4199475, 14801385,  1978470,  3050564,  9018310,  8586991,\n          7460968,  8502509,  7484612,  4329033,  4492118,  4304313,\n          4498134, 14422711, 15432019,  1892395, 19090813, 15970347,\n             6076,  4216805],\n        [14806520,  1757275,  8970120, 16661592, 16643319,    50955,\n           566930, 14801385,  4304313,  4329033,  7961709,  3907905,\n          4520412,  1968383, 18762444,     6076,  8160871,  4151052,\n           703822,  7460968,  8299666,  1912136,  2027503, 15986595,\n          7945166,  3929268,  8574057, 10642617, 18776676,  1978470,\n          5055313,  4537116,  8164470, 18780326, 14828009,  8973074,\n          4237382, 10668302,  7467467,  1605278,  4514631,   579143,\n         13573126, 17135441,   585637,  9040591,  8524965, 16347031,\n          4216805,  4244493,  7955220, 10637009, 14913250, 10687607,\n          1914912,    67523,  4141806,  4294325,  8608559,  8598555,\n           715367,   720712,  1622106,  4154468,  4649734, 17225518,\n          7484612,  8142774,  2011046, 12580233,  8956136,  3921358,\n          8586991, 15454517, 19090813,  6857777, 14894994, 15970347,\n         10622653,  4319561,  1740801, 16662401,  8615059, 13593967,\n          4206105, 14805524,  1982485,  3073105,  9035616,  8592546,\n          7466123,  8517788,  7488624,  4334552,  4498134,  4312048,\n          4507965, 14445249, 15433869,  1896202, 19095741, 15980710,\n            22513,  4221979],\n        [    2441,     2409,     2433,     2446,     2446,     2405,\n             2406,     2440,     2418,     2419,     2427,     2414,\n             2421,     2411,     2449,     2404,     2428,     2415,\n             2407,     2425,     2429,     2410,     2412,     2444,\n             2427,     2414,     2431,     2435,     2449,     2411,\n             2423,     2421,     2428,     2449,     2441,     2433,\n             2417,     2436,     2426,     2408,     2420,     2406,\n             2438,     2447,     2406,     2434,     2430,     2445,\n             2416,     2417,     2427,     2435,     2442,     2436,\n             2410,     2405,     2415,     2418,     2432,     2432,\n             2407,     2407,     2408,     2415,     2422,     2448,\n             2426,     2428,     2412,     2437,     2433,     2414,\n             2431,     2443,     2450,     2424,     2442,     2444,\n             2435,     2419,     2409,     2446,     2432,     2438,\n             2416,     2440,     2411,     2413,     2434,     2431,\n             2425,     2430,     2426,     2419,     2420,     2418,\n             2420,     2439,     2443,     2410,     2450,     2444,\n             2404,     2416],\n        [       0,        1,        1,        1,        0,        0,\n                0,        1,        1,        1,        0,        0,\n                0,        0,        0,        0,        1,        1,\n                0,        1,        0,        1,        1,        0,\n                0,        0,        0,        0,        1,        1,\n                0,        1,        0,        0,        1,        0,\n                1,        0,        0,        0,        0,        1,\n                0,        1,        0,        0,        0,        1,\n                1,        0,        1,        1,        1,        1,\n                0,        1,        0,        0,        1,        0,\n                1,        0,        1,        0,        0,        0,\n                1,        0,        0,        0,        0,        1,\n                1,        1,        1,        0,        0,        0,\n                0,        0,        0,        0,        0,        1,\n                0,        0,        0,        0,        1,        0,\n                0,        1,        0,        0,        0,        0,\n                1,        0,        0,        0,        0,        1,\n                1,        0]]),\n 'HUP121': array([[50995249,   692652, 46150831, 23805233, 15378183, 45642643,\n          9448024, 29828600, 13352680, 25823992,  5367175,  7859267,\n         31566454, 28038555, 35259924, 38927012,  7249461,  3057322,\n         51402381, 45471048, 46840476,  9267762, 21650216,  9988791,\n          1640013, 50501685, 11131409, 16963249, 33757635, 15073733,\n         33673634,  2471590,  3169973,  1635569,  1776877, 41826042,\n         24152637, 44302884,  1771043,  5772080, 21084795, 28886364,\n         13221153, 45546316,  1761015, 10816007, 46325665, 14648050,\n          7254783, 39982577, 34755350, 16620884,  1165872, 11118921,\n         14360192,  6312876, 32776919,  9628287,  1625846, 28551756,\n          7746600,   592884, 29858705, 25030519, 13510411, 39599258,\n         11028793, 24481188, 40852495, 48935447, 22974856, 38380463,\n          4220857, 42970194, 32233092,   737731, 22529744, 38832905,\n          6290342, 33293313,  7237136, 36383248, 43717604, 27814924,\n         50935023, 18806436,  1255995, 25796893, 49298067, 43099721,\n         51040416, 42744697, 52564546,   782815,  7656475, 44975021,\n         51219640,   277328, 24030934, 11135229, 10053343, 52508615,\n         27962736,  3845735,  3868265, 48273046, 51055473],\n        [51010303,   715193, 46165892, 23820290, 15400724, 45657708,\n          9470555, 29843655, 13375221, 25835735,  5389709,  7881800,\n         31581444, 28053611, 35274972, 38942067,  7254783,  3079849,\n         51415376, 45486100, 46855529,  9290293, 21665262, 10011332,\n          1648374, 50507927, 11135229, 16985790, 33763877, 15096261,\n         33688679,  2494107,  3192499,  1640013,  1783542, 41841088,\n         24160626, 44317934,  1776877,  5794614, 21099839, 28901416,\n         13243681, 45561381,  1771043, 10838548, 46337903, 14664540,\n          7259670, 39997633, 34770399, 16643417,  1188413, 11131409,\n         14382733,  6335417, 32788286,  9650828,  1635569, 28566805,\n          7769138,   615425, 29873757, 25045570, 13532935, 39608125,\n         11051334, 24496236, 40867551, 48950501, 22981351, 38395519,\n          4243391, 42985235, 32248150,   760272, 22544793, 38840026,\n          6312875, 33308362,  7249461, 36398304, 43732661, 27829977,\n         50950079, 18828961,  1278536, 25808387, 49313123, 43106093,\n         51055472, 42759743, 52579585,   805352,  7679002, 44990064,\n         51234681,   299869, 24037174, 11141453, 10075871, 52523655,\n         27977789,  3868264,  3890793, 48288102, 51070528],\n        [    1578,     1488,     1570,     1531,     1523,     1569,\n             1510,     1543,     1518,     1537,     1501,     1508,\n             1545,     1540,     1552,     1556,     1505,     1496,\n             1582,     1567,     1572,     1509,     1528,     1512,\n             1493,     1576,     1516,     1525,     1550,     1522,\n             1549,     1495,     1497,     1493,     1494,     1560,\n             1533,     1565,     1494,     1502,     1527,     1542,\n             1517,     1568,     1494,     1514,     1571,     1521,\n             1505,     1558,     1551,     1524,     1491,     1516,\n             1520,     1504,     1547,     1511,     1493,     1541,\n             1507,     1487,     1544,     1535,     1519,     1557,\n             1515,     1534,     1559,     1574,     1530,     1554,\n             1500,     1562,     1546,     1489,     1529,     1555,\n             1503,     1548,     1505,     1553,     1564,     1538,\n             1577,     1526,     1492,     1536,     1575,     1563,\n             1579,     1561,     1584,     1490,     1506,     1566,\n             1581,     1486,     1532,     1516,     1513,     1583,\n             1539,     1498,     1499,     1573,     1580],\n        [       0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                0,        0,        0,        1,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0]]),\n 'HUP129': array([[23631734, 24417769, 23048132, 15200969,  2227424,  2340057,\n         11457437,  3128318,  6894410, 26988417,   620316, 27699634,\n         19055336, 24409796, 20115777,  9625507, 31086624, 23855582,\n         27737422,  6308754, 25424947,  6781712, 12456304, 22722400,\n         32789722,  9510731,  2234693,  9603000,  2227424,   935899,\n         23630278, 28730961,  4509215, 18956820, 19603534, 22999672,\n          7104365,  9503366, 17823898,  2347293, 10745493, 27692354,\n         23326515,  7104458,  4802779,  4757772,   641851, 22007885,\n          9610880,  1871670, 22730309,  4802779,  8468563, 27647347,\n         13175363, 21528050,  7097154, 31043669, 26567051,  9457758,\n          7807187,  7113067, 19598262, 20654135,  3128318, 28212532,\n         32686902, 32820113, 15094161, 11917627,  3542009, 13017626,\n          6901670,  7112960, 20660380,   258280, 17777796, 25828288,\n          2572518,   249949, 11712825, 13854566,   942297,  6579090,\n           625186, 21025205, 25430098,  4493416, 15095743,  4487479,\n          6910820, 20439517,  2585835,  6586321,  4825313, 12449844,\n          7097154, 23332339, 25441902, 26560197, 27654550, 33393329,\n         20025621, 25553786,  9623751, 21535854, 11910334,  2234637,\n         13182607, 11447813,  4284756, 22992813,  2565279,  6781712,\n         17769725,  3533740,  4291631,  3553385, 32694766,  9450478,\n          6315688,  4832612, 16782906, 28809622, 23303973,   935892,\n         18964064,  4832568,  4764820, 26996298, 17016692,  8851654,\n          1871670,  4825313, 25546672,   940424, 23886991, 32797382,\n         16858945, 32823999, 31095937, 31033631],\n        [23652674, 24432278, 23055980, 15223510,  2234693,  2347293,\n         11458727,  3150793,  6901670, 26996298,   625186, 27714866,\n         19077877, 24417769, 20138318,  9648039, 31095937, 23864473,\n         27746044,  6315688, 25430098,  6804245, 12459107, 22730309,\n         32797382,  9525864,  2249918,  9610880,  2234637,   942297,\n         23631734, 28742055,  4509971, 18964064, 19620752, 23015351,\n          7112960,  9510731, 17846427,  2362510, 10753594, 27699634,\n         23332339,  7113067,  4825312,  4764820,   642844, 22016114,\n          9623751,  1894211, 22744901,  4825312,  8491104, 27654550,\n         13182607, 21535854,  7104458, 31056103, 26582690,  9472982,\n          7829728,  7119665, 19603534, 20660380,  3150793, 28235073,\n         32694766, 32823999, 15095743, 11932854,  3553385, 13040139,\n          6910820,  7119665, 20664645,   272436, 17792216, 25850825,\n          2585835,   258280, 11722309, 13877107,   946434,  6586321,\n           641851, 21033593, 25441902,  4509215, 15116744,  4493416,\n          6916918, 20450982,  2587776,  6601583,  4832612, 12456304,\n          7104365, 23348999, 25447441, 26567051, 27669787, 33415431,\n         20048162, 25557783,  9625506, 21550501, 11917627,  2249918,\n         13197876, 11457437,  4291631, 22999672,  2572518,  6804245,\n         17777796,  3542009,  4307069,  3556247, 32709303,  9457758,\n          6331232,  4847808, 16805447, 28832082, 23326514,   940424,\n         18979331,  4847805,  4780268, 27010986, 17039229,  8862181,\n          1894211,  4832568, 25553786,   946434, 23896335, 32812232,\n         16881486, 32829458, 31109143, 31043669],\n        [    3634,     3639,     3631,     3609,     3505,     3564,\n             3598,     3507,     3576,     3645,     3560,     3647,\n             3618,     3639,     3622,     3585,     3653,     3635,\n             3648,     3573,     3640,     3575,     3602,     3629,\n             3655,     3583,     3505,     3584,     3563,     3561,\n             3634,     3650,     3569,     3617,     3620,     3630,\n             3511,     3583,     3615,     3564,     3596,     3647,\n             3633,     3577,     3508,     3570,     3560,     3627,\n             3584,     3562,     3629,     3571,     3580,     3646,\n             3604,     3626,     3577,     3652,     3643,     3582,\n             3578,     3577,     3620,     3624,     3566,     3649,\n             3654,     3656,     3607,     3601,     3567,     3603,\n             3576,     3511,     3624,     3559,     3614,     3642,\n             3565,     3559,     3599,     3605,     3561,     3574,\n             3560,     3625,     3640,     3569,     3607,     3569,\n             3576,     3623,     3565,     3574,     3509,     3602,\n             3511,     3633,     3640,     3643,     3646,     3657,\n             3621,     3641,     3584,     3626,     3601,     3563,\n             3604,     3598,     3568,     3630,     3565,     3510,\n             3614,     3567,     3568,     3567,     3654,     3582,\n             3573,     3509,     3611,     3651,     3632,     3503,\n             3617,     3572,     3570,     3645,     3613,     3581,\n             3504,     3572,     3641,     3503,     3636,     3655,\n             3612,     3656,     3653,     3652],\n        [       1,        1,        1,        0,        0,        0,\n                0,        0,        0,        0,        0,        1,\n                0,        0,        0,        0,        0,        1,\n                1,        0,        0,        0,        0,        0,\n                0,        1,        1,        0,        0,        1,\n                0,        1,        0,        0,        1,        1,\n                1,        0,        0,        1,        0,        0,\n                0,        1,        0,        0,        0,        1,\n                1,        0,        1,        0,        0,        0,\n                0,        0,        0,        1,        1,        1,\n                0,        0,        0,        1,        0,        0,\n                0,        1,        0,        1,        1,        0,\n                1,        0,        0,        1,        1,        0,\n                1,        0,        1,        0,        0,        0,\n                1,        1,        1,        1,        1,        0,\n                0,        1,        0,        1,        0,        1,\n                0,        1,        0,        0,        1,        1,\n                0,        0,        0,        1,        0,        1,\n                1,        1,        0,        0,        0,        0,\n                0,        0,        1,        0,        1,        0,\n                1,        1,        0,        1,        0,        1,\n                1,        1,        1,        1,        0,        1,\n                0,        0,        1,        0,        1,        1,\n                0,        0,        1,        0]]),\n 'HUP131': array([[79238511, 62165830, 10474309, 50259839, 67907458, 67890288,\n          5922348, 42266876, 71436480, 55063474,  5854753, 11906413,\n         58171531,  8155959, 40262504, 89127141, 46670939, 79013183,\n         62157103,  9424195, 11132183, 65777468, 58687684,  7621421,\n         65784918, 91621119,  6582700, 54018259,  9934427, 71416803,\n         12514750, 62149749, 43119952, 72791365, 79031306, 64050745,\n         54020152,  6447556,  5752049, 64039217, 41995603, 44631809,\n         58688723, 65795881, 69201034,  3921098, 16846087,  3433827,\n          3914544, 65992856, 44878490, 71423926, 61474925, 92725234,\n         79020167, 64594963, 91620402,  7195581, 58349642, 44649059,\n         79979965, 50277107, 40252669, 41604744, 63791722,  8565421,\n         56753560, 50267497, 66000081,  4714507, 40245555, 66011921,\n          8497864,   128256, 44885735, 58169458, 10378286, 48277072,\n         16531749, 67897338,  4782072, 55716941, 41611596, 44893299,\n         44639891, 52823578, 88632953, 46663760, 90606695, 65902722,\n         64031863, 92736064,  7576383, 92717887, 73547510, 45022844],\n        [79261049, 62172266, 10496816, 50267497, 67912807, 67897338,\n          5944871, 42289414, 71439324, 55086015,  5877278, 11928938,\n         58191961,  8178487, 40268061, 89149657, 46686259, 79020167,\n         62165830,  9434818, 11154701, 65784918, 58688723,  7638412,\n         65795881, 91642913,  6605241, 54020152,  9956940, 71423926,\n         12537263, 62157103, 43142450, 72813906, 79035705, 64054381,\n         54040753,  6470084,  5764667, 64050745, 42018100, 44639891,\n         58710181, 65799990, 69223575,  3937054, 16868607,  3456334,\n          3921098, 66000081, 44885735, 71436480, 61497466, 92736064,\n         79031306, 64617504, 91621119,  7218107, 58372183, 44654321,\n         80002506, 50282358, 40262504, 41611596, 63814263,  8587935,\n         56776101, 50277107, 66011921,  4737029, 40252669, 66015377,\n          8520384,   150790, 44893299, 58171531, 10400814, 48299613,\n         16554264, 67907458,  4804582, 55739426, 41627243, 44900999,\n         44649059, 52846119, 88655464, 46670939, 90629230, 65925263,\n         64039217, 92740409,  7598905, 92725234, 73570051, 45045342],\n        [    1878,     1865,     1805,     1855,     1872,     1872,\n             1793,     1848,     1874,     1858,     1792,     1807,\n             1861,     1799,     1845,     1882,     1853,     1877,\n             1865,     1802,     1806,     1869,     1863,     1798,\n             1869,     1884,     1795,     1857,     1803,     1874,\n             1808,     1865,     1849,     1875,     1877,     1867,\n             1857,     1794,     1791,     1867,     1847,     1850,\n             1863,     1869,     1873,     1788,     1810,     1787,\n             1788,     1871,     1851,     1874,     1864,     1885,\n             1877,     1868,     1884,     1796,     1862,     1850,\n             1879,     1855,     1845,     1846,     1866,     1801,\n             1860,     1855,     1871,     1789,     1845,     1871,\n             1800,     1786,     1851,     1861,     1804,     1854,\n             1809,     1872,     1790,     1859,     1846,     1851,\n             1850,     1856,     1881,     1853,     1883,     1870,\n             1867,     1885,     1797,     1885,     1876,     1852],\n        [       0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        0,        0,        0,        1,        0,\n                1,        1,        0,        0,        0,        0,\n                1,        1,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        0,        0,        1,        0,        0,\n                1,        0,        0,        1,        0,        0,\n                0,        0,        0,        1,        0,        1,\n                1,        0,        0,        0,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                0,        1,        1,        0,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                0,        1,        0,        1,        1,        0,\n                1,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0]]),\n 'HUP137': array([[12872739, 66764272, 36348757, 61171310, 61500507, 16080888,\n         45892256,  9933497, 73049920,  9293951, 37675587, 37770480,\n         71160098, 36336064, 17544943, 63213122, 64600938, 27925678,\n         47793116, 72426594, 19193545, 61685514, 17549543, 58903074,\n         66888273, 38270163, 64606706, 41931366, 71048454, 62512812,\n          2263121, 13886370, 64619255,  3492381, 63227823, 26248583,\n         46178484, 33179134, 20004418, 35746660, 48715653, 56679299,\n         75239767, 11343591, 71032837, 61331785, 44039089, 38266084,\n         61325084, 68726816, 37657853,  7329264, 49873970, 33833256,\n         56660242, 16095199, 61167377, 45640658, 73094961, 23108706,\n         44036062, 13900467, 10803234, 61485714, 68730146, 58899270,\n         69861488, 33820475, 19988897, 75740014, 27024591, 30174446,\n         41800649, 10407585, 62701470, 10633381, 66870717, 44050801,\n         45648035, 72437998, 23094450, 13953937, 75232101, 35679129,\n         12877821, 41913240, 26256921, 71150575, 72042121, 57493733,\n         31444580, 58916718,  3479691, 12889378, 27031645, 41920599,\n          6259964, 41807812, 62136035, 68740093, 31907180, 13958034,\n         69034362, 10642186, 73063684, 41778110, 48108370,  4714199,\n         75246409,  6871039, 19983243, 15968255, 13974078, 66606079,\n         12460082, 47928209,  7163787, 43833563, 61708056, 26602858,\n         61181474, 45875930, 30192180, 43788510, 11863589, 45880294,\n         71039232, 45386761, 73057713, 63216659, 11276042, 19175953,\n         61482752, 26850613, 26269376, 38283390, 61341593, 13889720,\n         72054490, 36328794, 43841225, 66595607,  4971004, 59872423,\n         23089121, 27042098, 56667582, 16085431, 66590134,  3472424,\n         45658874, 72419239, 19178534, 51967397, 66877911, 54673741,\n         72036337, 40121609, 71145473, 31436579, 27632766, 33814934,\n         68041961, 30187225, 39378450, 49462443, 10625871,  8117472,\n         49446027, 37663233],\n        [12877821, 66786798, 36351307, 61181474, 61505271, 16085431,\n         45898449,  9956013, 73057713,  9310189, 37680376, 37793021,\n         71168000, 36348757, 17549543, 63216659, 64606706, 27939049,\n         47815623, 72437998, 19198477, 61708055, 17567460, 58916718,\n         66893238, 38283390, 64619255, 41935757, 71055363, 62535320,\n          2285630, 13889720, 64623462,  3494946, 63235646, 26256921,\n         46201003, 33201650, 20005753, 35755149, 48738176, 56682766,\n         75246409, 11366132, 71039232, 61341593, 44050801, 38270163,\n         61331785, 68730146, 37663233,  7351774, 49896511, 33837452,\n         56667582, 16103411, 61171310, 45648035, 73117481, 23111644,\n         44039089, 13908892, 10825747, 61500507, 68740093, 58903074,\n         69884029, 33833256, 20004418, 75762527, 27031645, 30187225,\n         41807812, 10430102, 62723998, 10642186, 66877911, 44058576,\n         45658874, 72441757, 23108706, 13958034, 75239767, 35701639,\n         12889378, 41920599, 26269376, 71160098, 72054490, 57516268,\n         31459088, 58921796,  3492381, 12895261, 27042098, 41931366,\n          6282471, 41823036, 62158576, 68749338, 31929721, 13974078,\n         69056903, 10648394, 73072443, 41800648, 48130901,  4736717,\n         75254615,  6893562, 19988897, 15990771, 13976452, 66612660,\n         12482623, 47950718,  7186303, 43841225, 61730564, 26625367,\n         61189904, 45880294, 30196961, 43811047, 11886102, 45892256,\n         71048454, 45409302, 73063684, 63227823, 11298558, 19178534,\n         61485714, 26873154, 26271096, 38288612, 61347606, 13900467,\n         72058855, 36336064, 43856004, 66606079,  4993517, 59894964,\n         23094450, 27047113, 56679299, 16095199, 66595607,  3479691,\n         45663173, 72426594, 19193545, 51978266, 66888273, 54696256,\n         72042121, 40144150, 71150575, 31444580, 27655307, 33820475,\n         68064486, 30192180, 39400988, 49468521, 10633381,  8139979,\n         49462443, 37675587],\n        [     179,      240,      201,      229,      231,      183,\n              215,      171,      250,      170,      202,      203,\n              247,      201,      184,      237,      238,      193,\n              217,      249,      185,      232,      184,      227,\n              241,      204,      238,      209,      246,      235,\n              161,      180,      238,      162,      237,      188,\n              216,      197,      186,      200,      220,      225,\n              252,      176,      246,      230,      212,      204,\n              230,      243,      202,      168,      222,      198,\n              225,      183,      229,      214,      251,      187,\n              212,      180,      174,      231,      243,      227,\n              245,      198,      186,      253,      191,      194,\n              208,      172,      236,      173,      241,      212,\n              214,      249,      187,      181,      252,      199,\n              179,      209,      188,      247,      248,      226,\n              195,      227,      162,      179,      191,      209,\n              165,      208,      234,      243,      196,      181,\n              244,      173,      250,      207,      219,      163,\n              252,      166,      186,      182,      181,      239,\n              178,      218,      167,      211,      233,      189,\n              229,      215,      194,      210,      177,      215,\n              246,      213,      250,      237,      175,      185,\n              231,      190,      188,      204,      230,      180,\n              248,      201,      211,      239,      164,      228,\n              187,      191,      225,      183,      239,      162,\n              214,      249,      185,      223,      241,      224,\n              248,      206,      247,      195,      192,      198,\n              242,      194,      205,      221,      173,      169,\n              221,      202],\n        [       0,        0,        0,        1,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        1,        0,        0,        0,        0,\n                0,        1,        0,        0,        1,        1,\n                0,        1,        1,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        0,        0,        1,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        1,        1,        0,\n                0,        1,        1,        0,        0,        0,\n                0,        0,        0,        1,        0,        0,\n                1,        0,        1,        0,        0,        0,\n                1,        0,        1,        1,        1,        0,\n                1,        0,        1,        0,        1,        1,\n                0,        1,        0,        0,        0,        1,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        1,\n                1,        0,        1,        1,        0,        0,\n                0,        0,        0,        0,        0,        1,\n                0,        0,        1,        1,        0,        0,\n                0,        0,        1,        1,        0,        0,\n                0,        0,        1,        0,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        1,        0,        1,        0,        0,\n                0,        1]]),\n 'HUP147': array([[ 2165905,  2754775, 33076576, 16710674, 45404065,  3538304,\n          2866086, 47604604,  2851550,  3717989, 23076958, 24956502,\n         15433722,  5164947,  2859580, 16818032, 16808171,  3972506,\n         43060471, 21085044,  3087567, 52464809,  2378397, 24433885,\n         28018407, 11538340, 24152420, 14943535, 32056183, 14954723,\n         30800316, 14914357, 21075919, 13703824, 52471980,  3798428,\n         15291706, 45422004, 16988433, 33087361, 15230994, 28012416,\n         31201663,  3640732,  2851550,  3545058, 34556931, 20392263,\n         29207099, 14905604, 43050709, 23087882, 34572501,  2748251,\n          3956135, 24163031,  5157168,  2748230,  3708329, 28001864,\n         15794214, 30811328,  3819393, 29196173,  2859689,  2866260,\n          5150758, 24168526,  3545120, 30815638,  3730855,  3155109,\n         24941153, 19618666,  2754864,  3956135, 24422815, 15276030,\n         26658552,  5150758,  3746590,  2165905, 26669548, 14898474,\n          2389081, 30159667,  3746552,  3200174,  3808162,  3740576,\n         23091978, 34567814,  3528085, 15238767, 45414489, 29213202,\n          3528085,  3165401, 15906894,  4023734, 33094335,  3200174,\n          3972634, 14958727,  2394705, 32490596, 29060955, 24437997,\n         15246309,  3724482, 16706616,  2932632, 15804940, 52456363,\n          2393568, 29076072, 16222380, 29072086, 16825768,  3965838,\n         27911708, 43067761, 47108855, 15443507, 24951057, 16695519,\n         32050440,  5157199, 31194327,  2927830,  2919023, 31183453,\n          5164938, 21093683, 15809007, 26545900, 49334774,  5195833,\n         12960025,  2378397,  2738902, 22225233,  4023734,  3170319,\n          3843494, 17003350,  3730855,  3740635, 15287209, 15449781,\n         26675397,  6889443, 32039883,  3537781,  5195833,  2387969,\n          2738902, 16999468,  3965832],\n        [ 2188446,  2761432, 33087361, 16718047, 45414489,  3545120,\n          2874081, 47627145,  2859689,  3724482, 23087882, 24963678,\n         15443507,  5173291,  2866086, 16825768, 16818032,  3978663,\n         43067761, 21093683,  3110076, 52471980,  2389081, 24437997,\n         28024390, 11560881, 24163031, 14954723, 32062397, 14958727,\n         30811328, 14920994, 21085044, 13726365, 52478874,  3808162,\n         15298547, 45426576, 16999468, 33094335, 15238767, 28018407,\n         31205971,  3663260,  2859580,  3550608, 34567814, 20414785,\n         29213202, 14914357, 43060471, 23091978, 34579457,  2754864,\n          3965832, 24168526,  5164947,  2754775,  3717989, 28012416,\n         15804940, 30815638,  3820952, 29207099,  2866260,  2874081,\n          5157199, 24174946,  3550608, 30822843,  3740635,  3165401,\n         24951057, 19641191,  2761432,  3965838, 24433885, 15287209,\n         26669548,  5157168,  3753378,  2188446, 26675397, 14905604,\n          2393568, 30182208,  3753378,  3222695,  3819393,  3746552,\n         23099486, 34572501,  3538304, 15246309, 45422004, 29218696,\n          3537781,  3170319, 15929423,  4046258, 33099089,  3222695,\n          3978663, 14966061,  2400920, 32513137, 29072086, 24445343,\n         15253509,  3730854, 16710674,  2941549, 15809007, 52464809,\n          2400920, 29083478, 16244908, 29076072, 16830695,  3972506,\n         27934249, 43073219, 47131396, 15449781, 24956502, 16706616,\n         32056183,  5164938, 31201663,  2932632,  2927830, 31194327,\n          5173291, 21098441, 15816741, 26568427, 49357263,  5218374,\n         12982566,  2387969,  2748230, 22247774,  4046258,  3177640,\n          3866010, 17010960,  3740576,  3746590, 15291706, 15456250,\n         26681069,  6911984, 32050440,  3545058,  5218374,  2394705,\n          2748251, 17003350,  3972634],\n        [    1673,     1592,     1631,     1609,     1635,     1595,\n             1593,     1637,     1676,     1683,     1616,     1619,\n             1605,     1599,     1593,     1610,     1610,     1597,\n             1634,     1614,     1678,     1639,     1591,     1618,\n             1623,     1692,     1617,     1602,     1629,     1602,\n             1627,     1695,     1614,     1694,     1639,     1685,\n             1604,     1635,     1611,     1631,     1603,     1623,\n             1628,     1682,     1593,     1681,     1632,     1613,\n             1625,     1695,     1634,     1616,     1632,     1675,\n             1687,     1617,     1599,     1592,     1683,     1623,\n             1606,     1627,     1685,     1625,     1676,     1676,\n             1689,     1617,     1595,     1627,     1596,     1679,\n             1619,     1612,     1675,     1597,     1618,     1604,\n             1621,     1599,     1596,     1590,     1621,     1695,\n             1591,     1626,     1684,     1680,     1685,     1684,\n             1616,     1632,     1595,     1603,     1635,     1625,\n             1681,     1679,     1607,     1598,     1631,     1594,\n             1687,     1602,     1674,     1630,     1624,     1618,\n             1603,     1683,     1609,     1677,     1606,     1639,\n             1591,     1624,     1608,     1624,     1610,     1597,\n             1622,     1634,     1636,     1605,     1619,     1609,\n             1629,     1689,     1628,     1677,     1677,     1628,\n             1689,     1614,     1606,     1620,     1638,     1600,\n             1693,     1674,     1592,     1615,     1688,     1679,\n             1686,     1611,     1684,     1596,     1604,     1605,\n             1621,     1691,     1629,     1681,     1690,     1674,\n             1675,     1611,     1687],\n        [       0,        0,        0,        0,        0,        1,\n                0,        0,        0,        1,        0,        0,\n                0,        0,        1,        1,        0,        0,\n                1,        1,        0,        1,        0,        1,\n                0,        0,        0,        0,        0,        1,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        1,        0,        1,\n                0,        0,        0,        0,        0,        0,\n                1,        1,        0,        1,        0,        1,\n                0,        1,        1,        1,        0,        0,\n                0,        1,        0,        0,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        1,        0,\n                1,        0,        0,        0,        1,        1,\n                0,        1,        0,        1,        1,        0,\n                0,        1,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        1,        0,        1,        0,\n                0,        0,        0,        1,        0,        1,\n                0,        0,        0,        1,        1,        0,\n                1,        1,        1,        1,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        1,        1,        0,\n                0,        0,        0,        1,        0,        1,\n                0,        1,        1]]),\n 'HUP153': array([], shape=(4, 0), dtype=int32),\n 'HUP156': array([[34251423, 19989045,  8651277, 27360613,  9825077, 20002175,\n         46545441, 47627223, 32673993, 25189498, 18134465,  8178833,\n          8645758, 30851013, 15541682, 18998639, 25235740,  7293421,\n          8217517,  4363611, 16865584,  6346914, 33101188, 16843098,\n         31766747,  2061108, 40781543, 39390383,  4927056,  3945784,\n          5467949, 24514558, 22215678,   602441, 25370924, 10629094,\n          8665882, 36251602, 11282605, 35327632, 42018951, 46562957,\n         29825518, 37544460, 11786674, 33883783, 45387155, 39435621,\n         22919620, 33115861, 22373466, 31675833, 36860155, 28351444,\n         13288647,  1810768, 40789318, 27368833, 36905145, 32698696,\n         45387155, 41164611,  6369411,  1985454, 13609277, 39384213,\n          3089433, 38753173, 38054508, 10336110, 17573053, 12432123,\n         40015198, 41171001, 45394079, 40023400, 24176506, 11778470,\n         31346417, 41344842, 47635489, 32688078,  6982006, 42832396,\n          4348777, 20913278, 17090954, 18119537, 15535863, 31786464,\n         18113911,  2435958, 22931626, 18111918,  9869818, 24182272,\n         25241515, 28335421, 28720767, 39451144, 10636865, 46550286,\n          2052929, 33096463, 28712852, 13625826, 38076107, 38761592,\n         18096701,  2444007, 29817228, 18992826, 14777284,   684557,\n         48483681, 16872708, 19553284, 42835865, 27885363,  5654595,\n          8224852, 38818643, 22914345, 22394512, 47086337,  1518013,\n         33231636, 40871636, 38801886, 45387155,  4948757, 16849534,\n         19533661,  6993799, 14769605, 35333718, 32690854, 25176466,\n          3096751, 13116033, 33862719, 24537054, 31338563,  6376534,\n         31773198, 30842714,   689996,  5648214, 19540358, 24544823,\n         39429246, 28329751, 20908492, 37536199,  6977919, 38798209,\n         41998464,   701941,  4369201, 32826046, 34245847, 35346822,\n         31661891, 25168156, 29456584,  4341113,  8191574, 13108352,\n         24522210, 38212242, 17911133,  9817746, 13604177, 33869083,\n         28149455, 36866425,   595654, 42883558, 38059552, 42004872,\n          4933088,  9862788, 32668355, 13536551, 46387651, 36911602,\n          8172476, 27879023, 42877385, 19984443,  6354290, 22379894,\n         31654096, 18091414],\n        [34268316, 20002175,  8665882, 27368833,  9840219, 20006941,\n         46550286, 47635489, 32688078, 25190658, 18136409,  8191574,\n          8651277, 30865209, 15558355, 19015319, 25241515,  7315962,\n          8224852,  4369201, 16872708,  6354290, 33115861, 16849534,\n         31773198,  2075411, 40789318, 39406699,  4933088,  3968325,\n          5490484, 24522210, 22238219,   618183, 25393465, 10636865,\n          8668253, 36274134, 11305146, 35333718, 42020956, 46567939,\n         29839722, 37558691, 11800963, 33885213, 45394079, 39451144,\n         22931626, 33118953, 22379894, 31676593, 36866425, 28352238,\n         13311188,  1833267, 40804029, 27383102, 36911602, 32713346,\n         45393904, 41171001,  6376534,  2007945, 13625826, 39390383,\n          3096751, 38761592, 38059552, 10358645, 17595588, 12454664,\n         40023400, 41187097, 45396026, 40037695, 24182272, 11786674,\n         31361057, 41367359, 47649720, 32690853,  6993799, 42835865,\n          4363608, 20930980, 17113495, 18134465, 15541682, 31789243,\n         18119537,  2444007, 22936845, 18113910,  9885278, 24198995,\n         25258231, 28351444, 28735344, 39451731, 10651584, 46562957,\n          2061108, 33101188, 28720767, 13626674, 38076995, 38775668,\n         18111918,  2458440, 29825518, 18998639, 14792094,   689996,\n         48506222, 16888078, 19556160, 42854803, 27901029,  5670682,\n          8240010, 38820699, 22919620, 22395957, 47108878,  1540509,\n         33254140, 40894151, 38818643, 45393904,  4949548, 16865579,\n         19540358,  7000428, 14777284, 35346822, 32698696, 25189498,\n          3111909, 13130851, 33869083, 24544823, 31346417,  6391898,\n         31786464, 30851013,   701941,  5654595, 19553284, 24559546,\n         39435621, 28335421, 20913278, 37544460,  6982006, 38801886,\n         42004872,   707062,  4386097, 32848553, 34251423, 35350133,\n         31675833, 25176466, 29479116,  4348777,  8194977, 13116033,\n         24537052, 38234783, 17933671,  9825077, 13609277, 33883783,\n         28171996, 36882641,   602441, 42899864, 38076107, 42018951,\n          4948757,  9869818, 32673993, 13559092, 46410189, 36927625,\n          8178833, 27885363, 42883558, 19989045,  6369401, 22394512,\n         31661891, 18096701],\n        [    2305,     2275,     2251,     2286,     2252,     2275,\n             2327,     2329,     2299,     2283,     2272,     2249,\n             2251,     2295,     2265,     2273,     2284,     2248,\n             2250,     2241,     2267,     2245,     2302,     2266,\n             2298,     2236,     2318,     2315,     2242,     2239,\n             2243,     2281,     2277,     2231,     2285,     2255,\n             2251,     2307,     2256,     2306,     2322,     2327,\n             2292,     2310,     2257,     2304,     2325,     2316,\n             2279,     2302,     2278,     2297,     2308,     2289,\n             2260,     2234,     2318,     2286,     2309,     2300,\n             2325,     2320,     2246,     2235,     2262,     2315,\n             2238,     2313,     2311,     2254,     2269,     2258,\n             2317,     2320,     2325,     2317,     2280,     2257,\n             2296,     2321,     2329,     2299,     2247,     2323,\n             2240,     2276,     2268,     2272,     2265,     2298,\n             2272,     2237,     2279,     2271,     2253,     2280,\n             2284,     2289,     2290,     2316,     2255,     2327,\n             2236,     2302,     2290,     2262,     2311,     2313,\n             2271,     2237,     2292,     2273,     2263,     2232,\n             2330,     2267,     2274,     2323,     2287,     2244,\n             2250,     2314,     2279,     2278,     2328,     2233,\n             2303,     2319,     2314,     2325,     2242,     2266,\n             2274,     2247,     2263,     2306,     2300,     2283,\n             2238,     2259,     2304,     2282,     2296,     2246,\n             2298,     2295,     2232,     2244,     2274,     2282,\n             2316,     2289,     2276,     2310,     2247,     2314,\n             2322,     2232,     2241,     2301,     2305,     2306,\n             2297,     2283,     2291,     2240,     2249,     2259,\n             2281,     2312,     2270,     2252,     2262,     2304,\n             2288,     2308,     2231,     2324,     2311,     2322,\n             2242,     2253,     2299,     2261,     2326,     2309,\n             2249,     2287,     2324,     2275,     2245,     2278,\n             2297,     2271],\n        [       1,        1,        1,        0,        1,        0,\n                0,        0,        1,        0,        0,        1,\n                0,        1,        1,        1,        0,        0,\n                0,        0,        0,        0,        1,        0,\n                0,        1,        0,        1,        0,        0,\n                0,        0,        0,        1,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        1,        1,        0,        1,        1,\n                1,        0,        0,        0,        0,        0,\n                0,        0,        1,        1,        0,        1,\n                1,        0,        0,        0,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        1,        0,        1,        0,        0,\n                1,        0,        1,        0,        1,        0,\n                1,        1,        0,        1,        0,        0,\n                0,        0,        0,        0,        1,        1,\n                1,        1,        1,        0,        1,        1,\n                0,        0,        0,        0,        0,        1,\n                1,        1,        0,        0,        1,        0,\n                0,        1,        0,        1,        1,        1,\n                1,        0,        0,        0,        0,        0,\n                0,        0,        1,        0,        0,        1,\n                0,        0,        0,        1,        0,        1,\n                1,        1,        0,        0,        0,        1,\n                1,        0,        1,        0,        1,        1,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                1,        0,        0,        0,        0,        0,\n                1,        0,        0,        0,        0,        1,\n                0,        1,        0,        1,        1,        1,\n                1,        0,        0,        0,        0,        1,\n                0,        0,        0,        0,        1,        1,\n                0,        0]]),\n 'HUP159': array([[1478672,  677874, 7975312, ..., 3020748, 5434256, 7478564],\n        [1487401,  687128, 7983827, ..., 3027178, 5443887, 7489802],\n        [   1241,    1324,    1395, ...,    1347,    1366,    1390],\n        [      1,       0,       1, ...,       0,       0,       1]]),\n 'HUP182': array([[ 8616083,  6677043, 12326524,  3960611,  3972354, 17376118,\n          4178090,  1190662,  4185637,  4028145,  4020460,  3938132,\n          2996889, 13993988,  8188035, 10380981, 14658603, 11997029,\n          9697872, 10786553,  8121684, 18179123,  6656950,  8130204,\n          1178054, 18194590,  1842491,  4041539, 10457037, 17384487,\n         10207055,  7490722,  8624247, 10198646, 10463498, 12004554,\n          7507605, 15317260,  7378055,  3952884, 17367868, 12777208,\n          3948520,  7400597,  3930382, 12793752,  3014859, 11703749,\n         14649452, 11712964, 17142572,  9706455,  8197753, 15474970,\n          7220261,  1830862, 11695550,  7287887, 10448556, 17151414,\n          7152663, 10803593,  8632393,  4196148,  7499297, 19418547,\n          1171184, 10389560, 12529382, 12785591,  9495042, 19598791,\n         18185665, 17097562,  8139118, 14641303,  3006187,  5259777,\n          9712575, 19486107,  1824845, 12506848,  6665996, 10399312,\n         10794592,  8207292, 11988487],\n        [ 8624247,  6679439, 12349065,  3972354,  3975381, 17384487,\n          4185637,  1193711,  4196148,  4041539,  4028145,  3948520,\n          3006187, 14016489,  8197753, 10389560, 14663806, 12004554,\n          9706455, 10794592,  8130204, 18185665,  6665996,  8139118,\n          1190662, 18201626,  1847362,  4042953, 10463498, 17390371,\n         10220749,  7499297,  8632393, 10207055, 10471068, 12010994,\n          7513227, 15339801,  7400596,  3960611, 17376118, 12785591,\n          3952883,  7423115,  3938132, 12799715,  3019405, 11712964,\n         14658603, 11718054, 17151414,  9712575,  8207292, 15497468,\n          7242802,  1842491, 11703749,  7310428, 10457037, 17164990,\n          7175200, 10809051,  8638590,  4200590,  7507605, 19441036,\n          1178054, 10399312, 12551871, 12793752,  9517583, 19621332,\n         18194590, 17120059,  8144188, 14649452,  3014859,  5282318,\n          9720385, 19508648,  1830862, 12529381,  6677043, 10403481,\n         10803593,  8210524, 11997029],\n        [    2876,     2867,     2886,     2863,     2863,     2897,\n             2865,     2858,     2865,     2864,     2864,     2862,\n             2861,     2891,     2875,     2880,     2892,     2885,\n             2878,     2883,     2874,     2898,     2867,     2874,\n             2858,     2898,     2859,     2864,     2881,     2897,\n             2879,     2873,     2876,     2879,     2881,     2885,\n             2873,     2893,     2871,     2863,     2897,     2889,\n             2862,     2872,     2862,     2889,     2861,     2884,\n             2892,     2884,     2896,     2878,     2875,     2894,\n             2869,     2859,     2884,     2870,     2881,     2896,\n             2868,     2883,     2876,     2865,     2873,     2899,\n             2858,     2880,     2888,     2889,     2877,     2901,\n             2898,     2895,     2874,     2892,     2861,     2866,\n             2878,     2900,     2859,     2887,     2867,     2880,\n             2883,     2875,     2885],\n        [       0,        0,        0,        1,        0,        1,\n                0,        0,        1,        1,        0,        1,\n                0,        0,        0,        0,        0,        1,\n                0,        0,        0,        0,        0,        1,\n                1,        0,        0,        0,        1,        0,\n                1,        0,        1,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        1,\n                1,        0,        0,        1,        1,        0,\n                0,        1,        0,        0,        0,        1,\n                0,        0,        0,        0,        1,        0,\n                0,        1,        0,        1,        0,        0,\n                1,        0,        0,        0,        1,        0,\n                0,        0,        0,        0,        1,        0,\n                1,        0,        0]]),\n 'HUP197': array([[ 1126396,   159654, 12365158,  4879016,  3876091,  7172168,\n         23963003,  1050707,   839374, 21588014,  2168593,  4011342,\n          4236748,  2942787,  2002334,  5373716,   907000,  3620321,\n          2446880,  5328742,  3740842,  3311530],\n        [ 1134370,   182195, 12410131,  4923988,  3898632,  7216986,\n         24007959,  1058769,   861915, 21632986,  2191134,  4033882,\n          4259289,  2965328,  2010808,  5418688,   915454,  3642842,\n          2469421,  5373715,  3763383,  3319366],\n        [    3407,     3403,     3427,     3418,     3415,     3423,\n             3449,     3406,     3404,     3444,     3409,     3416,\n             3417,     3411,     3408,     3420,     3405,     3413,\n             3410,     3419,     3414,     3412],\n        [       0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0]]),\n 'HUP199': array([[33547096, 13626271, 31070534, 31064222, 30161533, 30147444,\n         47997857, 66973708, 47976377,  4297750, 55752500,  4312847,\n         25541943, 59775723, 15254525,  1595608, 42928098,  5991583,\n         34290118, 30141275, 32225778, 31685572, 25562233, 66987463,\n         13425362, 59791542, 23240468, 48319788,  5994352,  8310788,\n         33565760,  2248856, 66967478, 34296431, 49242045, 18069293,\n         50583948,  9749445, 49710190, 55754223, 13637239, 33552518,\n         68783060, 42921500, 53583236, 40527322, 59978281,  1604295,\n         68292981, 22164167, 49237272, 38890932, 25542961,  2256397,\n         66260782, 59777741, 49252564, 31690225, 60676473, 68775838,\n         48335450, 50565718, 66300909,  7477539, 31667716, 68311969,\n         42937984, 26014643, 38907011, 32214258, 38672716, 33659645,\n         17281076, 50571222,  6011540, 72950467, 23223028, 11593517,\n         16436671, 59981535, 31707790, 47977494,  5135657, 15266915,\n         13620282, 66288612, 16241191, 38665810, 31673005, 31081014,\n         66283320,  3171867,  7493275, 53589028, 53597919, 11573588,\n         48314023, 11579521, 55767960, 13417540, 31695647,  3187467,\n         38896689, 18070854, 60696854, 40512318, 16422107, 34310623,\n         72094667, 23224227, 59999164, 16421392,  1589596,  3178744,\n         40514625, 33665008, 15252312,  7484820,  4298615, 33674597,\n         38680911, 32208035,  8314689],\n        [33552518, 13637239, 31081014, 31070534, 30163778, 30161533,\n         47998854, 66987463, 47977494,  4298615, 55754223,  4320244,\n         25542961, 59777741, 15266915,  1604295, 42937984,  5994352,\n         34296431, 30147444, 32230541, 31690224, 25564448, 66989982,\n         13440013, 59798223, 23245522, 48335450,  6011540,  8314689,\n         33569603,  2256397, 66973708, 34310623, 49252564, 18070854,\n         50588226,  9771952, 49732731, 55767960, 13642772, 33565760,\n         68798257, 42928098, 53589028, 40534819, 59981535,  1612128,\n         68311969, 22186708, 49242045, 38896689, 25562233,  2271152,\n         66283319, 59791542, 49259787, 31695647, 60696854, 68783060,\n         48336516, 50571222, 66305828,  7484820, 31673005, 68315434,\n         42944011, 26037184, 38913443, 32225778, 38680911, 33665008,\n         17303605, 50583948,  6014069, 72973004, 23224227, 11596079,\n         16443898, 59999164, 31712733, 47997857,  5158198, 15274819,\n         13626271, 66300909, 16263718, 38672716, 31685572, 31086732,\n         66288612,  3178744,  7500039, 53597919, 53605753, 11579521,\n         48319788, 11593517, 55775006, 13425362, 31707790,  3194357,\n         38907011, 18091780, 60698950, 40514625, 16436671, 34312617,\n         72117185, 23240468, 60000774, 16422107,  1595608,  3187467,\n         40527322, 33674597, 15254525,  7493275,  4312847, 33682160,\n         38688326, 32214258,  8332831],\n        [    3904,     3889,     3900,     3900,     3899,     3899,\n             3911,     3924,     3911,     3881,     3918,     3881,\n             3897,     3919,     3890,     3878,     3910,     3883,\n             3906,     3899,     3903,     3901,     3897,     3924,\n             3888,     3919,     3896,     3912,     3883,     3885,\n             3904,     3879,     3924,     3906,     3914,     3894,\n             3916,     3886,     3915,     3918,     3889,     3904,\n             3926,     3910,     3917,     3909,     3920,     3878,\n             3925,     3895,     3914,     3908,     3897,     3879,\n             3922,     3919,     3914,     3902,     3921,     3926,\n             3912,     3916,     3923,     3884,     3901,     3925,\n             3910,     3898,     3908,     3903,     3907,     3905,\n             3893,     3916,     3883,     3928,     3896,     3887,\n             3892,     3920,     3902,     3911,     3882,     3890,\n             3889,     3923,     3891,     3907,     3901,     3900,\n             3923,     3880,     3884,     3917,     3917,     3887,\n             3912,     3887,     3918,     3888,     3902,     3880,\n             3908,     3894,     3921,     3909,     3892,     3906,\n             3927,     3896,     3920,     3892,     3878,     3880,\n             3909,     3905,     3890,     3884,     3881,     3905,\n             3907,     3903,     3885],\n        [       0,        1,        1,        0,        0,        1,\n                0,        1,        0,        0,        0,        0,\n                0,        0,        1,        1,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        0,        0,        1,        1,        0,\n                0,        0,        0,        1,        1,        0,\n                0,        0,        0,        1,        0,        1,\n                1,        0,        0,        0,        0,        0,\n                1,        0,        0,        0,        1,        1,\n                0,        1,        0,        0,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        1,        1,        0,\n                0,        1,        0,        0,        0,        0,\n                0,        1,        0,        1,        0,        0,\n                0,        1,        0,        0,        1,        0,\n                0,        0,        0,        1,        0,        0,\n                0,        1,        0,        0,        1,        0,\n                1,        1,        0,        0,        1,        0,\n                0,        1,        0,        0,        0,        1,\n                1,        1,        0,        1,        1,        0,\n                0,        0,        1]]),\n 'HUP205': array([], shape=(4, 0), dtype=int32),\n 'RNS026': array([[13116634, 42650470, 13109377, 29470173, 11590959, 21862488,\n         10569366, 43049519, 23999106,  5555716, 28426002, 15271086,\n         17502446, 11801728, 36148661,  5754448, 10082500, 11811751,\n         26115271, 15796000, 21883891, 21877470, 42846876, 16696678,\n         33192724,    89058, 22296629, 42722466, 44310531,   832623,\n           163221, 38565144, 12971848, 27753821, 17873240,  9380707,\n         12042322, 17538952, 12802138, 38381051, 39111809, 10571711,\n          5772583,  3183963, 29459717, 21368385, 30032641,  4514090,\n         38547476,  7285620, 29897684, 20850328, 20748038, 10590463,\n         42335172, 38374580,  3296189, 21348794, 21636281, 29963095,\n         15098066, 42704193, 29452778, 15805137,   742499, 42515342,\n         20740705,  3173300,  6887534, 17496235, 12965579,  7900540,\n         42866476, 34420660, 42929445, 12425112, 38156721, 20718167,\n         12792931, 28410334, 22289341, 21900437, 42342585, 10089743,\n         43349588, 29950468, 16689601,  9403427,  4141684, 13045355,\n         11588926,  4123899, 41381101, 44963690,  3286229, 23212060,\n           102030, 42914473,   178195, 12312535,  9366317, 15788790,\n         25582532, 21886637, 17181088, 44973155, 39100773, 43056760,\n          2348088, 42657455,  7893525, 38554457,  6898089, 20504117,\n         33209889, 27758240, 29903716, 36894158, 23231438, 42816710,\n         12049583, 36141399, 17525920, 42852225, 25566608,  6880317,\n         44317893,  7555758, 32306457, 13129209, 43387433, 38146531,\n         43070788, 22330468, 33198140, 17751492,  5570968,  4131250,\n         11794736,  9384713, 22311823, 17759543,  5551659, 10952125,\n         34437710, 17197643, 34645852, 29708333, 23984928, 29712105,\n         17744410, 28455331,  4506943, 21356148, 25859394, 21643349,\n         36161335, 28458157, 17518730, 22316464, 40290085,  8902488,\n         29942661, 42921951, 38127100, 17864359, 16345105,  8740522,\n         16669623, 15277748, 12177424, 20837576, 17857021,  3166582,\n         15090995, 23977868, 12785407, 20830771, 13041931, 28475196,\n         34021496, 23219202, 16667119, 28417616, 43342413, 39096513,\n         34019677, 12334130, 16688553, 16336377, 37029366, 41366781,\n         34432026, 14235184, 38149446,  5761570, 12319849, 20761672,\n            96313, 12057080,  9362217,   156635, 41816950,  8898162,\n         23054408,  3279239,  9388590, 16329268,  9474744,  7562813,\n         21861396, 17188278, 25866634],\n        [13129209, 42657455, 13116634, 29475287, 11611384, 21877470,\n         10571711, 43056760, 24000359,  5570968, 28432836, 15277748,\n         17518717, 11811751, 36161335,  5761570, 10089743, 11817245,\n         26123197, 15805137, 21886637, 21883890, 42852225, 16712090,\n         33198140,    96313, 22311821, 42726668, 44317893,   855152,\n           178195, 38569982, 12988061, 27758240, 17879523,  9384712,\n         12049583, 17541218, 12807915, 38397054, 39119020, 10590463,\n          5776953,  3189081, 29470173, 21371288, 30055178,  4529425,\n         38554457,  7308161, 29903716, 20853262, 20761672, 10591857,\n         42342585, 38381051,  3301749, 21356148, 21643349, 29965136,\n         15113477, 42722466, 29459717, 15811296,   765026, 42537883,\n         20748038,  3183963,  6898089, 17502446, 12971848,  7916021,\n         42869392, 34432026, 42936975, 12447633, 38171918, 20740704,\n         12802138, 28417616, 22296629, 21906390, 42357648, 10104989,\n         43364893, 29963095, 16696678,  9407205,  4146410, 13064409,\n         11590959,  4131250, 41389104, 44973155,  3296189, 23219202,\n           111587, 42921951,   179161, 12319849,  9380707, 15796000,\n         25589095, 21900437, 17188278, 44986166, 39111809, 43070788,\n          2370629, 42672964,  7900540, 38565144,  6902825, 20526654,\n         33215226, 27776294, 29920160, 36916699, 23234549, 42824392,\n         12057080, 36148661, 17538952, 42866476, 25582532,  6887534,\n         44333025,  7562813, 32328998, 13131870, 43409974, 38149445,\n         43072009, 22334299, 33209889, 17759543,  5574151,  4141684,\n         11801728,  9388590, 22316464, 17766922,  5555716, 10974654,\n         34443143, 17203591, 34668393, 29712105, 23999106, 29717716,\n         17751492, 28458157,  4514090, 21368385, 25866634, 21658758,\n         36163893, 28475196, 17525920, 22330468, 40312626,  8920638,\n         29950468, 42929445, 38146531, 17873240, 16351778,  8763063,\n         16688553, 15293570, 12199965, 20850328, 17864359,  3173300,\n         15098066, 23984928, 12792931, 20837576, 13045355, 28477812,\n         34042145, 23231438, 16669623, 28426002, 43349588, 39100773,\n         34021496, 12335022, 16689600, 16345105, 37051907, 41381101,\n         34437710, 14257725, 38156721,  5772583, 12334130, 20763204,\n           102030, 12064824,  9366317,   163221, 41839487,  8902488,\n         23076949,  3286229,  9403427, 16336377,  9497285,  7578247,\n         21862488, 17197643, 25881885],\n        [    3260,     3315,     3260,     3292,     3251,     3279,\n             3249,     3320,     3285,     3236,     3290,     3263,\n             3269,     3252,     3302,     3237,     3248,     3252,\n             3288,     3264,     3280,     3279,     3318,     3267,\n             3298,     3227,     3281,     3316,     3323,     3230,\n             3228,     3308,     3258,     3289,     3272,     3245,\n             3253,     3270,     3257,     3307,     3309,     3249,\n             3237,     3232,     3292,     3277,     3296,     3235,\n             3308,     3239,     3294,     3276,     3275,     3249,\n             3313,     3307,     3233,     3277,     3278,     3295,\n             3262,     3316,     3292,     3264,     3229,     3314,\n             3275,     3232,     3238,     3269,     3258,     3241,\n             3318,     3300,     3319,     3256,     3306,     3274,\n             3257,     3290,     3281,     3280,     3313,     3248,\n             3321,     3295,     3267,     3246,     3234,     3259,\n             3251,     3234,     3311,     3324,     3233,     3284,\n             3227,     3319,     3228,     3255,     3245,     3264,\n             3286,     3280,     3268,     3324,     3309,     3320,\n             3231,     3315,     3241,     3308,     3238,     3273,\n             3298,     3289,     3294,     3303,     3284,     3317,\n             3253,     3302,     3270,     3318,     3286,     3238,\n             3323,     3240,     3297,     3260,     3322,     3305,\n             3320,     3282,     3298,     3271,     3236,     3234,\n             3252,     3246,     3282,     3271,     3236,     3250,\n             3300,     3268,     3301,     3293,     3285,     3293,\n             3271,     3291,     3235,     3277,     3287,     3278,\n             3302,     3291,     3270,     3282,     3310,     3244,\n             3295,     3319,     3305,     3272,     3265,     3243,\n             3266,     3263,     3254,     3276,     3272,     3232,\n             3262,     3285,     3257,     3276,     3259,     3291,\n             3299,     3284,     3266,     3290,     3321,     3309,\n             3299,     3255,     3266,     3265,     3304,     3311,\n             3300,     3261,     3306,     3237,     3255,     3275,\n             3227,     3253,     3245,     3228,     3312,     3244,\n             3283,     3233,     3246,     3265,     3247,     3240,\n             3279,     3268,     3287],\n        [       1,        0,        0,        0,        1,        1,\n                0,        0,        0,        1,        0,        0,\n                1,        1,        1,        0,        0,        0,\n                0,        1,        0,        0,        0,        1,\n                0,        0,        1,        0,        0,        0,\n                1,        0,        1,        0,        0,        0,\n                0,        0,        0,        1,        0,        1,\n                0,        0,        1,        0,        0,        1,\n                0,        0,        0,        0,        1,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        1,        0,        0,        0,        0,\n                0,        1,        1,        0,        0,        1,\n                0,        0,        0,        0,        1,        0,\n                1,        0,        0,        0,        1,        1,\n                1,        1,        0,        0,        0,        1,\n                0,        0,        0,        0,        1,        0,\n                0,        0,        0,        0,        1,        0,\n                0,        1,        0,        1,        1,        1,\n                0,        1,        0,        1,        0,        0,\n                0,        1,        1,        0,        0,        0,\n                1,        0,        1,        1,        1,        0,\n                1,        0,        0,        0,        0,        0,\n                0,        0,        1,        1,        0,        1,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        1,        1,        0,\n                0,        0,        0,        1,        0,        1,\n                0,        1,        0,        1,        0,        1,\n                0,        1,        1,        1,        0,        0,\n                1,        1,        0,        1,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                1,        1,        0,        1,        0,        0,\n                0,        0,        0,        1,        0,        1,\n                1,        0,        0,        1,        1,        0,\n                1,        0,        0,        0,        0,        0,\n                0,        0,        1,        0,        0,        1,\n                0,        1,        1]]),\n 'RNS029': array([[ 5210961, 19808200, 71663839,  5744045, 50685126, 56035772,\n         43542096, 21728109,  6415209, 74278390, 26713387, 74416448,\n         64251220, 76671332, 56035772, 36930468, 68061707, 19064820,\n         47222809, 13383192,  5431225, 30978226, 32972630, 37262431,\n         56035772, 69502535, 71655693, 15701504, 60809715,  6261107,\n         74445890,    79306,  4842738,  9843677, 63771492, 46029090,\n         22427651,  2807620, 13360669, 20177912, 63762518, 50688062,\n         46035880, 68614377, 42212534, 75541819, 42197505, 56028892,\n          2815040,  2820313, 37253298, 21710690,  5974798,  7111655,\n         74438978, 34613109,  5420724,  4126906, 49779218, 52129782,\n         50820252, 14654550, 49418954, 60804040, 40883544, 43068947,\n         43076409, 43085002, 52077676, 54386637, 57312607, 15465544,\n         50816174, 56096312, 63034237,  9843677, 33766024, 76678717,\n          8461116, 15150173, 56118023, 33247629, 69485893, 49426182,\n         69493162,  5986062,  7173952, 15822068, 74259174,  6703318,\n         22434521, 53538215, 75563270, 32954805, 13367822,  5052935,\n          5110356, 27872131, 59115142, 77406407, 75586800, 56012496,\n         76663447, 65529988, 52139189, 12569278,  8217580, 73587450,\n          7264048, 47228208, 66453312, 38945949, 65537739, 63038852,\n         66457845, 22444089, 38952547, 49351405, 69891198, 56104052,\n         21706631,  2831229, 48289431,  9836292, 40893422, 42190058,\n         37245955, 16047405, 20180857, 42933704, 39283968, 73584075,\n         14722125, 30987305, 52122645, 13378729, 63755323, 40891210,\n         75594316, 30971466, 59121558, 56006422, 75549231, 34609379,\n          4617509,  2953276,  3123506, 19071152, 32961987, 13390468,\n         49358591,  7442201, 42219919, 73043245, 22943308,   637518,\n         14149170,  3736651, 74264974, 71647328,  2266714,  5465789,\n          5097967,  9843677,   592451, 48281906, 57317432],\n        [ 5233476, 19830738, 71669824,  5766560, 50688062, 56051340,\n         43564635, 21729117,  6437729, 74281644, 26735928, 74438977,\n         64273761, 76678717, 56051340, 36953009, 68084120, 19071152,\n         47228208, 13390468,  5443248, 30987305, 32977314, 37268465,\n         56051320, 69508388, 71663839, 15709361, 60826494,  6283622,\n         74461442,   101837,  4865250,  9858793, 63777838, 46035880,\n         22434521,  2815040, 13367822, 20180857, 63771492, 50707609,\n         46051535, 68636910, 42219919, 75549231, 42212450, 56035772,\n          2820312,  2831229, 37262431, 21728109,  5986062,  7134176,\n         74445890, 34631862,  5431225,  4135387, 49801759, 52139189,\n         50838645, 14677054, 49426182, 60809715, 40891210, 43076409,\n         43085002, 43091461, 52100135, 54409175, 57317432, 15488058,\n         50820252, 56104052, 63038852,  9858793, 33788562, 76685943,\n          8472733, 15172714, 56118798, 33270170, 69493162, 49441410,\n         69502535,  5997266,  7196467, 15844577, 74264974,  6725837,\n         22444089, 53560756, 75564261, 32961987, 13378729,  5075448,\n          5120372, 27894672, 59121558, 77428947, 75594316, 56028890,\n         76671332, 65537739, 52145160, 12591778,  8235816, 73606514,\n          7286556, 47245213, 66457845, 38952547, 65552474, 63056713,\n         66475792, 22450157, 38968437, 49358591, 69913658, 56118023,\n         21710690,  2842895, 48304343,  9843677, 40906012, 42197505,\n         37253298, 16069926, 20200372, 42956242, 39306500, 73587450,\n         14744639, 30993979, 52129782, 13383191, 63762518, 40893422,\n         75609232, 30978226, 59137610, 56012496, 75563270, 34613109,\n          4640023,  2975804,  3142123, 19087307, 32972630, 13405701,\n         49373824,  7464729, 42235005, 73065758, 22965849,   660046,\n         14171711,  3748520, 74278390, 71655693,  2289239,  5488302,\n          5110356,  9858804,   614975, 48289431, 57335093],\n        [    3741,     3769,     3820,     3744,     3798,     3805,\n             3791,     3771,     3747,     3823,     3774,     3824,\n             3813,     3828,     3805,     3781,     3816,     3768,\n             3793,     3759,     3742,     3776,     3777,     3782,\n             3805,     3818,     3820,     3765,     3810,     3746,\n             3825,     3727,     3738,     3756,     3812,     3792,\n             3772,     3731,     3758,     3770,     3812,     3798,\n             3792,     3817,     3788,     3826,     3787,     3805,\n             3731,     3732,     3782,     3771,     3745,     3749,\n             3825,     3780,     3742,     3736,     3797,     3801,\n             3799,     3761,     3796,     3810,     3785,     3790,\n             3790,     3790,     3800,     3803,     3808,     3764,\n             3799,     3807,     3811,     3756,     3779,     3828,\n             3754,     3763,     3807,     3778,     3818,     3796,\n             3818,     3745,     3750,     3766,     3823,     3748,\n             3772,     3802,     3826,     3777,     3758,     3739,\n             3740,     3775,     3809,     3829,     3827,     3804,\n             3828,     3814,     3801,     3757,     3753,     3822,\n             3751,     3793,     3815,     3783,     3814,     3811,\n             3815,     3772,     3783,     3795,     3819,     3807,\n             3771,     3732,     3794,     3756,     3785,     3787,\n             3782,     3767,     3770,     3789,     3784,     3822,\n             3762,     3776,     3801,     3758,     3812,     3785,\n             3827,     3776,     3809,     3804,     3826,     3780,\n             3737,     3733,     3734,     3768,     3777,     3759,\n             3795,     3752,     3788,     3821,     3773,     3729,\n             3760,     3735,     3823,     3820,     3730,     3743,\n             3740,     3756,     3728,     3794,     3808],\n        [       0,        0,        0,        0,        0,        1,\n                0,        0,        0,        0,        0,        0,\n                0,        1,        0,        0,        1,        0,\n                0,        0,        1,        1,        0,        0,\n                1,        0,        1,        0,        1,        0,\n                1,        0,        0,        1,        0,        0,\n                0,        1,        0,        0,        1,        1,\n                1,        0,        0,        0,        1,        0,\n                0,        0,        1,        1,        0,        0,\n                0,        1,        0,        0,        0,        1,\n                1,        0,        0,        0,        0,        0,\n                1,        0,        1,        0,        0,        0,\n                0,        0,        0,        0,        0,        0,\n                0,        0,        0,        0,        0,        1,\n                1,        1,        0,        0,        0,        0,\n                1,        0,        0,        0,        1,        0,\n                1,        0,        0,        0,        0,        1,\n                0,        0,        0,        0,        0,        1,\n                0,        1,        0,        0,        1,        1,\n                1,        0,        1,        0,        0,        1,\n                0,        1,        1,        0,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                0,        0,        0,        0,        0,        1,\n                1,        0,        1,        0,        1,        0,\n                0,        0,        0,        1,        1,        1,\n                1,        0,        1,        0,        0,        0,\n                0,        0,        1,        0,        0,        0,\n                0,        1,        0,        0,        1]])}"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-25T11:13:00.075382Z",
     "end_time": "2023-10-25T11:13:00.762499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T13:01:46.731213Z",
     "end_time": "2023-04-20T13:02:00.105663Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:12<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "window_len = 1\n",
    "stride = 1\n",
    "concat_n = 4\n",
    "for id in tqdm(clip_dict.keys()):\n",
    "    data_import[id].set_window_parameter(window_length=window_len, window_displacement=stride)\n",
    "    data_import[id].set_concatenation_parameter(concatenate_window_n=concat_n)\n",
    "    window_indices, _ = data_import[id].get_windowed_data(clip_dict[id][0], clip_dict[id][1])\n",
    "    import_label = np.array([])\n",
    "    for i, ind in enumerate(window_indices):\n",
    "        import_label = np.hstack((import_label, np.repeat(clip_dict[id][2][i], len(ind))))\n",
    "    data_import[id].normalize_windowed_data()\n",
    "    _, concatenated_data = data_import[id].get_concatenated_data(data_import[id].windowed_data, arrange='channel_stack')\n",
    "    assert import_label.shape[0] == concatenated_data.shape[0]\n",
    "    np.save('rns_test_cache/' + id + '.npy', {'data': concatenated_data, 'label': import_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T13:02:00.111667Z",
     "end_time": "2023-04-20T13:02:00.663174Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNS_Downstream(Dataset):\n",
    "    def __init__(self, data, label, transform=True, astensor=True):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        print('data loaded')\n",
    "\n",
    "        self.label = self.label[np.newaxis].T\n",
    "\n",
    "        self.length = len(self.data)\n",
    "\n",
    "        print(data.shape)\n",
    "        print(label.shape)\n",
    "\n",
    "        if astensor:\n",
    "            self.augmentation = T.Compose([\n",
    "                T.ToPILImage(),\n",
    "                T.Resize((256, 256), interpolation=T.InterpolationMode.NEAREST),\n",
    "                T.RandomApply([T.ColorJitter()], p=0.5),\n",
    "                T.RandomApply([T.GaussianBlur(kernel_size=(3, 3))], p=0.5),\n",
    "                T.RandomInvert(p=0.2),\n",
    "                T.RandomPosterize(4, p=0.2),\n",
    "                T.ToTensor()\n",
    "            ])\n",
    "\n",
    "            self.totensor = T.Compose([\n",
    "                T.ToPILImage(),\n",
    "                T.Resize((256, 256), interpolation=T.InterpolationMode.NEAREST),\n",
    "                T.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            self.augmentation = T.Compose([\n",
    "                T.ToPILImage(),\n",
    "                T.Resize((256, 256), interpolation=T.InterpolationMode.NEAREST),\n",
    "                T.RandomApply([T.ColorJitter()], p=0.5),\n",
    "                T.RandomApply([T.GaussianBlur(kernel_size=(3, 3))], p=0.5),\n",
    "                T.RandomInvert(p=0.2),\n",
    "                T.RandomPosterize(4, p=0.2),\n",
    "            ])\n",
    "\n",
    "            self.totensor = T.Compose([\n",
    "                T.ToPILImage(),\n",
    "                T.Resize((256, 256), interpolation=T.InterpolationMode.NEAREST),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.label[index]\n",
    "\n",
    "        if self.transform:\n",
    "            concat_len = data.shape[1] / 4\n",
    "            channel_index = np.arange(4)\n",
    "            np.random.shuffle(channel_index)\n",
    "            channel_index = channel_index * concat_len + (concat_len - 1) / 2\n",
    "            channel_index = np.repeat(channel_index, concat_len)\n",
    "            concate_len_1 = (concat_len - 1) / 2\n",
    "            a_repeat = np.arange(-concate_len_1, concate_len_1 + 1)[np.newaxis].T\n",
    "            base_repeat = np.repeat(a_repeat, 4, axis=1).T.flatten()\n",
    "            channel_index = channel_index + base_repeat\n",
    "            data = data[channel_index.astype(int)]\n",
    "            data = torch.from_numpy(data).clone()\n",
    "            data = data.repeat(3, 1, 1)\n",
    "            data = self.augmentation(data)\n",
    "\n",
    "        else:\n",
    "            concat_len = data.shape[1] / 4\n",
    "            channel_index = np.arange(4)\n",
    "            # np.random.shuffle(channel_index)\n",
    "            channel_index = channel_index * concat_len + (concat_len - 1) / 2\n",
    "            channel_index = np.repeat(channel_index, concat_len)\n",
    "            concate_len_1 = (concat_len - 1) / 2\n",
    "            a_repeat = np.arange(-concate_len_1, concate_len_1 + 1)[np.newaxis].T\n",
    "            base_repeat = np.repeat(a_repeat, 4, axis=1).T.flatten()\n",
    "            channel_index = channel_index + base_repeat\n",
    "            data = data[channel_index.astype(int)]\n",
    "            data = torch.from_numpy(data).clone()\n",
    "            data = data.repeat(3, 1, 1)\n",
    "            data = self.totensor(data)\n",
    "\n",
    "        return data, torch.from_numpy(label).to(dtype=torch.long), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T13:02:00.667177Z",
     "end_time": "2023-04-20T13:02:01.647068Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "from lightly.data import LightlyDataset, SwaVCollateFunction\n",
    "from lightly.loss import SwaVLoss\n",
    "from lightly.loss.memory_bank import MemoryBankModule\n",
    "from lightly.models.modules import SwaVProjectionHead, SwaVPrototypes\n",
    "\n",
    "\n",
    "class SwaV(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = SwaVProjectionHead(2048, 2048, 128)\n",
    "        self.prototypes = SwaVPrototypes(128, 2048, 1)\n",
    "\n",
    "        self.start_queue_at_epoch = 35\n",
    "        self.queues = nn.ModuleList([MemoryBankModule(size=256) for _ in range(2)])\n",
    "\n",
    "    def forward(self, high_resolution, low_resolution, epoch):\n",
    "        self.prototypes.normalize()\n",
    "\n",
    "        high_resolution_features = [self._subforward(x) for x in high_resolution]\n",
    "        low_resolution_features = [self._subforward(x) for x in low_resolution]\n",
    "\n",
    "        high_resolution_prototypes = [\n",
    "            self.prototypes(x, epoch) for x in high_resolution_features\n",
    "        ]\n",
    "        low_resolution_prototypes = [\n",
    "            self.prototypes(x, epoch) for x in low_resolution_features\n",
    "        ]\n",
    "        queue_prototypes = self._get_queue_prototypes(high_resolution_features, epoch)\n",
    "\n",
    "        return high_resolution_prototypes, low_resolution_prototypes, queue_prototypes\n",
    "\n",
    "    def _subforward(self, input):\n",
    "        features = self.backbone(input).flatten(start_dim=1)\n",
    "        features = self.projection_head(features)\n",
    "        features = nn.functional.normalize(features, dim=1, p=2)\n",
    "        return features\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_queue_prototypes(self, high_resolution_features, epoch):\n",
    "        if len(high_resolution_features) != len(self.queues):\n",
    "            raise ValueError(\n",
    "                f\"The number of queues ({len(self.queues)}) should be equal to the number of high \"\n",
    "                f\"resolution inputs ({len(high_resolution_features)}). Set `n_queues` accordingly.\"\n",
    "            )\n",
    "\n",
    "        # Get the queue features\n",
    "        queue_features = []\n",
    "        for i in range(len(self.queues)):\n",
    "            _, features = self.queues[i](high_resolution_features[i], update=True)\n",
    "            # Queue features are in (num_ftrs X queue_length) shape, while the high res\n",
    "            # features are in (batch_size X num_ftrs). Swap the axes for interoperability.\n",
    "            features = torch.permute(features, (1, 0))\n",
    "            queue_features.append(features)\n",
    "\n",
    "        # If loss calculation with queue prototypes starts at a later epoch,\n",
    "        # just queue the features and return None instead of queue prototypes.\n",
    "        if self.start_queue_at_epoch > 0 and epoch < self.start_queue_at_epoch:\n",
    "            return None\n",
    "\n",
    "        # Assign prototypes\n",
    "        queue_prototypes = [self.prototypes(x, epoch) for x in queue_features]\n",
    "        return queue_prototypes\n",
    "\n",
    "\n",
    "resnet = torchvision.models.resnet50()\n",
    "\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "model = SwaV(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T13:02:01.647068Z",
     "end_time": "2023-04-20T13:02:02.169545Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def sigmoid_focal_loss(\n",
    "        inputs: torch.Tensor,\n",
    "        targets: torch.Tensor,\n",
    "        alpha: float = 0.25,\n",
    "        gamma: float = 2,\n",
    "        reduction: str = \"none\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n",
    "\n",
    "    Args:\n",
    "        inputs (Tensor): A float tensor of arbitrary shape.\n",
    "                The predictions for each example.\n",
    "        targets (Tensor): A float tensor with the same shape as inputs. Stores the binary\n",
    "                classification label for each element in inputs\n",
    "                (0 for the negative class and 1 for the positive class).\n",
    "        alpha (float): Weighting factor in range (0,1) to balance\n",
    "                positive vs negative examples or -1 for ignore. Default: ``0.25``.\n",
    "        gamma (float): Exponent of the modulating factor (1 - p_t) to\n",
    "                balance easy vs hard examples. Default: ``2``.\n",
    "        reduction (string): ``'none'`` | ``'mean'`` | ``'sum'``\n",
    "                ``'none'``: No reduction will be applied to the output.\n",
    "                ``'mean'``: The output will be averaged.\n",
    "                ``'sum'``: The output will be summed. Default: ``'none'``.\n",
    "    Returns:\n",
    "        Loss tensor with the reduction option applied.\n",
    "    \"\"\"\n",
    "    # Original implementation from https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/focal_loss.py\n",
    "\n",
    "    p = torch.sigmoid(inputs)\n",
    "\n",
    "    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "    p_t = p * targets + (1 - p) * (1 - targets)\n",
    "    loss = ce_loss * ((1 - p_t) ** gamma)\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    # Check reduction option and return loss accordingly\n",
    "    if reduction == \"none\":\n",
    "        pass\n",
    "    elif reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid Value for arg 'reduction': '{reduction} \\n Supported reduction modes: 'none', 'mean', 'sum'\"\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T13:02:02.169545Z",
     "end_time": "2023-04-20T13:02:02.689015Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SupervisedDownstream(pl.LightningModule):\n",
    "    def __init__(self, backbone, unfreeze_backbone_at_epoch=100):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.fc1 = nn.Linear(2048, 512)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc3 = nn.Linear(64, 8)\n",
    "        self.fc4 = nn.Linear(8, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.alpha = 0.5\n",
    "        self.gamma = 8\n",
    "        self.unfreeze_backbone_at_epoch = unfreeze_backbone_at_epoch\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        if self.current_epoch < self.unfreeze_backbone_at_epoch:\n",
    "            self.backbone.eval()\n",
    "            x = self.backbone(x)\n",
    "            with torch.no_grad():\n",
    "                x = x.view(-1, 2048)\n",
    "        else:\n",
    "            x = self.backbone(x)\n",
    "            x = x.view(-1, 2048)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        pred = self.fc4(x)\n",
    "        pred = self.softmax(pred)\n",
    "        label = F.one_hot(y, num_classes=2).squeeze()\n",
    "        loss = sigmoid_focal_loss(pred.float(), label.float(), alpha=self.alpha, gamma=self.gamma, reduction='mean')\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(-1, 2048)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        pred = self.fc4(x)\n",
    "        pred = self.softmax(pred)\n",
    "        label = F.one_hot(y, num_classes=2).squeeze()\n",
    "        loss = sigmoid_focal_loss(pred.float(), label.float(), alpha=self.alpha, gamma=self.gamma, reduction='mean')\n",
    "        out = torch.argmax(pred, dim=1)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        target = y.squeeze().detach().cpu().numpy()\n",
    "        precision, recall, fscore, support = sklearn.metrics.precision_recall_fscore_support(out, target, labels=[0, 1],\n",
    "                                                                                             zero_division=0)\n",
    "        acc = sklearn.metrics.accuracy_score(out, target)\n",
    "        # print(acc)\n",
    "        # print(precision)\n",
    "        # print(recall)\n",
    "        # print(fscore)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "        self.log(\"val_precision\", precision[1])\n",
    "        self.log(\"val_recall\", recall[1])\n",
    "        return pred, label\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        emb = self.backbone(x)\n",
    "        emb = emb.view(-1, 2048)\n",
    "        x = F.relu(self.fc1(emb))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        pred = self.fc4(x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        return pred, y, emb\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-2)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T13:02:02.691018Z",
     "end_time": "2023-04-20T13:02:03.208489Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    info = list(zip(*batch))\n",
    "    data = info[0]\n",
    "    label = info[1]\n",
    "    return torch.stack(data), torch.stack(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T13:02:03.210490Z",
     "end_time": "2023-04-20T13:02:03.731965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['HUP047.npy',\n 'HUP084.npy',\n 'HUP096.npy',\n 'HUP109.npy',\n 'HUP121.npy',\n 'HUP129.npy',\n 'HUP131.npy',\n 'HUP137.npy',\n 'HUP147.npy',\n 'HUP156.npy',\n 'HUP159.npy',\n 'HUP182.npy',\n 'HUP199.npy',\n 'RNS026.npy',\n 'RNS029.npy']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('rns_test_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_data(file_names, split=0.7):\n",
    "    file_name_temp = file_names[0]\n",
    "    cache = np.load('rns_test_cache/' + file_name_temp, allow_pickle=True)\n",
    "    temp_file = cache.item().get('data')\n",
    "\n",
    "    train_data = np.empty((0, temp_file.shape[1], temp_file.shape[2]))\n",
    "    train_label = np.array([])\n",
    "    test_data = np.empty((0, temp_file.shape[1], temp_file.shape[2]))\n",
    "    test_label = np.array([])\n",
    "\n",
    "    for name in tqdm(file_names):\n",
    "        cache = np.load('rns_test_cache/' + name, allow_pickle=True)\n",
    "        data = cache.item().get('data')\n",
    "        label = cache.item().get('label')\n",
    "        split_n = int(data.shape[0] * (split))\n",
    "        train_data = np.vstack((train_data, data[:split_n]))\n",
    "        train_label = np.hstack((train_label, label[:split_n]))\n",
    "        test_data = np.vstack((test_data, data[split_n:]))\n",
    "        test_label = np.hstack((test_label, label[split_n:]))\n",
    "\n",
    "    return train_data, train_label, test_data, test_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T13:02:03.735968Z",
     "end_time": "2023-04-20T13:02:04.253439Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:15<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84503, 249, 36)\n",
      "(84503,)\n",
      "(21132, 249, 36)\n",
      "(21132,)\n"
     ]
    }
   ],
   "source": [
    "data_list = os.listdir('rns_test_cache')\n",
    "\n",
    "train_data, train_label, test_data, test_label = get_data(data_list, split=0.8)\n",
    "# data, label,_,_ = get_data(data_list, split=1)\n",
    "# train_data, test_data, train_label, test_label = sklearn.model_selection.train_test_split(data, label, test_size=0.8, random_state=42)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T13:02:41.503954Z",
     "end_time": "2023-04-20T13:02:58.957464Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "5320.0"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T13:02:58.959467Z",
     "end_time": "2023-04-20T13:02:59.939358Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# ckpt = torch.load(\"rns_ckpt/checkpoint31.pth\")\n",
    "resnet = torchvision.models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "swav = SwaV(backbone)\n",
    "# swav.load_state_dict(ckpt['model_state_dict'])\n",
    "model = SupervisedDownstream(backbone, 1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "checkpoint_callback = pl_callbacks.ModelCheckpoint(monitor='val_loss',\n",
    "                                                   filename='swav_pretrained-{epoch:02d}-{val_loss:.5f}',\n",
    "                                                   dirpath='rns_linear_checkpoints', every_n_epochs=5)\n",
    "csv_logger = pl_loggers.CSVLogger(\"rns_linear_logs\", name=\"logger\")\n",
    "\n",
    "trainer = pl.Trainer(logger=csv_logger, max_epochs=80, callbacks=[checkpoint_callback], accelerator='gpu', devices=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T13:05:17.950211Z",
     "end_time": "2023-04-20T13:05:19.111263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T13:05:21.246205Z",
     "end_time": "2023-04-20T20:47:49.217427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick Xu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:616: UserWarning: Checkpoint directory C:\\Users\\Patrick Xu\\Desktop\\RNS_Annotation_Project\\rns_linear_checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | backbone | Sequential | 23.5 M\n",
      "1 | fc1      | Linear     | 1.0 M \n",
      "2 | fc2      | Linear     | 32.8 K\n",
      "3 | fc3      | Linear     | 520   \n",
      "4 | fc4      | Linear     | 18    \n",
      "5 | softmax  | Softmax    | 0     \n",
      "----------------------------------------\n",
      "24.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.6 M    Total params\n",
      "98.362    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "(84503, 249, 36)\n",
      "(84503,)\n",
      "data loaded\n",
      "(21132, 249, 36)\n",
      "(21132,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf9793df4ae54e82a9d630ef96c4185a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick Xu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Patrick Xu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc527ba8ec9a4f21a27b301745fffb35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c776a4ac232b4edcb03fe61ccf6187d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64ff1807589447d4b75ee073e9a403a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8563857343844a0b9742291060b1f72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8df1a7b997043988bf93154d4fd663b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0784fcaa5ded4d19864036c88edfc673"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddcbd1aacbc6461b8b5efdf791138054"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4105187dea74123b4208bd19944c8b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "908b3b66b8dd4a87b523ca3122b2f549"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8d20785eda440e996e9392a05bf950f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb037ee71db54efe9d56b1e01a41b08a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99255f966b0c4f9fb469b1a9cb359559"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ff6bac43b914e33bd2e45df0b7d5e01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bab44c6d530d471f9125223eda02468b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f9b79f693fc4d9cb9c44f419893394d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "218a623b6f884e1386c68510669721d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e08e7800d084572976ea8f124ebc578"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf62e8570c264c50aca7915816e2ed3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f4f0d9680104a71be91d927b58b3fb1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24b48d5a56c74470b335331ccb9d3355"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d64ccdba9d24dcc9fbbbbc9326fc056"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44117cddac2145838a906c3e8e49e9ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13e0ba845b784403a8b639bfa2d1eb1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ee1da1a873c436cb438978ca3c48333"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "007d2917715b4b978c9fad930fec6801"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9432e9fb48834d28aeb39938508229a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fee75c4881f34c689a40c84cb512e31e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e3916ed519c48698b566c7c7bc2f2eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "817bd5e5679b40efa1ab207a6e85713e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce9e990628c6452f9fbc48ca7e2f4aa5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e25cdb32451a4840ba6e1aa5032e85cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "843f22dc0e6e4e239e36c37912fe1af5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d30fe35556b4e72b572cc3ca00ac889"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16ba5e3c9b4040e087f09389d18e9b19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5af8b4d0722e4adc8489bd357891295f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a36f078c365245d68af114d5f51f7681"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1aa240da486741769795d3e9f6a150a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13ba37ebe45b4e259c2f77a70d4087a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5688e3faf6c44f10b66330f61146ee43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cef941edb8b240e0b476ef775262b968"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34971ac847fc4d00a96fc0807e2de693"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "962367f9f38c4948a3b55dbcb25485c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4c43a45abd24e0e936e258148dcebd0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b575fe6eff1427f95c2065120c5f338"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf404041d0474d13b7a9b2ed59b8dc07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04c31d1f255d486a8c6121d7cf95c8ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d99572b3da78410798d74142cbb46803"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "713a1404410845fd99b0c0370f9ebff9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8131731bc43e43c081f03b4706ee8d37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acfe8ef56b5f44e19f8b596bf925d58f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a97d8c811cb641409d0118ff800a808d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick Xu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RNS_Downstream(train_data, train_label, transform=True, astensor=True)\n",
    "test_dataset = RNS_Downstream(test_data, test_label, transform=False, astensor=True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset = RNS_Downstream(test_data, test_label, transform=False, astensor=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T19:17:54.164779Z",
     "end_time": "2023-04-19T19:17:55.165689Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = trainer.predict(model, val_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T19:17:55.160685Z",
     "end_time": "2023-04-19T19:18:11.325567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_list = []\n",
    "target_list = []\n",
    "emb_list = []\n",
    "m = nn.Softmax(dim=1)\n",
    "for pred, y, emb in predictions:\n",
    "    output_list.append(pred)\n",
    "    target_list.append(y)\n",
    "    emb_list.append(emb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T06:30:51.238121Z",
     "end_time": "2023-04-19T06:30:51.775610Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T06:30:51.775610Z",
     "end_time": "2023-04-19T06:30:52.323108Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_raw = torch.vstack(output_list)\n",
    "target = torch.vstack(target_list)\n",
    "emb = torch.vstack(emb_list)\n",
    "out = torch.argmax(pred_raw, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T06:30:52.324108Z",
     "end_time": "2023-04-19T06:30:52.889624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.sum(target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T06:30:52.890624Z",
     "end_time": "2023-04-19T06:30:53.454137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(torch.argmax(pred_raw, dim=1), target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T06:30:53.454137Z",
     "end_time": "2023-04-19T06:30:54.005638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf_report = sklearn.metrics.classification_report(torch.argmax(pred_raw, dim=1), target, digits=6)\n",
    "\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T06:30:54.005638Z",
     "end_time": "2023-04-19T06:30:54.635308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T06:30:54.633307Z",
     "end_time": "2023-04-19T06:30:55.211158Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T06:30:55.211158Z",
     "end_time": "2023-04-19T06:30:55.746644Z"
    }
   },
   "outputs": [],
   "source": [
    "len(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T06:30:55.747645Z",
     "end_time": "2023-04-19T06:31:52.531071Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_comp_n = 30\n",
    "batch_size = 32\n",
    "\n",
    "pca = PCA(n_components=pca_comp_n, copy=True).fit(emb)\n",
    "p = pca.transform(emb)\n",
    "\n",
    "# ind = np.random.choice(len(emb), 10000)\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=75, random_state=142, init='pca')\n",
    "z = tsne.fit_transform(emb)\n",
    "interictal_inds = np.where(target == 0)[0]\n",
    "ictal_inds = np.where(target == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T06:31:52.532072Z",
     "end_time": "2023-04-19T06:31:53.167154Z"
    }
   },
   "outputs": [],
   "source": [
    "spc = z\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(spc[interictal_inds,0],spc[interictal_inds,1],c='gold',label= 'interictal')\n",
    "plt.scatter(spc[ictal_inds, 0], spc[ictal_inds, 1], c='royalblue', label='ictal')\n",
    "plt.title('Swav Embedding t-SNE')\n",
    "plt.xlabel('comp 1')\n",
    "plt.ylabel(\"comp 2\")\n",
    "plt.legend()\n",
    "plt.xlim(-67, 74)\n",
    "plt.ylim(-67, 75)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T06:31:53.149137Z",
     "end_time": "2023-04-19T06:31:53.821331Z"
    }
   },
   "outputs": [],
   "source": [
    "# dt = np.vstack((z[:,0], z[:,1])).T\n",
    "interactive_plot.interactive_plot(z, ['RNS026', 'HUP159', 'HUP129', 'HUP096'], data_import, color_override=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T06:31:53.822331Z",
     "end_time": "2023-04-19T06:31:54.497782Z"
    }
   },
   "outputs": [],
   "source": [
    "interactive_plot.interactive_plot(z, ['HUP159'], data_import, color_override=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    target,\n",
    "    output[:, 1],\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves:\\nVirginica vs (Setosa & Versicolor)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = torch.argmax(output, dim=1)\n",
    "output = output.detach().cpu().numpy()\n",
    "target = target.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "clf_report = sklearn.metrics.classification_report(output, target, digits=6)\n",
    "\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, label in tqdm(val_dataloader):\n",
    "    batch = batch.to(device)\n",
    "    label = label.to(device)\n",
    "    label = F.one_hot(label).squeeze()\n",
    "    outputs = model(batch)\n",
    "    print(batch)\n",
    "    loss = sigmoid_focal_loss(pred.float(), label.float(), alpha=0.5, gamma=8, reduction='mean')\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# import torch\n",
    "# import torchvision\n",
    "# from torch import nn\n",
    "#\n",
    "# from lightly.data import DINOCollateFunction, LightlyDataset\n",
    "# from lightly.loss import DINOLoss\n",
    "# from lightly.models.modules import DINOProjectionHead\n",
    "# from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "# from lightly.utils.scheduler import cosine_schedule\n",
    "#\n",
    "#\n",
    "# class DINO(torch.nn.Module):\n",
    "#     def __init__(self, backbone, input_dim):\n",
    "#         super().__init__()\n",
    "#         self.student_backbone = backbone\n",
    "#         self.student_head = DINOProjectionHead(\n",
    "#             input_dim, 512, 64, 2048, freeze_last_layer=1\n",
    "#         )\n",
    "#         self.teacher_backbone = copy.deepcopy(backbone)\n",
    "#         self.teacher_head = DINOProjectionHead(input_dim, 512, 64, 2048)\n",
    "#         deactivate_requires_grad(self.teacher_backbone)\n",
    "#         deactivate_requires_grad(self.teacher_head)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         y = self.student_backbone(x).flatten(start_dim=1)\n",
    "#         z = self.student_head(y)\n",
    "#         return z\n",
    "#\n",
    "#     def forward_teacher(self, x):\n",
    "#         y = self.teacher_backbone(x).flatten(start_dim=1)\n",
    "#         z = self.teacher_head(y)\n",
    "#         return z\n",
    "#\n",
    "#\n",
    "# resnet = torchvision.models.resnet18()\n",
    "# backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "# input_dim = 512\n",
    "# # instead of a resnet you can also use a vision transformer backbone as in the\n",
    "# # original paper (you might have to reduce the batch size in this case):\n",
    "# # backbone = torch.hub.load('facebookresearch/dino:main', 'dino_vits16', pretrained=False)\n",
    "# # input_dim = backbone.embed_dim\n",
    "#\n",
    "# model = DINO(backbone, input_dim)\n",
    "#\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model.to(device)\n",
    "#\n",
    "# # # we ignore object detection annotations by setting target_transform to return 0\n",
    "# # pascal_voc = torchvision.datasets.VOCDetection(\n",
    "# #     \"datasets/pascal_voc\", download=True, target_transform=lambda t: 0\n",
    "# # )\n",
    "# # dataset = LightlyDataset.from_torch_dataset(pascal_voc)\n",
    "# # # or create a dataset from a folder containing images or videos:\n",
    "# # # dataset = LightlyDataset(\"path/to/folder\")\n",
    "#\n",
    "# collate_fn = DINOCollateFunction(solarization_prob = 0, hf_prob = 0,vf_prob = 0,rr_prob=0,cj_prob=0,random_gray_scale=0)\n",
    "#\n",
    "# dataloader = torch.utils.data.DataLoader(\n",
    "#     train_set,\n",
    "#     batch_size=64,\n",
    "#     collate_fn=collate_fn,\n",
    "#     shuffle=True,\n",
    "#     drop_last=True,\n",
    "#     num_workers=1,\n",
    "# )\n",
    "#\n",
    "# criterion = DINOLoss(\n",
    "#     output_dim=2048,\n",
    "#     warmup_teacher_temp_epochs=5,\n",
    "# )\n",
    "# # move loss to correct device because it also contains parameters\n",
    "# criterion = criterion.to(device)\n",
    "#\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#\n",
    "# epochs = 10\n",
    "#\n",
    "# print(\"Starting Training\")\n",
    "# for epoch in range(epochs):\n",
    "#     total_loss = 0\n",
    "#     momentum_val = cosine_schedule(epoch, epochs, 0.996, 1)\n",
    "#     for views, _, _ in tqdm(dataloader):\n",
    "#         update_momentum(model.student_backbone, model.teacher_backbone, m=momentum_val)\n",
    "#         update_momentum(model.student_head, model.teacher_head, m=momentum_val)\n",
    "#         views = [view.to(device) for view in views]\n",
    "#         global_views = views[:2]\n",
    "#         teacher_out = [model.forward_teacher(view) for view in global_views]\n",
    "#         student_out = [model.forward(view) for view in views]\n",
    "#         loss = criterion(teacher_out, student_out, epoch=epoch)\n",
    "#         total_loss += loss.detach()\n",
    "#         loss.backward()\n",
    "#         # We only cancel gradients of student head.\n",
    "#         model.student_head.cancel_last_layer_gradients(current_epoch=epoch)\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#\n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "#     print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((256, 512), interpolation=T.InterpolationMode.NEAREST),\n",
    "    T.RandomApply([T.ColorJitter()], p=0.5),\n",
    "    T.RandomApply([T.GaussianBlur(kernel_size=(3, 3))], p=0.5),\n",
    "    T.RandomInvert(p=0.2),\n",
    "    T.RandomPosterize(4, p=0.2),\n",
    "])\n",
    "\n",
    "data = ictal_data_X[0]\n",
    "\n",
    "channel_index = np.arange(data.shape[0])\n",
    "np.random.shuffle(channel_index)\n",
    "data = data[channel_index]\n",
    "data = torch.from_numpy(data).clone()\n",
    "data = data.repeat(3, 1, 1)\n",
    "data = augmentation(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[channel_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# print(\"Starting Training\")\n",
    "# for epoch in range(50):\n",
    "#     total_loss = 0\n",
    "#     i = 0\n",
    "#     for batch, label in tqdm(dataloader):\n",
    "#         batch = batch.to(device)\n",
    "#         # print(type(batch))\n",
    "#         label = label.to(device)\n",
    "#         label = F.one_hot(label).squeeze()\n",
    "#         outputs = model(batch)\n",
    "#         loss = sigmoid_focal_loss(outputs.float(),label.float(), alpha = 0.25, gamma = 7,reduction = 'mean')\n",
    "#         total_loss += loss.detach()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "#\n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "#     torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': avg_loss,\n",
    "#             }, 'ckpt/checkpoint'+str(epoch)+'.pth')\n",
    "#\n",
    "#     print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
