{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T11:39:05.332854Z",
     "end_time": "2024-02-07T11:39:06.312772Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T11:39:06.312772Z",
     "end_time": "2024-02-07T11:39:10.719630Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('../tools')\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import pytorch_lightning.callbacks as pl_callbacks\n",
    "import data_utility, annotation_utility\n",
    "from models.rns_dataloader import *\n",
    "from active_learning_utility import get_strategy\n",
    "from active_learning_data import Data\n",
    "from active_learning_net import Net\n",
    "from copy import deepcopy\n",
    "from models.SwaV import SwaV\n",
    "from models.SupervisedDownstream import SupervisedDownstream\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argument*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Set a lower value for log_every_n_steps if you want to see logs for the training epoch*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T11:39:10.719630Z",
     "end_time": "2024-02-07T11:39:11.076443Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    # True ensures the algorithm selected by CUFA is deterministic\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # torch.set_deterministic(True)\n",
    "    # False ensures CUDA select the same algorithm each time the application is run\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import pytorch_lightning\n",
    "pytorch_lightning.utilities.seed.seed_everything(seed=random_seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T11:39:11.076443Z",
     "end_time": "2024-02-07T11:39:11.411541Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../../user_data/\"\n",
    "log_folder_root = '../../../user_data/logs/'\n",
    "ckpt_folder_root = '../../../user_data/checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T11:39:11.411541Z",
     "end_time": "2024-02-07T11:39:11.741540Z"
    }
   },
   "outputs": [],
   "source": [
    "strategy_name = 'LeastConfidence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T11:39:11.741540Z",
     "end_time": "2024-02-07T11:39:12.076608Z"
    }
   },
   "outputs": [],
   "source": [
    "nStart = 1\n",
    "nEnd = 20\n",
    "nQuery = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T11:39:12.076608Z",
     "end_time": "2024-02-07T11:39:12.403036Z"
    }
   },
   "outputs": [],
   "source": [
    "args_task = {'n_epoch': 100,\n",
    "             'transform_train': True,\n",
    "             'strategy_name': strategy_name,\n",
    "             'transform': False,\n",
    "             'loader_tr_args': {'batch_size': 256, 'num_workers': 4, 'collate_fn': collate_fn,\n",
    "                                'drop_last': True,'persistent_workers':True},\n",
    "             'loader_te_args': {'batch_size': 256, 'num_workers': 8, 'collate_fn': collate_fn,\n",
    "                                'drop_last': True,'persistent_workers':True}\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T11:39:12.403036Z",
     "end_time": "2024-02-07T11:39:12.733037Z"
    }
   },
   "outputs": [],
   "source": [
    "# raw_annotations = pd.read_csv(data_dir + 'full_updated_anns_annotTbl_cleaned.csv')\n",
    "# ids = list(np.unique(raw_annotations[raw_annotations['descriptions'].notnull()]['HUP_ID']))\n",
    "# # ids = list(np.unique(raw_annotations['HUP_ID']))\n",
    "#\n",
    "# data_import = data_utility.read_files(path=data_dir+'rns_data', path_data=data_dir+'rns_raw_cache', patientIDs=ids,\n",
    "#                                       verbose=True)  # Import data with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T11:39:12.733037Z",
     "end_time": "2024-02-07T11:39:30.368797Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:16<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86197, 249, 36)\n",
      "(86197,)\n",
      "(21556, 249, 36)\n",
      "(21556,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# data_list = os.listdir(data_dir+'rns_test_cache')\n",
    "# print(data_list)\n",
    "data_list = ['HUP047.npy', 'HUP084.npy', 'HUP096.npy', 'HUP109.npy', 'HUP121.npy', 'HUP129.npy', 'HUP131.npy',\n",
    "             'HUP137.npy', 'HUP147.npy', 'HUP156.npy', 'HUP159.npy', 'HUP182.npy', 'HUP197.npy', 'HUP199.npy',\n",
    "             'RNS026.npy', 'RNS029.npy']\n",
    "X_train, y_train, X_test, y_test, index_train, index_test  = get_data(data_list, split=0.8)\n",
    "# data, label,_,_ = get_data(data_list, split=1)\n",
    "# train_data, test_data, train_label, test_label = sklearn.model_selection.train_test_split(data, label, test_size=0.8, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "unique_episodes, unique_episodes_counts = np.unique(index_train[index_train['episode_index']], return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T10:51:23.870708Z",
     "end_time": "2024-02-07T10:51:24.557677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array([38, 90, 90, ..., 88, 89, 89], dtype=int64)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def indices_of_change(arr):\n",
    "    # Find indices where changes occur\n",
    "    change_indices = np.where(arr[:-1] != arr[1:])[0]\n",
    "\n",
    "    # Increment indices by 1 to get the index of the changed element\n",
    "    change_indices += 1\n",
    "\n",
    "    # Add index 0 if the first element is a change\n",
    "    if arr[0] != arr[1]:\n",
    "        change_indices = np.insert(change_indices, 0, 0)\n",
    "\n",
    "    # Add index n-1 if the last element is a change\n",
    "    if arr[-1] != arr[-2]:\n",
    "        change_indices = np.append(change_indices, len(arr) - 1)\n",
    "\n",
    "    return change_indices\n",
    "np.diff(indices_of_change(index_train['episode_index']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T13:13:37.255742Z",
     "end_time": "2024-02-07T13:13:37.788731Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 20])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [5, 8] at index 1 does not match the shape of the indexed tensor [5, 6, 20] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36m<cell line: 56>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     53\u001B[0m output \u001B[38;5;241m=\u001B[39m lstm_model(x, lengths)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# Apply mask to ignore padded positions\u001B[39;00m\n\u001B[1;32m---> 56\u001B[0m masked_output \u001B[38;5;241m=\u001B[39m \u001B[43moutput\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mview(batch_size, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, hidden_size)\n",
      "\u001B[1;31mIndexError\u001B[0m: The shape of the mask [5, 8] at index 1 does not match the shape of the indexed tensor [5, 6, 20] at index 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define your LSTM model\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Sort input sequence by length\n",
    "        sorted_lengths, sorted_idx = lengths.sort(descending=True)\n",
    "        x_sorted = x[sorted_idx]\n",
    "\n",
    "        # Pack the padded sequence\n",
    "        x_packed = nn.utils.rnn.pack_padded_sequence(x_sorted, sorted_lengths, batch_first=True)\n",
    "        # print(x_packed.size())\n",
    "        # Forward pass through LSTM\n",
    "        out_packed, _ = self.lstm(x_packed)\n",
    "        # print(out_packed.size())\n",
    "        # Unpack the output sequence\n",
    "        out_sorted, _ = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)\n",
    "        print(out_sorted.size())\n",
    "\n",
    "        # Reorder the output sequence\n",
    "        _, original_idx = sorted_idx.sort()\n",
    "        out = out_sorted[original_idx]\n",
    "\n",
    "        return out\n",
    "\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 2\n",
    "batch_size = 5\n",
    "max_seq_length = 8\n",
    "\n",
    "# Random input sequence\n",
    "x = torch.randn(batch_size, max_seq_length, input_size)\n",
    "\n",
    "# Generate random lengths for each sequence in the batch\n",
    "lengths = torch.randint(1, max_seq_length, (batch_size,))\n",
    "\n",
    "# Masking: Create mask tensor where padded positions are 0 and others are 1\n",
    "mask = torch.arange(max_seq_length).expand(len(lengths), max_seq_length) < lengths.unsqueeze(1)\n",
    "\n",
    "# Create LSTM model instance\n",
    "lstm_model = MyLSTM(input_size, hidden_size, num_layers)\n",
    "\n",
    "# Forward pass\n",
    "output = lstm_model(x, lengths)\n",
    "\n",
    "# Apply mask to ignore padded positions\n",
    "masked_output = output[mask].view(batch_size, -1, hidden_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Sample dataset with varying sequence lengths\n",
    "class VariableLengthDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Function to pad and pack sequences\n",
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True)  # Sort by sequence length\n",
    "    sequences, labels = zip(*batch)\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True)\n",
    "    lengths = [len(seq) for seq in sequences]\n",
    "    return sequences_padded, torch.tensor(labels), lengths\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Pack the sequence\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        packed_output, (ht, ct) = self.lstm(packed_input)\n",
    "        # We use the last hidden state to classify\n",
    "        output = self.fc(ht[-1])\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "input_size = 10  # Number of features\n",
    "hidden_size = 50\n",
    "output_size = 2  # Number of output classes\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Assuming 'data' is your dataset of variable-length sequences and 'labels' their corresponding labels\n",
    "dataset = VariableLengthDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for sequences, labels, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, lengths)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 8])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T13:18:32.086718Z",
     "end_time": "2024-02-07T13:18:32.400318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 5, 20])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T13:18:40.333289Z",
     "end_time": "2024-02-07T13:18:40.653435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 7, 20])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T13:16:40.265014Z",
     "end_time": "2024-02-07T13:16:40.604301Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T12:20:18.597857Z",
     "end_time": "2024-02-07T12:20:19.688667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861\n",
      "1723\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "n_pool = len(y_train)\n",
    "n_test = len(y_test)\n",
    "\n",
    "NUM_INIT_LB = int(nStart * n_pool / 100)\n",
    "NUM_QUERY = int(nQuery * n_pool / 100) if nStart != 100 else 0\n",
    "NUM_ROUND = int((int(nEnd * n_pool / 100) - NUM_INIT_LB) / NUM_QUERY) if nStart != 100 else 0\n",
    "if NUM_QUERY != 0:\n",
    "    if (int(nEnd * n_pool / 100) - NUM_INIT_LB) % NUM_QUERY != 0:\n",
    "        NUM_ROUND += 1\n",
    "\n",
    "print(NUM_INIT_LB)\n",
    "print(NUM_QUERY)\n",
    "print(NUM_ROUND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T12:20:19.959804Z",
     "end_time": "2024-02-07T12:20:20.294079Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Data(X_train, y_train, X_test, y_test, RNS_Downstream, args_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T12:20:22.396893Z",
     "end_time": "2024-02-07T12:20:23.596468Z"
    }
   },
   "outputs": [],
   "source": [
    "swav = SwaV().load_from_checkpoint(\n",
    "    ckpt_folder_root + 'rns_swav_50_12/rns_swav-epoch=82-swav_loss=2.58204.ckpt')\n",
    "model = SupervisedDownstream(swav.backbone)\n",
    "# initialize model and save the model state\n",
    "modelstate = deepcopy(model.state_dict())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "net = Net(model, args_task, device, ckpt_folder_root = 'rns_active', log_folder_root = 'rns_active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-07T12:20:25.722293Z",
     "end_time": "2024-02-07T12:20:26.171327Z"
    }
   },
   "outputs": [],
   "source": [
    "strategy = get_strategy(strategy_name, dataset, net, None, args_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\RNS_Annotation-Pipeline\\scripts\\RNS_LITT_ANNOTATION_PIPELINE\\rns_scripts\\../tools\\query_strategies\\strategy.py:67\u001B[0m, in \u001B[0;36mStrategy.get_embeddings\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_embeddings\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[1;32m---> 67\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m embeddings\n",
      "File \u001B[1;32m~\\Desktop\\RNS_Annotation-Pipeline\\scripts\\RNS_LITT_ANNOTATION_PIPELINE\\rns_scripts\\../tools\\active_learning_net.py:148\u001B[0m, in \u001B[0;36mNet.get_embeddings\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_embeddings\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[1;32m--> 148\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_prediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    149\u001B[0m     emb_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m pred, y, emb \u001B[38;5;129;01min\u001B[39;00m predictions:\n",
      "File \u001B[1;32m~\\Desktop\\RNS_Annotation-Pipeline\\scripts\\RNS_LITT_ANNOTATION_PIPELINE\\rns_scripts\\../tools\\active_learning_net.py:75\u001B[0m, in \u001B[0;36mNet.run_prediction\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_prediction\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[0;32m     74\u001B[0m     loader \u001B[38;5;241m=\u001B[39m DataLoader(data, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloader_te_args\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 75\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predictions\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:949\u001B[0m, in \u001B[0;36mTrainer.predict\u001B[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001B[0m\n\u001B[0;32m    924\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    925\u001B[0m \u001B[38;5;124;03mRun inference on your data.\u001B[39;00m\n\u001B[0;32m    926\u001B[0m \u001B[38;5;124;03mThis will call the model forward function to compute predictions. Useful to perform distributed\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m \u001B[38;5;124;03m    Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.\u001B[39;00m\n\u001B[0;32m    947\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m model \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module\n\u001B[1;32m--> 949\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    950\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_predictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    951\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001B[0m, in \u001B[0;36mTrainer._call_and_handle_interrupt\u001B[1;34m(self, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    648\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    649\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 650\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    651\u001B[0m \u001B[38;5;66;03m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001B[39;00m\n\u001B[0;32m    652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:996\u001B[0m, in \u001B[0;36mTrainer._predict_impl\u001B[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001B[0m\n\u001B[0;32m    990\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__set_ckpt_path(\n\u001B[0;32m    991\u001B[0m     ckpt_path, model_provided\u001B[38;5;241m=\u001B[39mmodel_provided, model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    992\u001B[0m )\n\u001B[0;32m    994\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predicted_ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mckpt_path  \u001B[38;5;66;03m# TODO: remove in v1.8\u001B[39;00m\n\u001B[1;32m--> 996\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    998\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    999\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1166\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m   1162\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mrestore_training_state()\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mresume_end()\n\u001B[1;32m-> 1166\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1168\u001B[0m log\u001B[38;5;241m.\u001B[39mdetail(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1169\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_teardown()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1251\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1249\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_evaluate()\n\u001B[0;32m   1250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[1;32m-> 1251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_train()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1307\u001B[0m, in \u001B[0;36mTrainer._run_predict\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[_PREDICT_OUTPUT]:\n\u001B[1;32m-> 1307\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset_predict_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlightning_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1308\u001B[0m     \u001B[38;5;66;03m# reset trainer on this loop and all child loops in case user connected a custom loop\u001B[39;00m\n\u001B[0;32m   1309\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_loop\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1961\u001B[0m, in \u001B[0;36mTrainer.reset_predict_dataloader\u001B[1;34m(self, model)\u001B[0m\n\u001B[0;32m   1959\u001B[0m enable_prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlimit_predict_batches \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m source\u001B[38;5;241m.\u001B[39mis_defined() \u001B[38;5;129;01mand\u001B[39;00m enable_prediction:\n\u001B[1;32m-> 1961\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_predict_batches, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_dataloaders \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_connector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reset_eval_dataloader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1962\u001B[0m \u001B[43m        \u001B[49m\u001B[43mRunningStage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPREDICTING\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpl_module\u001B[49m\n\u001B[0;32m   1963\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:385\u001B[0m, in \u001B[0;36mDataConnector._reset_eval_dataloader\u001B[1;34m(self, mode, model)\u001B[0m\n\u001B[0;32m    377\u001B[0m     apply_to_collection(\n\u001B[0;32m    378\u001B[0m         loader\u001B[38;5;241m.\u001B[39mloaders \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(loader, CombinedLoader) \u001B[38;5;28;01melse\u001B[39;00m loader,\n\u001B[0;32m    379\u001B[0m         DataLoader,\n\u001B[0;32m    380\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_eval_shuffling,\n\u001B[0;32m    381\u001B[0m         mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[0;32m    382\u001B[0m     )\n\u001B[0;32m    384\u001B[0m \u001B[38;5;66;03m# add samplers\u001B[39;00m\n\u001B[1;32m--> 385\u001B[0m dataloaders \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_dataloader(dl, mode\u001B[38;5;241m=\u001B[39mmode) \u001B[38;5;28;01mfor\u001B[39;00m dl \u001B[38;5;129;01min\u001B[39;00m dataloaders \u001B[38;5;28;01mif\u001B[39;00m dl \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[0;32m    387\u001B[0m \u001B[38;5;66;03m# add worker_init_fn for correct seeding in worker processes\u001B[39;00m\n\u001B[0;32m    388\u001B[0m apply_to_collection(\n\u001B[0;32m    389\u001B[0m     dataloaders, dtype\u001B[38;5;241m=\u001B[39mDataLoader, function\u001B[38;5;241m=\u001B[39m_auto_add_worker_init_fn, rank\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mglobal_rank\n\u001B[0;32m    390\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:385\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    377\u001B[0m     apply_to_collection(\n\u001B[0;32m    378\u001B[0m         loader\u001B[38;5;241m.\u001B[39mloaders \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(loader, CombinedLoader) \u001B[38;5;28;01melse\u001B[39;00m loader,\n\u001B[0;32m    379\u001B[0m         DataLoader,\n\u001B[0;32m    380\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_eval_shuffling,\n\u001B[0;32m    381\u001B[0m         mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[0;32m    382\u001B[0m     )\n\u001B[0;32m    384\u001B[0m \u001B[38;5;66;03m# add samplers\u001B[39;00m\n\u001B[1;32m--> 385\u001B[0m dataloaders \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m dl \u001B[38;5;129;01min\u001B[39;00m dataloaders \u001B[38;5;28;01mif\u001B[39;00m dl \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[0;32m    387\u001B[0m \u001B[38;5;66;03m# add worker_init_fn for correct seeding in worker processes\u001B[39;00m\n\u001B[0;32m    388\u001B[0m apply_to_collection(\n\u001B[0;32m    389\u001B[0m     dataloaders, dtype\u001B[38;5;241m=\u001B[39mDataLoader, function\u001B[38;5;241m=\u001B[39m_auto_add_worker_init_fn, rank\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mglobal_rank\n\u001B[0;32m    390\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:296\u001B[0m, in \u001B[0;36mDataConnector._prepare_dataloader\u001B[1;34m(self, dataloader, shuffle, mode)\u001B[0m\n\u001B[0;32m    293\u001B[0m         shuffle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m RunningStage\u001B[38;5;241m.\u001B[39mTRAINING \u001B[38;5;28;01melse\u001B[39;00m _is_dataloader_shuffled(dataloader)\n\u001B[0;32m    295\u001B[0m     sampler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resolve_sampler(dataloader, shuffle\u001B[38;5;241m=\u001B[39mshuffle, mode\u001B[38;5;241m=\u001B[39mmode)\n\u001B[1;32m--> 296\u001B[0m     dataloader \u001B[38;5;241m=\u001B[39m \u001B[43m_update_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    298\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mprocess_dataloader(dataloader)\n\u001B[0;32m    300\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cycle_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:202\u001B[0m, in \u001B[0;36m_update_dataloader\u001B[1;34m(dataloader, sampler, mode)\u001B[0m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_dataloader\u001B[39m(\n\u001B[0;32m    200\u001B[0m     dataloader: DataLoader, sampler: Union[Sampler, Iterable], mode: Optional[RunningStage] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    201\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataLoader:\n\u001B[1;32m--> 202\u001B[0m     dl_args, dl_kwargs \u001B[38;5;241m=\u001B[39m \u001B[43m_get_dataloader_init_args_and_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    203\u001B[0m     dataloader \u001B[38;5;241m=\u001B[39m _reinstantiate_wrapped_cls(dataloader, \u001B[38;5;241m*\u001B[39mdl_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdl_kwargs)\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dataloader\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:250\u001B[0m, in \u001B[0;36m_get_dataloader_init_args_and_kwargs\u001B[1;34m(dataloader, sampler, mode, disallow_batch_sampler)\u001B[0m\n\u001B[0;32m    246\u001B[0m         params\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m was_wrapped:\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;66;03m# keep only the params whose default is different to the current attr value\u001B[39;00m\n\u001B[1;32m--> 250\u001B[0m     non_defaults \u001B[38;5;241m=\u001B[39m {name \u001B[38;5;28;01mfor\u001B[39;00m name, p \u001B[38;5;129;01min\u001B[39;00m params\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m attrs \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mdefault \u001B[38;5;241m!=\u001B[39m attrs[name]}\n\u001B[0;32m    252\u001B[0m     \u001B[38;5;66;03m# add `dataset` as it might have been replaced with `*args`\u001B[39;00m\n\u001B[0;32m    253\u001B[0m     non_defaults\u001B[38;5;241m.\u001B[39madd(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:250\u001B[0m, in \u001B[0;36m<setcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    246\u001B[0m         params\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m was_wrapped:\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;66;03m# keep only the params whose default is different to the current attr value\u001B[39;00m\n\u001B[1;32m--> 250\u001B[0m     non_defaults \u001B[38;5;241m=\u001B[39m {name \u001B[38;5;28;01mfor\u001B[39;00m name, p \u001B[38;5;129;01min\u001B[39;00m params\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m attrs \u001B[38;5;129;01mand\u001B[39;00m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefault\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m}\n\u001B[0;32m    252\u001B[0m     \u001B[38;5;66;03m# add `dataset` as it might have been replaced with `*args`\u001B[39;00m\n\u001B[0;32m    253\u001B[0m     non_defaults\u001B[38;5;241m.\u001B[39madd(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "train_emb = strategy.get_embeddings(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T13:09:20.469503Z",
     "end_time": "2024-01-24T13:16:57.942466Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "data loaded\n",
      "(0, 249, 36)\n",
      "(0,)\n",
      "data loaded\n",
      "(21556, 249, 36)\n",
      "(21556,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# initial round of training, round 0\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# dataset.initialize_labels(NUM_INIT_LB)\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\RNS_Annotation-Pipeline\\scripts\\RNS_LITT_ANNOTATION_PIPELINE\\rns_scripts\\../tools\\query_strategies\\strategy.py:38\u001B[0m, in \u001B[0;36mStrategy.train\u001B[1;34m(self, data, model_name)\u001B[0m\n\u001B[0;32m     33\u001B[0m     labeled_idxs, labeled_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mget_labeled_data()\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;66;03m# print([d.shape for d in labeled_data.data])\u001B[39;00m\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;66;03m# print([d.shape for d in self.dataset.get_test_data().data])\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabeled_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_test_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet\u001B[38;5;241m.\u001B[39mtrain(data)\n",
      "File \u001B[1;32m~\\Desktop\\RNS_Annotation-Pipeline\\scripts\\RNS_LITT_ANNOTATION_PIPELINE\\rns_scripts\\../tools\\active_learning_net.py:66\u001B[0m, in \u001B[0;36mNet.train\u001B[1;34m(self, data, test_data)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m test_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     testloader \u001B[38;5;241m=\u001B[39m DataLoader(test_data, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloader_te_args\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 66\u001B[0m     loader \u001B[38;5;241m=\u001B[39m DataLoader(data, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloader_tr_args\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mfit(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet, loader, testloader)\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:353\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# map-style\u001B[39;00m\n\u001B[0;32m    352\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[1;32m--> 353\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m \u001B[43mRandomSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    354\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    355\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\sampler.py:107\u001B[0m, in \u001B[0;36mRandomSampler.__init__\u001B[1;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement should be a boolean value, but got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    104\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement))\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 107\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_samples should be a positive integer \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    108\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue, but got num_samples=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples))\n",
      "\u001B[1;31mValueError\u001B[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# initial round of training, round 0\n",
    "# dataset.initialize_labels(NUM_INIT_LB)\n",
    "strategy.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# q_idxs = strategy.query(NUM_QUERY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:16:57.943464Z",
     "end_time": "2024-01-24T13:16:58.259139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "(21556, 249, 36)\n",
      "(21556,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c9f995c94784bf0a3357ee687b0e837"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unlabeled_data = strategy.dataset.get_test_data()\n",
    "test_emb = strategy.get_embeddings(unlabeled_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T12:36:28.753615Z",
     "end_time": "2024-02-07T12:37:08.103102Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "np.save(data_dir + 'rns_emb/test_emb.npy', test_emb.cpu().detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T12:39:00.513174Z",
     "end_time": "2024-02-07T12:39:01.170675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([21556, 2048])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emb.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T12:39:08.549554Z",
     "end_time": "2024-02-07T12:39:08.872077Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "unique_episodes, unique_episodes_counts = np.unique(index_train[unlabeled_idxs]['episode_index'], return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:20:33.456769Z",
     "end_time": "2024-01-24T13:20:34.703301Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  3.05195380000805\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "uncertainties = probs.max(1)[0]\n",
    "orders = torch.sort(uncertainties,stable = True)[1]\n",
    "ranks = torch.argsort(orders)\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "rank_list = [ranks[index_train[unlabeled_idxs]['episode_index'] == epi_ind]for epi_ind in unique_episodes]\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time: \", elapsed_time)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:20:34.705298Z",
     "end_time": "2024-01-24T13:20:38.095459Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "first_n = 5000\n",
    "from copy import deepcopy\n",
    "emission_table = []\n",
    "rank_list_copy = deepcopy(rank_list)\n",
    "emission_table = [torch.where(rl < first_n, 0.85, 0.15) for rl in rank_list_copy]\n",
    "rank_list_copy = deepcopy(rank_list)\n",
    "active_rank_list = [torch.where(rl < first_n, 1, 0) for rl in rank_list_copy]\n",
    "ordered_rank_list = []\n",
    "rank_list_copy = deepcopy(rank_list)\n",
    "active_rank_list = [torch.where(rl < first_n, rl, 0) for rl in rank_list_copy]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:20:38.097504Z",
     "end_time": "2024-01-24T13:20:38.517220Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 866,  820,  107,  339,  654,  395,  833,  407,  158,  122,  364,  741,\n         167,  382,   12,  363,  799,  360,  304,  359,  343,  387,  956,  838,\n         345,  126,  162,  789,  720,  168,   34,  624,  223,  369,  491,   22,\n         490,  926,  414,  904,  787,    1,  119,  296,    3,   96,  769,  816,\n         412,  396,  665,  217,  973,  934,  328,  770,  264,  410,  790,  664,\n         262,   40,  607,  850,   51,  771,  511,  795,  831,  922,  828,    0,\n         150,  468,  842,  219,  498,  136,  792,  885,  367,  228,  557,  449,\n         878,  178,  314,  946,  967,  752,  921,  205,  586,  915,  415,   80,\n         517,  212,  569,  313,   83,   36,  151,  311,  893,  527,  729,  202,\n         626,  848,  406,  465,  994,  213,  951,  867,  577,   89,  435,   71,\n          75,   15,  639,   43,  907,  454,  445,  444,  349,  287,  604,  398,\n         821,   47,  943,  199,  279,  225,  473,  611,  616,  270,  553,   52,\n         470,  222,   11,  901,  909,  810,  644,  409,   31,  750,  431,  911,\n         372,  441,  753,  555,  277,  602,  938,  992,  642,  523,  436,  457,\n         532,  649,  316,  755,  499,  995,  629,  317,  148,  346,  188,  737,\n         751,  863,   90,  633,  676,  793,  440,  924,  812,  286,  923,  673,\n         489,  309,  844,  668,  320,  243,  102,  303,   50,  291,  478,  236,\n         589,  348,  686,   10,  706,  745,  239,  614,  983,  829,  408,  684,\n         997,  912,   76,  112,  429,  638,  376,  391,  187,  711,  252,   98,\n         839,  546,  514,  718,  451,  161,  622,  660,  508,  655,  450,  131,\n         352,  989,   99,  824,    9,  486,  315,  525,  141,   42,  332,  526,\n         681,  662,  853,  469,  132,  759,  698,  453,  380,  535,  402,  545,\n         763,   29,  114,  181,  708,  724,  479,  674,  544,  377,  757,  179,\n         458,  583,  246,  814,  503,  804,  461,  497,  298,  897,  182,  974,\n         742, 1001,  782,  446,  558,  336,   97,  506,  723,  585,  778,  733,\n         434,  932,  559,  652,  221,  962,  195,  519,  691,  948,  702,  319,\n         293,  416,  292,  615,  267,   59,  487,  552,  153,  456,  646,  520,\n         442,  428,  280,  171,  115,  482,  327,  504,  965,  917,  717,  578,\n         138,  743,  653,   58,   38,  448,  964,  845,  501,  389,  477,   18,\n         183,  423,  329,  953,  823,  635,  937,  347,  588,  564,  949,  645,\n         719,   24,  308,  500,  576,  341,  325,  591,  103,  401,  651,  560,\n         773,  301,  947,   17,  647, 1002,  231,  933,  518,  536,  522,  509,\n          93,  658,  547,  235,  160,  714,  971,  105,  326,  944,  699,  841,\n         781,  865,  467,  732,  727,  648,  817,  960,  370,  492,  679,  991,\n         554,  600,  123,  688,  108,  430,  422,  247,  254,   26,    4,   94,\n          73,  979,  340,  562,  657,  455,  496,  310,  238,  275,  976,  521,\n         996,  248,   39,  725,  334,  567,   87,  985,  420,  256,  350,  659,\n         140,  570,  333,  747,  507,  683,  895,  208,  625,  972,  530,  548,\n          28,  237,  273,  230,  998,  268,  118,  300,  220,  988,   25,  677,\n         177,  452,  734,  650,  786,  419,  322,  515,  620,   45,   68,  970,\n         371,  889,  945,  631,  746,  531,  641,    7,  374,  133,  982,  335,\n         324,  656,  476,  488,  801,  599,  920,  288,   67,  595,  368,  302,\n         672,  634,  627,  111,   13,  338,  618,  661,  284,   81,  110,  196,\n         692,  735,  788,  472,  700,   53,  785,  121,  754,   70,  459,  147,\n         137,  229,   35,  966,  185,   32,  736,  542,  538,  959,  249,  203,\n         510,  612,   64,  669,  791,  282,  572,  355,  617,  883,  935,  537,\n         516,  685,  251,  906,  425,   27,  351,  318,  539,  780,  101,  818,\n         925,  993,  703,  744, 1000,  294,  619,  154,  571,  977,  563,  232,\n         894,   57,  550,  808,  253,   61,  134,  721,  899,  881,  257,  240,\n         819,  443,  940,  667,  265,  666,  565,  142,  930,   37,  331,  144,\n         528,  927,  432,  969,  766,  474,  480,  373,  540,  337,  263,  890,\n         663,  250,  365,  471,  756,  859,    6,  675,  610,  916,  386,  696,\n         643,  739,  767,  165,  438,  809,  873,  587,  608,  712,   56,  980,\n         961,  593,  954,  903,  779,  464,  299,  146,  433,  283,  116,  748,\n         505,  687,  447,  832,  918,  900,  847,  321,  835,  854,  975,  952,\n         242,  621,  534,  730,   62,  353,  722,  437,  978,  533,  936,    5,\n         957,  713,  384,  295,  707,  529,  421,  758,  566,  330,  494,  826,\n         716,  671,   54,  913,  174,  342,  106,  984,  990,  190,  636,  426,\n         224,  424,  704,  524,   65,  357,   23,  125,    8,  598,   85,  128,\n         485,  427,  481,  963,  366,   44,  152,   74,  939,  543,  272,  245,\n         834,  999,  381,  981,  740,  568,  628,  439,  605,  143,  307,   46,\n         512,  411,  117,  176,  200,  783,  460,  726,  362,  104,  484,  705,\n         987,  908,  393,  483,  798,   82,  312,  495,  868,  463,  764,  156,\n         892,  269,  601,  244,   41,   69,  637,  968,   49,  197,  775,  887,\n         761,  682,   66,   60,  297,  255,  241,  266,  561,  955,  129,  870,\n         306,  139,   33,  259,  169,  760,  613,  390,  836,  541,  840,  590,\n         582,  493,  882,   63,  862,  323,  260,  172,  502,  827,  234,  574,\n         689,  399,  777,  898,  405,  986,  135,  289,  100,  383,  513,  884,\n         354,    2,  858,   88,  765,  749,  271,  891,  851,  164,  888,   48,\n         305,   79,  549,  356,  919,  379,  584,   77,  774,  109,  931,  768,\n         385,  896,  958,  462,  261,   30,  551,  191,   72,  941,  942,  580,\n          86,  581,  274,  914,  120,  155,  640,  772,  211,  815,  606,  609,\n         869,  690,  680,   55,  207,  573,  905,  466,  693,  738,  157,  361,\n         344,  378,  233,   14,  210,   21,   91,  556,  852,  163,  670,  194,\n         871,  697,  206,  579,  404,  124,  358,  475,  860,  802,  630,  800,\n         709,  910,  837,  173])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rank = torch.sort(torch.tensor([torch.sum(rl)/(torch.count_nonzero(rl)+1e-6) for rl in active_rank_list]))\n",
    "episode_rank = avg_rank[1][avg_rank[0]>0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:25:16.658209Z",
     "end_time": "2024-01-24T13:25:17.020463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0, 102])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_rank_list[395]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:25:48.967333Z",
     "end_time": "2024-01-24T13:25:49.282073Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "s = []\n",
    "for ls in active_rank_list:\n",
    "    s.append(torch.sum(ls))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T11:11:05.519843Z",
     "end_time": "2024-01-24T11:11:05.842013Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.sort(\nvalues=tensor([25, 24, 24,  ...,  0,  0,  0]),\nindices=tensor([ 648,  537,  535,  ...,  388,  290, 1003]))"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(torch.tensor(s),descending =True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T11:11:09.945738Z",
     "end_time": "2024-01-24T11:11:10.268179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n        1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0])"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[torch.argsort(torch.tensor(s),descending =True)[2]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.69920319, 0.30079681])"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.HMM import HMM\n",
    "\n",
    "hmm = HMM(active_rank_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T11:13:19.385073Z",
     "end_time": "2024-01-24T11:13:20.257784Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  1.3014186000073096\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "filtered_list = []\n",
    "for i in range(len(active_rank_list)):\n",
    "    emission_mat_1 = emission_table[i]\n",
    "    emission_mat_0 = 1-emission_mat_1\n",
    "    emission_mat = torch.vstack([emission_mat_1,emission_mat_0]).T\n",
    "    predicted_label = 1 - hmm.predict_labels(active_rank_list[i].numpy(), emission_mat.numpy())\n",
    "    filtered_list.append(predicted_label)\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time: \", elapsed_time)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T11:19:16.551710Z",
     "end_time": "2024-01-24T11:19:18.158516Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "def filter_continuous_positive(array, length_m):\n",
    "\n",
    "    # Find the indices where 1s start and end\n",
    "    start_indices = np.where(np.diff(array) == 1)[0] + 1\n",
    "    end_indices = np.where(np.diff(array) == -1)[0]\n",
    "\n",
    "    if array[0] == 1:\n",
    "        start_indices = np.insert(start_indices, 0, 0)\n",
    "    if array[-1] == 1:\n",
    "        end_indices = np.append(end_indices, len(array) - 1)\n",
    "\n",
    "    lengths = end_indices - start_indices + 1\n",
    "\n",
    "    filtered_indices = start_indices[lengths > length_m]\n",
    "    filtered_lengths = lengths[lengths>length_m]\n",
    "\n",
    "    result_array = np.zeros_like(array)\n",
    "    for start_idx,length in zip(filtered_indices,filtered_lengths):\n",
    "        result_array[start_idx:start_idx + length] = 1\n",
    "\n",
    "    return result_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:05:19.458609Z",
     "end_time": "2024-01-24T13:05:19.949917Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  0.029054699989501387\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.perf_counter()\n",
    "filtered_filtered_list = [filter_continuous_positive(arr,9) for arr in filtered_list]\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time: \", elapsed_time)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:05:21.250307Z",
     "end_time": "2024-01-24T13:05:21.610353Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "data": {
      "text/plain": "2161"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([np.sum(arr) for arr in filtered_filtered_list])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:05:22.540992Z",
     "end_time": "2024-01-24T13:05:22.986399Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "data": {
      "text/plain": "(85336,)"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(filtered_filtered_list).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T13:05:24.026258Z",
     "end_time": "2024-01-24T13:05:24.369213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-10T15:41:49.731496Z",
     "end_time": "2023-11-11T01:20:27.124530Z"
    }
   },
   "outputs": [],
   "source": [
    "for rd in range(1, NUM_ROUND +1):\n",
    "    print('round ' + str(rd))\n",
    "    q_idxs = strategy.query(NUM_QUERY)\n",
    "    strategy.update(q_idxs)\n",
    "    strategy.net.round = rd\n",
    "    strategy.net.net.load_state_dict(modelstate)\n",
    "    strategy.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
