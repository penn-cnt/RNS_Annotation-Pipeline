{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-02-07T17:47:57.276319Z",
     "end_time": "2024-02-07T17:47:58.824578Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "sys.path.append('../tools')\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "import pytorch_lightning.callbacks as pl_callbacks\n",
    "import data_utility, annotation_utility\n",
    "from models.rns_dataloader import *\n",
    "from active_learning_utility import get_strategy\n",
    "from active_learning_data import Data\n",
    "from active_learning_net import Net\n",
    "from copy import deepcopy\n",
    "from models.SwaV import SwaV\n",
    "from models.SupervisedDownstream import SupervisedDownstream\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argument*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Set a lower value for log_every_n_steps if you want to see logs for the training epoch*\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T18:15:29.120020Z",
     "end_time": "2024-02-07T18:15:29.457762Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_data1 = torch.randn((60,256))\n",
    "train_data2 = torch.randn((89,256))\n",
    "train_data3 = torch.randn((35,256))\n",
    "train_data4 = torch.randn((40,256))\n",
    "train_data5 = torch.randn((35,256))\n",
    "train_data6 = torch.randn((20,256))\n",
    "train_data7 = torch.randn((10,256))\n",
    "train_data8 = torch.randn((50,256))\n",
    "\n",
    "train_label1 = torch.randn((60,2))\n",
    "train_label2 = torch.randn((89,2))\n",
    "train_label3 = torch.randn((35,2))\n",
    "train_label4 = torch.randn((40,2))\n",
    "train_label5 = torch.randn((35,2))\n",
    "train_label6 = torch.randn((20,2))\n",
    "train_label7 = torch.randn((10,2))\n",
    "train_label8 = torch.randn((50,2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-07T18:00:34.966830Z",
     "end_time": "2024-02-07T18:00:35.296221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_list = [train_data1,train_data2,train_data3,train_data4,train_data5,train_data6,train_data7,train_data8]\n",
    "label_list = [train_label1,train_label2,train_label3,train_label4,train_label5,train_label6,train_label7,train_label8]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T15:58:01.193062Z",
     "end_time": "2024-02-08T15:58:01.505322Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence,pack_sequence,pad_packed_sequence\n",
    "class SimpleDataset(Dataset):\n",
    "    \"\"\"A simple dataset example.\"\"\"\n",
    "\n",
    "    def __init__(self, data, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (list): List of data.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of data points.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Retrieve a single data point at the specified index.\"\"\"\n",
    "        x = self.data[idx]\n",
    "        y = self.label[idx]\n",
    "\n",
    "        return x,y\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     info = list(zip(*batch))\n",
    "#     data = info[0]\n",
    "#     label = info[1]\n",
    "#\n",
    "#     print(data)\n",
    "#     print(label)\n",
    "#     # data.sort(key=lambda x: len(x), reverse=True)\n",
    "#     data = pack_sequence(data,enforce_sorted=False)\n",
    "#     # data.sort(key=lambda x: len(x), reverse=True)\n",
    "#     label = pack_sequence(label,enforce_sorted=False)\n",
    "#\n",
    "#     return data,label\n",
    "def collate_fn(batch):\n",
    "    info = list(zip(*batch))\n",
    "    data = list(info[0])\n",
    "    label = list(info[1])\n",
    "\n",
    "    print(data[0].size())\n",
    "    print(data[1].size())\n",
    "    print(data[2].size())\n",
    "\n",
    "    # data.sort(key=lambda x: len(x), reverse=True)\n",
    "    seq_len = [s.size(0) for s in data]\n",
    "    # print(seq_len)\n",
    "    # data.sort(key=lambda x: len(x), reverse=True)\n",
    "\n",
    "    data = pack_sequence(data,enforce_sorted=False)\n",
    "    label = pack_sequence(label,enforce_sorted=False)\n",
    "    # label = pad_sequence(label, batch_first=True).float()\n",
    "    # # data = data.unsqueeze(-1)\n",
    "    # label = pack_padded_sequence(label,  batch_first=True,enforce_sorted=True)\n",
    "\n",
    "    return data, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-09T12:42:05.464111Z",
     "end_time": "2024-02-09T12:42:06.112787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([5,6,7])\n",
    "c = torch.tensor([7,8])\n",
    "d = torch.tensor([9])\n",
    "train_x = [a, b, c, d]\n",
    "a = torch.tensor([10,20,30,40])\n",
    "b = torch.tensor([50,60,70])\n",
    "c = torch.tensor([70,80])\n",
    "d = torch.tensor([90])\n",
    "train_y = [a, b, c, d]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-09T12:42:06.770174Z",
     "end_time": "2024-02-09T12:42:07.126182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 256])\n",
      "torch.Size([60, 256])\n",
      "torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "data = SimpleDataset(data_list,label_list)\n",
    "data_loader = DataLoader(data, batch_size=3, shuffle=True, collate_fn=collate_fn)\n",
    "# 采用默认的 collate_fn 会报错\n",
    "#data_loader = DataLoader(data, batch_size=2, shuffle=True)\n",
    "batch_x, batch_y = iter(data_loader).next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-09T13:28:40.511041Z",
     "end_time": "2024-02-09T13:28:40.833648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([105, 256])\n"
     ]
    }
   ],
   "source": [
    "print(batch_x.data.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-09T13:28:41.304960Z",
     "end_time": "2024-02-09T13:28:41.621420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([105, 2])\n"
     ]
    }
   ],
   "source": [
    "print(batch_y.data.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-09T13:28:42.159187Z",
     "end_time": "2024-02-09T13:28:42.513314Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(256, 1024, 1, batch_first=True, bidirectional=True)\n",
    "ln = nn.Linear(2048, 2)\n",
    "# h0 = torch.rand(1, 2, 4).float()\n",
    "# c0 = torch.rand(1, 2, 4).float()\n",
    "out, (h1, c1) = rnn(batch_x)\n",
    "out_pad, out_len = pad_packed_sequence(out, batch_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T17:47:22.278581Z",
     "end_time": "2024-02-22T17:47:23.525290Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 60, 2048])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_pad.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T17:47:39.881961Z",
     "end_time": "2024-02-22T17:47:40.229327Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 1024])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T17:55:08.147246Z",
     "end_time": "2024-02-22T17:55:08.456718Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "PackedSequence(data=tensor([[-0.0389,  0.0633, -0.2791,  ..., -0.0707,  0.1296,  0.0750],\n        [-0.0238, -0.3834,  0.0858,  ..., -0.0675, -0.0851,  0.2169],\n        [ 0.1407, -0.4122, -0.1507,  ...,  0.0331,  0.1320,  0.0769],\n        ...,\n        [-0.1645, -0.4452, -0.2556,  ...,  0.0231,  0.0059,  0.0803],\n        [-0.0684,  0.2535,  0.3032,  ...,  0.1625, -0.0538,  0.1373],\n        [-0.0341,  0.1125,  0.0395,  ...,  0.0863,  0.0731, -0.0858]],\n       grad_fn=<CatBackward0>), batch_sizes=tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), sorted_indices=tensor([0, 2, 1]), unsorted_indices=tensor([0, 2, 1]))"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestModel(L.LightningModule):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(2048, 1024, 1, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(1024, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        x, (_, _) = self.rnn(x)\n",
    "        x, out_len = pad_packed_sequence(out, batch_first=True)\n",
    "        x = self.fc(x)\n",
    "\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_x, batch_y = batch\n",
    "        output = self(batch_x)\n",
    "\n",
    "        loss = torch.nn.functional.nll_loss(output, target.view(-1))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.model.parameters(), lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-09T12:42:14.209406Z",
     "end_time": "2024-02-09T12:42:14.524858Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 89, 2])"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln(out_pad.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T13:08:39.639876Z",
     "end_time": "2024-02-12T13:08:39.959463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([89, 10, 50])"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(out_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T13:09:02.695943Z",
     "end_time": "2024-02-12T13:09:03.256295Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 89, 2])"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(s,2) for s in out_len], batch_first=True)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-12T13:20:13.106929Z",
     "end_time": "2024-02-12T13:20:13.497864Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.1353,  0.1171,  0.0591,  ..., -0.0651,  0.2652,  0.0494],\n        [-0.3548,  0.1277,  0.0018,  ..., -0.1391,  0.1277, -0.4318],\n        [-0.0429,  0.0922, -0.0733,  ..., -0.1177,  0.1244, -0.0559],\n        ...,\n        [-0.1608,  0.0006, -0.1758,  ...,  0.1924,  0.2358,  0.2687],\n        [-0.0807, -0.0302, -0.2945,  ..., -0.0398,  0.2050,  0.1637],\n        [ 0.1689, -0.1518, -0.1156,  ...,  0.1064,  0.0400,  0.1942]],\n       grad_fn=<SelectBackward0>)"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_pad[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T16:50:15.881088Z",
     "end_time": "2024-02-08T16:50:16.195510Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
