{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T21:42:28.101575Z",
     "end_time": "2024-02-15T21:42:28.177310Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T21:42:28.177310Z",
     "end_time": "2024-02-15T21:42:28.254772Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../tools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import math\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import lightning as L\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from model_config import MODEL_CONFIG\n",
    "from lightly.models.modules import SwaVPrototypes, SwaVProjectionHead\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch import callbacks as pl_callbacks\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "matplotlib.use(\"nbAgg\")\n",
    "\n",
    "import data_utility\n",
    "\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:42:28.255771Z",
     "end_time": "2024-02-15T21:42:33.376424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T21:42:33.378424Z",
     "end_time": "2024-02-15T21:42:33.721072Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_dir = \"../../../user_data/\"\n",
    "log_folder_root = '../../../user_data/logs/'\n",
    "ckpt_folder_root = '../../../user_data/checkpoints/'\n",
    "torch.set_float32_matmul_precision('medium')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:42:33.722071Z",
     "end_time": "2024-02-15T21:42:34.063447Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T21:42:34.063447Z",
     "end_time": "2024-02-15T21:42:34.417452Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_list = os.listdir(data_dir + 'rns_data')\n",
    "patientIDs = [s for s in dir_list for type_string in ['HUP', 'RNS'] if type_string in s.upper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T21:42:34.403455Z",
     "end_time": "2024-02-15T21:42:34.746797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['HUP047.npy',\n 'HUP059.npy',\n 'HUP084.npy',\n 'HUP096.npy',\n 'HUP101.npy',\n 'HUP108.npy',\n 'HUP109.npy',\n 'HUP121.npy',\n 'HUP127.npy',\n 'HUP128.npy',\n 'HUP129.npy',\n 'HUP131.npy',\n 'HUP136.npy',\n 'HUP137.npy',\n 'HUP143.npy',\n 'HUP147.npy',\n 'HUP153.npy',\n 'HUP156.npy',\n 'HUP159.npy',\n 'HUP182.npy',\n 'HUP192.npy',\n 'HUP197.npy',\n 'HUP199.npy',\n 'HUP205.npy',\n 'RNS021.npy',\n 'RNS022.npy',\n 'RNS026.npy',\n 'RNS029.npy']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir + 'rns_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g05XnHgHas-D",
    "ExecuteTime": {
     "start_time": "2024-02-15T21:42:34.748796Z",
     "end_time": "2024-02-15T21:42:50.375654Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:15<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "data_import = data_utility.read_files(path=data_dir + 'rns_data', path_data=data_dir + 'rns_raw_cache',\n",
    "                                      patientIDs=patientIDs, annotation_only=False, verbose=True)\n",
    "ids = list(data_import.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T21:42:50.377658Z",
     "end_time": "2024-02-15T21:43:42.682964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUP047\n",
      "HUP059\n",
      "HUP084\n",
      "HUP096\n",
      "HUP101\n",
      "bla\n",
      "HUP108\n",
      "bla\n",
      "HUP109\n",
      "bla\n",
      "HUP121\n",
      "HUP127\n",
      "HUP128\n",
      "bla\n",
      "HUP129\n",
      "bla\n",
      "HUP131\n",
      "HUP136\n",
      "bla\n",
      "HUP143\n",
      "HUP147\n",
      "bla\n",
      "bla\n",
      "HUP153\n",
      "HUP159\n",
      "HUP182\n",
      "bla\n",
      "HUP192\n",
      "bla\n",
      "HUP197\n",
      "HUP199\n",
      "bla\n",
      "HUP205\n",
      "RNS021\n",
      "bla\n",
      "bla\n",
      "RNS022\n",
      "RNS026\n",
      "bla\n",
      "RNS029\n",
      "bla\n",
      "bla\n",
      "bla\n"
     ]
    }
   ],
   "source": [
    "window_len = 10\n",
    "stride = 10\n",
    "concat_n = 1\n",
    "\n",
    "ids = ['HUP047',\n",
    "       'HUP059',\n",
    "       'HUP084',\n",
    "       'HUP096',\n",
    "       'HUP101',\n",
    "       'HUP108',\n",
    "       'HUP109',\n",
    "       'HUP121',\n",
    "       'HUP127',\n",
    "       'HUP128',\n",
    "       'HUP129',\n",
    "       'HUP131',\n",
    "       'HUP136',\n",
    "       # 'HUP137',\n",
    "       'HUP143',\n",
    "       'HUP147',\n",
    "       'HUP153',\n",
    "       # 'HUP156',\n",
    "       'HUP159',\n",
    "       'HUP182',\n",
    "       'HUP192',\n",
    "       'HUP197',\n",
    "       'HUP199',\n",
    "       'HUP205',\n",
    "       'RNS021',\n",
    "       'RNS022',\n",
    "       'RNS026',\n",
    "       'RNS029']\n",
    "\n",
    "data_list = []\n",
    "for id in ids:\n",
    "    print(id)\n",
    "    data_import[id].set_window_parameter(window_length=window_len, window_displacement=stride)\n",
    "    data_import[id].normalize_data()\n",
    "    _, sliced_data = data_import[id].get_windowed_data(data_import[id].catalog[\"Event Start idx\"],\n",
    "                                                       data_import[id].catalog[\"Event End idx\"])\n",
    "    data_list.append(sliced_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# next(iter(RNSDataset(sliced_data)))[0][1].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:43:42.683964Z",
     "end_time": "2024-02-15T21:43:43.028320Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# next(iter(unlabeled_dataset))[0].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:43:43.029323Z",
     "end_time": "2024-02-15T21:43:43.361210Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import os\n",
    "import random\n",
    "from lightly.loss import SwaVLoss\n",
    "from lightly.loss.memory_bank import MemoryBankModule\n",
    "from lightly.models.modules import SwaVProjectionHead, SwaVPrototypes\n",
    "from lightly.transforms.swav_transform import SwaVTransform\n",
    "from lightly.data import SwaVCollateFunction\n",
    "from model_config import MODEL_CONFIG\n",
    "\n",
    "\n",
    "class Transpose(nn.Module):\n",
    "    def __init__(self, dim1, dim2):\n",
    "        super(Transpose, self).__init__()\n",
    "        self.dim1 = dim1\n",
    "        self.dim2 = dim2\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.transpose(self.dim1, self.dim2)\n",
    "\n",
    "\n",
    "class SwaV(L.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet50()\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.projection_head = SwaVProjectionHead(2048, 2048, 128)\n",
    "        self.prototypes = SwaVPrototypes(128, 256, 1)\n",
    "        self.start_queue_at_epoch = 15\n",
    "        self.queues = nn.ModuleList([MemoryBankModule(size=512) for _ in range(2)])\n",
    "        self.criterion = SwaVLoss(sinkhorn_epsilon=0.05)\n",
    "\n",
    "        data_dir = \"../../../user_data/\"\n",
    "        self.dir_list = os.listdir(data_dir + 'rns_cache')\n",
    "        # self.patientIDs = [s for s in dir_list for type_string in ['HUP', 'RNS'] if type_string in s.upper()]\n",
    "\n",
    "        self.ft_enc = nn.ModuleList()\n",
    "        for i, _ in enumerate(config.ft_enc_dims):\n",
    "            if i == 0:\n",
    "                self.ft_enc.append(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=4,\n",
    "                        out_channels=config.ft_enc_dims[i],\n",
    "                        kernel_size=config.ft_enc_kernel_widths[i],\n",
    "                        stride=config.ft_enc_strides[i],\n",
    "                        padding=0,\n",
    "                        groups=config.channel_buffer_size,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                self.ft_enc.append(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=config.ft_enc_dims[i - 1],\n",
    "                        out_channels=config.ft_enc_dims[i],\n",
    "                        kernel_size=config.ft_enc_kernel_widths[i],\n",
    "                        stride=config.ft_enc_strides[i],\n",
    "                        padding=0,\n",
    "                        groups=config.channel_buffer_size,\n",
    "                    )\n",
    "                )\n",
    "            # transpose the output of the convolutional layer\n",
    "            self.ft_enc.append(Transpose(1, 2))\n",
    "            # layer normalization\n",
    "            self.ft_enc.append(nn.LayerNorm(config.ft_enc_dims[i]))\n",
    "            # GELU activation\n",
    "            self.ft_enc.append(nn.GELU())\n",
    "            # transpose the output of the convolutional layer\n",
    "            self.ft_enc.append(Transpose(1, 2))\n",
    "\n",
    "        # add a adaptive pool so different sized crops can be the same length afterward\n",
    "        self.ft_enc.append(nn.AdaptiveAvgPool1d(config.spatial_transformer_hidden))\n",
    "\n",
    "        # convert the list of modules to a sequential module\n",
    "        self.ft_enc = nn.Sequential(*self.ft_enc)\n",
    "\n",
    "        crop_transforms = []\n",
    "        crop_sizes = [224, 96]\n",
    "        crop_min_scales = [0.14, 0.05]\n",
    "        crop_max_scales = [1.0, 0.14]\n",
    "        crop_counts = [2, 6]\n",
    "        for i in range(len(crop_sizes)):\n",
    "            random_resized_crop = T.RandomResizedCrop(crop_sizes[i], scale=(crop_min_scales[i], crop_max_scales[i]))\n",
    "\n",
    "            crop_transforms.extend([T.Compose([random_resized_crop])] * crop_counts[i])\n",
    "\n",
    "        self.crop_transforms = crop_transforms\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[0].float()\n",
    "\n",
    "        x = self.ft_enc(x)\n",
    "\n",
    "        views = []\n",
    "        for tf in self.crop_transforms:\n",
    "            views.append(tf(x).unsqueeze(1).repeat(1, 3, 1, 1))\n",
    "\n",
    "        high_resolution, low_resolution = views[:2], views[2:]\n",
    "        self.prototypes.normalize()\n",
    "\n",
    "        high_resolution_features = [self._subforward(x) for x in high_resolution]\n",
    "        low_resolution_features = [self._subforward(x) for x in low_resolution]\n",
    "\n",
    "        high_resolution_prototypes = [\n",
    "            self.prototypes(x, self.current_epoch) for x in high_resolution_features\n",
    "        ]\n",
    "        low_resolution_prototypes = [\n",
    "            self.prototypes(x, self.current_epoch) for x in low_resolution_features\n",
    "        ]\n",
    "        queue_prototypes = self._get_queue_prototypes(high_resolution_features)\n",
    "        loss = self.criterion(\n",
    "            high_resolution_prototypes, low_resolution_prototypes, queue_prototypes\n",
    "        )\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optim\n",
    "\n",
    "    def _subforward(self, input):\n",
    "        features = self.backbone(input).flatten(start_dim=1)\n",
    "        features = self.projection_head(features)\n",
    "        features = nn.functional.normalize(features, dim=1, p=2)\n",
    "        return features\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_queue_prototypes(self, high_resolution_features):\n",
    "        if len(high_resolution_features) != len(self.queues):\n",
    "            raise ValueError(\n",
    "                f\"The number of queues ({len(self.queues)}) should be equal to the number of high \"\n",
    "                f\"resolution inputs ({len(high_resolution_features)}). Set `n_queues` accordingly.\"\n",
    "            )\n",
    "\n",
    "        # Get the queue features\n",
    "        queue_features = []\n",
    "        for i in range(len(self.queues)):\n",
    "            _, features = self.queues[i](high_resolution_features[i], update=True)\n",
    "            # Queue features are in (num_ftrs X queue_length) shape, while the high res\n",
    "            # features are in (batch_size X num_ftrs). Swap the axes for interoperability.\n",
    "            features = torch.permute(features, (1, 0))\n",
    "            queue_features.append(features)\n",
    "\n",
    "        # If loss calculation with queue prototypes starts at a later epoch,\n",
    "        # just queue the features and return None instead of queue prototypes.\n",
    "        if (\n",
    "                self.start_queue_at_epoch > 0\n",
    "                and self.current_epoch < self.start_queue_at_epoch\n",
    "        ):\n",
    "            return None\n",
    "\n",
    "        # Assign prototypes\n",
    "        queue_prototypes = [\n",
    "            self.prototypes(x, self.current_epoch) for x in queue_features\n",
    "        ]\n",
    "        return queue_prototypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:43:43.369210Z",
     "end_time": "2024-02-15T21:43:43.706149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "del data_import"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:43:43.708670Z",
     "end_time": "2024-02-15T21:43:47.151586Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from models.rns_dataloader import RNSDataset\n",
    "\n",
    "unlabeled_dataset = RNSDataset(data_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:43:47.142590Z",
     "end_time": "2024-02-15T21:44:33.727244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "del data_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:44:33.756244Z",
     "end_time": "2024-02-15T21:44:35.457764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T21:44:35.464762Z",
     "end_time": "2024-02-15T21:44:36.535344Z"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    unlabeled_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=10,\n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# np.vstack(data_list).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:44:36.537344Z",
     "end_time": "2024-02-15T21:44:37.269333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T21:37:01.456181Z",
     "end_time": "2024-02-15T21:39:57.617400Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick Xu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\fabric\\connector.py:565: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Patrick Xu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:630: Checkpoint directory C:\\Users\\Patrick Xu\\Desktop\\RNS_Annotation-Pipeline\\scripts\\RNS_LITT_ANNOTATION_PIPELINE\\rns_scripts\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type               | Params\n",
      "-------------------------------------------------------\n",
      "0 | backbone        | Sequential         | 23.5 M\n",
      "1 | projection_head | SwaVProjectionHead | 4.5 M \n",
      "2 | prototypes      | SwaVPrototypes     | 33.0 K\n",
      "3 | queues          | ModuleList         | 0     \n",
      "4 | criterion       | SwaVLoss           | 0     \n",
      "5 | ft_enc          | Sequential         | 22.7 K\n",
      "-------------------------------------------------------\n",
      "28.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.0 M    Total params\n",
      "112.098   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4ed0298046049fd80b63d6d1c200b2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = SwaV(MODEL_CONFIG)\n",
    "\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "checkpoint_callback = pl_callbacks.ModelCheckpoint(monitor='train_loss',\n",
    "                                                   filename='model_epoch-{epoch:02d}-{train_loss:.5f}',\n",
    "                                                   save_top_k=-1,\n",
    "                                                   every_n_epochs=5,\n",
    "                                                   # enable_version_counter=True,\n",
    "                                                   dirpath='checkpoints')\n",
    "\n",
    "early_stopping = pl_callbacks.EarlyStopping(monitor=\"train_loss\",\n",
    "                                            mode=\"min\",\n",
    "                                            patience=15)\n",
    "csv_logger = pl_loggers.CSVLogger('logs',\n",
    "                                  name=\"log\")\n",
    "\n",
    "trainer = L.Trainer(log_every_n_steps=500,\n",
    "                    logger=csv_logger,\n",
    "                    max_epochs=500,\n",
    "                    callbacks=[checkpoint_callback, early_stopping],\n",
    "                    accelerator='gpu',\n",
    "                    devices=1,\n",
    "                    precision=16)\n",
    "trainer.fit(model=model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-15T21:09:15.815950Z",
     "end_time": "2024-02-15T21:09:16.142843Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_a = torch.arange(65536).reshape(256, 256).repeat(10, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crop_transforms = []\n",
    "crop_sizes = [224, 96]\n",
    "crop_min_scales = [0.14, 0.05]\n",
    "crop_max_scales = [1.0, 0.14]\n",
    "crop_counts = [2, 6]\n",
    "for i in range(len(crop_sizes)):\n",
    "    random_resized_crop = T.RandomResizedCrop(crop_sizes[i], scale=(crop_min_scales[i], crop_max_scales[i]))\n",
    "\n",
    "    crop_transforms.extend([T.Compose([random_resized_crop])] * crop_counts[i])\n",
    "\n",
    "views = []\n",
    "for tf in crop_transforms:\n",
    "    views.append(tf(test_a))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:04:32.266665Z",
     "end_time": "2024-02-15T21:04:32.725550Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "views[0].unsqueeze(1).repeat(1, 3, 1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:07:36.910102Z",
     "end_time": "2024-02-15T21:07:37.284153Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "views[0][1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-15T21:04:52.497698Z",
     "end_time": "2024-02-15T21:04:52.834829Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Train_SwAV_10_epochs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
